# 1. å›¾åƒåˆ†ç±»æ¨¡å‹éƒ¨ç½²: PyTorch -> ONNX

## 1.1 æ¨¡å‹éƒ¨ç½²ä»‹ç»

### 1.1.1 äººå·¥æ™ºèƒ½å¼€å‘éƒ¨ç½²å…¨æµç¨‹

```mermaid
graph LR

style step1 fill:transparent,stroke:#FF0F50,stroke-width:2px;
style æ•°æ® fill:transparent,stroke:#4CAF50,stroke-width:2px;
style æ•°æ®é‡‡é›† fill:transparent,stroke:#4CAF50,stroke-width:2px;
style å®šä¹‰ç±»åˆ« fill:transparent,stroke:#4CAF50,stroke-width:2px;
style æ ‡æ³¨ fill:transparent,stroke:#4CAF50,stroke-width:2px;
style æ•°æ®é›† fill:transparent,stroke:#4CAF50,stroke-width:2px;

style step2 fill:transparent,stroke:#FF0F50,stroke-width:2px;
style æ¨¡å‹ fill:transparent,stroke:#2196F3,stroke-width:2px;
style è®­ç»ƒæ¨¡å‹ fill:transparent,stroke:#2196F3,stroke-width:2px;
style æµ‹è¯•é›†è¯„ä¼° fill:transparent,stroke:#2196F3,stroke-width:2px;
style è°ƒå‚ä¼˜åŒ– fill:transparent,stroke:#2196F3,stroke-width:2px;
style å¯è§£é‡Šåˆ†æ fill:transparent,stroke:#2196F3,stroke-width:2px;

style step3 fill:transparent,stroke:#FF0F50,stroke-width:2px;
style éƒ¨ç½² fill:transparent,stroke:#BA55D30,stroke-width:2px;
style æ‰‹æœº/å¹³æ¿ fill:transparent,stroke:#BA55D30,stroke-width:2px;
style æœåŠ¡å™¨ fill:transparent,stroke:#BA55D30,stroke-width:2px;
style PC/æµè§ˆå™¨ fill:transparent,stroke:#BA55D30,stroke-width:2px;
style åµŒå…¥å¼å¼€å‘æ¿ fill:transparent,stroke:#BA55D30,stroke-width:2px;

step1 --> æ•°æ® --> æ•°æ®é‡‡é›† --> å®šä¹‰ç±»åˆ« --> æ ‡æ³¨ --> æ•°æ®é›†

step2 --> æ¨¡å‹ --> è®­ç»ƒæ¨¡å‹ --> æµ‹è¯•é›†è¯„ä¼° --> è°ƒå‚ä¼˜åŒ– --> å¯è§£é‡Šåˆ†æ

step3 --> éƒ¨ç½² --> æ‰‹æœº/å¹³æ¿
éƒ¨ç½² --> æœåŠ¡å™¨
éƒ¨ç½² --> PC/æµè§ˆå™¨
éƒ¨ç½² --> åµŒå…¥å¼å¼€å‘æ¿
```

### 1.1.2 æ¨¡å‹éƒ¨ç½²å¹³å°å’ŒèŠ¯ç‰‡ä»‹ç»

- **è®¾å¤‡**ï¼šPCã€æµè§ˆå™¨ã€APPã€å°ç¨‹åºã€æœåŠ¡å™¨ã€åµŒå…¥å¼å¼€å‘æ¿ã€æ— äººè½¦ã€æ— äººæœºã€Jetson Nanoã€æ ‘è“æ´¾ã€æœºæ¢°è‡‚ã€ç‰©è”ç½‘è®¾å¤‡
- **å‚å•†**ï¼š
  - è‹±ç‰¹å°”ï¼ˆIntelï¼‰ï¼šä¸»è¦ç”Ÿäº§ CPUï¼ˆä¸­å¤®å¤„ç†å™¨ï¼‰å’Œä¸€äº› FPGAï¼ˆç°åœºå¯ç¼–ç¨‹é—¨é˜µåˆ—ï¼‰èŠ¯ç‰‡ã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬ Intel Core ç³»åˆ— CPU å’Œ Xeon ç³»åˆ—æœåŠ¡å™¨ CPUï¼Œä»¥åŠ FPGA äº§å“å¦‚ Intel Stratix ç³»åˆ—ã€‚
  - è‹±ä¼Ÿè¾¾ï¼ˆNVIDIAï¼‰ï¼šä»¥ GPUï¼ˆå›¾å½¢å¤„ç†å™¨ï¼‰ä¸ºä¸»æ‰“äº§å“ï¼Œå¹¿æ³›åº”ç”¨äºå›¾å½¢æ¸²æŸ“ã€æ·±åº¦å­¦ä¹ ç­‰é¢†åŸŸã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬ NVIDIA GeForce ç³»åˆ—ç”¨äºæ¸¸æˆå›¾å½¢å¤„ç†ï¼ŒNVIDIA Tesla å’Œ NVIDIA A100 ç”¨äºæ·±åº¦å­¦ä¹ åŠ é€Ÿã€‚
  - AMDï¼šä¸»è¦ç”Ÿäº§ CPU å’Œ GPUã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬ AMD Ryzen ç³»åˆ— CPU å’Œ AMD EPYC ç³»åˆ—æœåŠ¡å™¨ CPUï¼Œä»¥åŠ AMD Radeon ç³»åˆ— GPU ç”¨äºæ¸¸æˆå’Œä¸“ä¸šå›¾å½¢å¤„ç†ã€‚
  - è‹¹æœï¼ˆAppleï¼‰ï¼šç”Ÿäº§è‡ªå®¶è®¾è®¡çš„èŠ¯ç‰‡ï¼Œä¸»è¦åŒ…æ‹¬è‹¹æœ M ç³»åˆ—èŠ¯ç‰‡ã€‚ä»£è¡¨ä½œå“æœ‰ M1 èŠ¯ç‰‡ï¼Œå¹¿æ³›åº”ç”¨äºè‹¹æœçš„ Mac ç”µè„‘ã€iPad å’Œä¸€äº›å…¶ä»–è®¾å¤‡ã€‚
  - é«˜é€šï¼ˆQualcommï¼‰ï¼šä¸»è¦ç”Ÿäº§ç§»åŠ¨å¹³å°èŠ¯ç‰‡ï¼ŒåŒ…æ‹¬ç§»åŠ¨å¤„ç†å™¨å’Œè°ƒåˆ¶è§£è°ƒå™¨ã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬ Snapdragon ç³»åˆ—èŠ¯ç‰‡ï¼Œç”¨äºæ™ºèƒ½æ‰‹æœºå’Œç§»åŠ¨è®¾å¤‡ã€‚
  - æ˜‡è…¾ï¼ˆAscendï¼‰ï¼šç”±åä¸ºç”Ÿäº§ï¼Œä¸»è¦ç”Ÿäº§ NPUï¼ˆç¥ç»ç½‘ç»œå¤„ç†å™¨ï¼‰ï¼Œç”¨äºæ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬æ˜‡è…¾ 910 å’Œæ˜‡è…¾ 310ã€‚
  - éº’éºŸï¼ˆKirinï¼‰ï¼šåŒæ ·ç”±åä¸ºç”Ÿäº§ï¼Œä¸»è¦ç”Ÿäº§æ‰‹æœºèŠ¯ç‰‡ï¼ŒåŒ…æ‹¬ CPU å’Œ GPUã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬éº’éºŸ 9000 ç³»åˆ—ï¼Œç”¨äºåä¸ºæ——èˆ°æ‰‹æœºã€‚
  - ç‘èŠ¯å¾®ï¼ˆRockchipï¼‰ï¼šä¸»è¦ç”Ÿäº§ VPUï¼ˆè§†è§‰å¤„ç†å™¨ï¼‰å’Œä¸€äº›ç§»åŠ¨å¹³å°èŠ¯ç‰‡ã€‚ä»£è¡¨ä½œå“åŒ…æ‹¬ RK3288 å’Œ RK3399ï¼Œå¹¿æ³›åº”ç”¨äºæ™ºèƒ½æ˜¾ç¤ºã€æœºå™¨äººç­‰é¢†åŸŸã€‚

|èŠ¯ç‰‡å|è‹±æ–‡å|ä¸­æ–‡å|å‚å•†|ä¸»è¦ä»»åŠ¡|æ˜¯å¦è®­ç»ƒ|æ˜¯å¦æ¨ç†|ç®—åŠ›|é€Ÿåº¦|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|CPU|Central Processing Unit(CPU)|ä¸­å¤®å¤„ç†å™¨|å„å¤§å‚å•†|é€šç”¨è®¡ç®—|æ˜¯|æ˜¯|é«˜|ä¸­ç­‰|
|GPU|Graphics Processing Unit(GPU)|å›¾å½¢å¤„ç†å™¨|NVIDIAã€AMDç­‰|å›¾å½¢æ¸²æŸ“ã€æ·±åº¦å­¦ä¹ åŠ é€Ÿ|æ˜¯|æ˜¯|é«˜|é«˜|
|TPU|Tensor Processing Unit(TPU)|å¼ é‡å¤„ç†å™¨|è°·æ­Œ|æœºå™¨å­¦ä¹ ä¸­çš„å¼ é‡è¿ç®—|æ˜¯|æ˜¯|é«˜|é«˜|
|NPU|Neural Processing Unit(NPU)|ç¥ç»ç½‘ç»œå¤„ç†å™¨|åä¸ºã€è”å‘ç§‘ç­‰|æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½æå‡|æ˜¯|æ˜¯|é«˜|ä¸­ç­‰|
|VPU|Vision Processing Unit(VPU)|è§†è§‰å¤„ç†å™¨|è‹±ç‰¹å°”ã€åšé€šç­‰|å›¾åƒå’Œè§†é¢‘å¤„ç†|å¦|æ˜¯|ä¸­ç­‰|ä¸­ç­‰|
|DSP|Digital Signal Processor(DSP)|æ•°å­—ä¿¡å·å¤„ç†å™¨|å¾·å·ä»ªå™¨ã€é«˜é€šç­‰|æ•°å­—ä¿¡å·å¤„ç†ã€éŸ³é¢‘ä¿¡å·å¤„ç†|å¦|æ˜¯|ä¸­ç­‰|ä¸­ç­‰|
|FPGA|Field-Programmable Gate Array(FPGA)|ç°åœºå¯ç¼–ç¨‹é—¨é˜µåˆ—|è‹±ç‰¹å°”ã€èµ›çµæ€ç­‰|å¯ç¼–ç¨‹ç¡¬ä»¶åŠ é€Ÿå™¨|æ˜¯|æ˜¯|é«˜|ä¸­ç­‰|

### 1.1.3 æ¨¡å‹éƒ¨ç½²çš„é€šç”¨æµç¨‹

```mermaid
graph LR

style PyTorch fill:transparent,stroke:#2196F3,stroke-width:2px;
style TensorFlow fill:transparent,stroke:#2196F3,stroke-width:2px;
style Caffe fill:transparent,stroke:#2196F3,stroke-width:2px;
style PaddlePaddle fill:transparent,stroke:#2196F3,stroke-width:2px;
style è®­ç»ƒæ¡†æ¶ fill:transparent,stroke:#2196F3,stroke-width:2px;
style ONNX/ä¸­é—´è¡¨ç¤º fill:transparent,stroke:#4CAF50,stroke-width:2px;
style æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ fill:transparent,stroke:#2196F3,stroke-width:2px;
style TensorRT fill:transparent,stroke:#2196F3,stroke-width:2px;
style ONNXRuntime fill:transparent,stroke:#2196F3,stroke-width:2px;
style OpenVINO fill:transparent,stroke:#2196F3,stroke-width:2px;
style NCNN/TNN fill:transparent,stroke:#2196F3,stroke-width:2px;
style PPL fill:transparent,stroke:#2196F3,stroke-width:2px;

PyTorch --> è®­ç»ƒæ¡†æ¶
TensorFlow --> è®­ç»ƒæ¡†æ¶
Caffe --> è®­ç»ƒæ¡†æ¶
PaddlePaddle --> è®­ç»ƒæ¡†æ¶
è®­ç»ƒæ¡†æ¶ -->|è½¬æ¢| ONNX/ä¸­é—´è¡¨ç¤º -->|è¿è¡Œ| æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯
æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ --> TensorRT
æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ --> ONNXRuntime
æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ --> OpenVINO
æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ --> NCNN/TNN
æ¨ç†æ¡†æ¶/å¼•æ“/åç«¯ --> PPL
```

## 1.2 ä½¿ç”¨ ONNX çš„æ„ä¹‰

<div align=center>
    <img src=./imgs_markdown/2024-01-25-10-49-51.png
    width=100%>
</div>

<div align=center>
    <img src=./imgs_markdown/2024-01-25-10-50-17.png
    width=100%>
</div>

ä»è¿™ä¸¤å¼ å›¾å¯ä»¥å¾ˆæ˜æ˜¾çš„çœ‹åˆ°ï¼Œå½“æœ‰äº†ä¸­é—´è¡¨ç¤º ONNX åï¼Œä»åŸæ¥çš„ $M \times N$ å˜ä¸ºäº† $M + N$ï¼Œè®©æ¨¡å‹éƒ¨ç½²çš„æµç¨‹å˜å¾—ç®€å•ã€‚

## 1.3 ONNX çš„ä»‹ç»

å¼€æºæœºå™¨å­¦ä¹ <font color='blue'>é€šç”¨ä¸­é—´æ ¼å¼</font>ï¼Œç”±å¾®è½¯ã€Facebookï¼ˆMetaï¼‰ã€äºšé©¬é€Šã€IBM å…±åŒå‘èµ·çš„ã€‚<font color='green'>å®ƒå¯ä»¥å…¼å®¹å„ç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¹Ÿå¯ä»¥å…¼å®¹å„ç§æ¨ç†å¼•æ“å’Œç»ˆç«¯ç¡¬ä»¶ã€æ“ä½œç³»ç»Ÿ</font>ã€‚

## 1.4 ONNX ç¯å¢ƒå®‰è£…

```bash
pip install onnx -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install onnxruntime -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## 1.5 å°†ä¸€ä¸ªåˆ†ç±»æ¨¡å‹è½¬æ¢ä¸º ONNX

```python
import torch
from torchvision import models


device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"æ­£åœ¨ä½¿ç”¨çš„è®¾å¤‡: {device}")

# åˆ›å»ºä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹
model = models.resnet18(pretrained=True)  # ImageNet é¢„è®­ç»ƒæƒé‡
model = model.eval().to(device)

# æ„å»ºä¸€ä¸ªè¾“å…¥
dummy_input = torch.randn(size=[1, 3, 256, 256]).to(device)  # [N, B, H, W]

# è®©æ¨¡å‹æ¨ç†
output = model(dummy_input)
print(f"output.shape: {output.shape}")

# ä½¿ç”¨ PyTorch è‡ªå¸¦çš„å‡½æ•°å°†æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼
onnx_save_path = 'ONNX/saves/resnet18_imagenet.onnx'  # å¯¼å‡ºçš„ONNXæ¨¡å‹è·¯å¾„ 
with torch.no_grad():
    torch.onnx.export(
        model=model,                            # è¦è½¬æ¢çš„æ¨¡å‹
        args=dummy_input,                       # æ¨¡å‹çš„è¾“å…¥
        f=onnx_save_path,                       # å¯¼å‡ºçš„ONNXæ¨¡å‹è·¯å¾„ 
        input_names=['input'],                  # ONNXæ¨¡å‹è¾“å…¥çš„åå­—(è‡ªå®šä¹‰)
        output_names=['output'],                # ONNXæ¨¡å‹è¾“å‡ºçš„åå­—(è‡ªå®šä¹‰)
        opset_version=11,                       # Opsetç®—å­é›†åˆçš„ç‰ˆæœ¬ï¼ˆé»˜è®¤ä¸º17ï¼‰
    )
    
print(f"ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼Œè·¯å¾„ä¸ºï¼š{onnx_save_path}")
```

```
æ­£åœ¨ä½¿ç”¨çš„è®¾å¤‡: cpu
/home/leovin/anaconda3/envs/wsl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/leovin/anaconda3/envs/wsl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /home/leovin/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:03<00:00, 13.9MB/s]
output.shape: torch.Size([1, 1000])
ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼Œè·¯å¾„ä¸ºï¼šONNX/saves/resnet18_imagenet.onnx
```

ğŸ’¡ <kbd>Tips</kbd>:
1. opset ç®—å­é›†ä¸åŒç‰ˆæœ¬åŒºåˆ«: [Operators.md](https://github.com/onnx/onnx/blob/main/docs/Operators.md)
2. è™½ç„¶è¯´ PyTorch åœ¨æé†’ `pretrained=True` å°†ä¼šè¢«å¼ƒç”¨ï¼Œå¯ä»¥ä½¿ç”¨ `weights=weights=ResNet18_Weights.DEFAULT` æˆ– `weights=ResNet18_Weights.IMAGENET1K_V1` æ¥ä»£æ›¿ã€‚ä½†å¾ˆæ˜æ˜¾å‰è€…æ¯”è¾ƒæ–¹ä¾¿ï¼Œåè€…è¿˜éœ€è¦æŸ¥çœ‹å¯¹åº”çš„ç‰ˆæœ¬å·ï¼Œæ¯”è¾ƒéº»çƒ¦ :joy:

æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨ Netron æŸ¥çœ‹ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-25-11-35-29.png
    width=100%>
</div>

> 1. åŸå›¾é“¾æ¥ä¸ºï¼š[resnet18_imagenet.png](https://github.com/Le0v1n/Learning-Notebook-Codes/blob/main/ONNX/imgs_markdown/resnet18_imagenet.png)
> 2. ImageNet æ•°æ®é›†æœ‰ 1000 ä¸ªç±»åˆ«

## 1.6 æ£€æŸ¥ä¸€ä¸ªæ¨¡å‹å¯¼å‡ºæ˜¯å¦æ­£ç¡®

```python
import onnx


# è¯»å–å¯¼å‡ºçš„æ¨¡å‹
onnx_path = 'ONNX/saves/resnet18_imagenet.onnx'  # å¯¼å‡ºçš„ONNXæ¨¡å‹è·¯å¾„
onnx_model = onnx.load(onnx_path)

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£å¸¸
onnx.checker.check_model(onnx_model)

print(f"æ¨¡å‹å¯¼å‡ºæ­£å¸¸!")
```

```
æ¨¡å‹å¯¼å‡ºæ­£å¸¸!
```

> æˆ‘ä»¬åœ¨ã€ŠonnxåŸºç¡€ã€‹ä¸­å·²ç»è®²è¿‡ `check_model()` è¿™ä¸ªå‡½æ•°ï¼Œå®ƒå¯ä»¥æ£€æŸ¥ ONNX æ¨¡å‹ï¼Œå¦‚æœè¯¥å‡½æ•°å‘ç°æ¨¡å‹é”™è¯¯ï¼Œåˆ™ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œ

## 1.7 ä¿®æ”¹åŠ¨æ€ç»´åº¦

å‰é¢æˆ‘ä»¬å¯¼å‡ºçš„ ONNX æ¨¡å‹ä¸­ï¼Œè¾“å…¥çš„ç»´åº¦æ˜¯å›ºå®šçš„ï¼š`[1, 3, 256, 256]`ï¼Œé‚£ä¹ˆæ­¤æ—¶è¿™ä¸ª ONNX çš„è¾“å…¥å°±è¢«é™åˆ¶äº†ï¼š
- å¦‚æœæˆ‘ä»¬æƒ³è¦å¤š Batch çš„è¾“å…¥ â†’ ä¸è¡Œ
- å¦‚æœæˆ‘ä»¬è¾“å…¥çš„å›¾ç‰‡æ˜¯ç°åº¦å›¾ â†’ ä¸è¡Œ
- å¦‚æœæˆ‘ä»¬è¾“å…¥çš„å›¾ç‰‡å°ºå¯¸ä¸æ˜¯ 256Ã—256 â†’ ä¸è¡Œ

è€Œ `torch.onnx.export()` è¿™ä¸ªå‡½æ•°ä¹Ÿå¸®æˆ‘è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå®ƒæœ‰ä¸€ä¸ªåä¸º `dynamic_axis` çš„å‚æ•°ï¼Œæˆ‘ä»¬çœ‹ä¸€ä¸‹å®˜ç½‘å¯¹è¯¥å‚æ•°çš„æè¿°ï¼š

> dynamic_axes (*dict[string, dict[int, string]] or dict[string, list(int)], default empty dict*) â€“
> 
> By default the exported model will have the shapes of all input and output tensors set to exactly match those given in `args`. To specify axes of tensors as dynamic (i.e. known only at run-time), set `dynamic_axes` to a dict with schema:
> - **KEY (str)**: an input or output name. Each name must also be provided in input_names or output_names.
> - **VALUE (dict or list)**: If a dict, keys are axis indices and values are axis names. If a list, each element is an axis index.

> dynamic_axesï¼ˆ*dict[string, dict[int, string]]æˆ–dict[string, list(int)]ï¼Œé»˜è®¤ä¸ºç©ºå­—å…¸*ï¼‰â€“
> 
> é»˜è®¤æƒ…å†µä¸‹ï¼Œå¯¼å‡ºçš„æ¨¡å‹å°†ä½¿æ‰€æœ‰è¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„å½¢çŠ¶å®Œå…¨åŒ¹é…`args`ä¸­ç»™å®šçš„å½¢çŠ¶ã€‚è¦å°†å¼ é‡çš„è½´æŒ‡å®šä¸ºåŠ¨æ€ï¼ˆ<font color='green'>å³ä»…åœ¨è¿è¡Œæ—¶çŸ¥é“</font>ï¼‰ï¼Œè¯·å°†`dynamic_axes`è®¾ç½®ä¸ºä¸€ä¸ªå…·æœ‰ä»¥ä¸‹ç»“æ„çš„å­—å…¸ï¼š
> - **KEYï¼ˆstrï¼‰**ï¼šè¾“å…¥æˆ–è¾“å‡ºçš„åç§°ã€‚æ¯ä¸ªåç§°è¿˜å¿…é¡»åœ¨ `input_names` æˆ– `output_names` ä¸­æä¾›ã€‚
> - **VALUEï¼ˆdictæˆ–listï¼‰**ï¼šå¦‚æœæ˜¯å­—å…¸ï¼Œåˆ™é”®æ˜¯è½´ç´¢å¼•ï¼Œå€¼æ˜¯è½´åç§°ã€‚å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåˆ™æ¯ä¸ªå…ƒç´ æ˜¯è½´ç´¢å¼•ã€‚

ä¸‹é¢æˆ‘ä»¬ç”¨ä¸€ä¸‹è¿™ä¸ªå‚æ•°ï¼š

```python
import torch
from torchvision import models
import onnx


device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"æ­£åœ¨ä½¿ç”¨çš„è®¾å¤‡: {device}")

# åˆ›å»ºä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹
model = models.resnet18(pretrained=True)  # ImageNet é¢„è®­ç»ƒæƒé‡
model = model.eval().to(device)

# æ„å»ºä¸€ä¸ªè¾“å…¥
dummy_input = torch.randn(size=[1, 3, 256, 256]).to(device)  # [N, B, H, W]

# è®©æ¨¡å‹æ¨ç†
output = model(dummy_input)
print(f"output.shape: {output.shape}\n")

# ------ ä½¿ç”¨ PyTorch è‡ªå¸¦çš„å‡½æ•°å°†æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼
onnx_save_path = 'ONNX/saves/resnet18_imagenet-with_dynamic_axis.onnx'  # å¯¼å‡ºçš„ONNXæ¨¡å‹è·¯å¾„ 
with torch.no_grad():
    torch.onnx.export(
        model=model,                            # è¦è½¬æ¢çš„æ¨¡å‹
        args=dummy_input,                       # æ¨¡å‹çš„è¾“å…¥
        f=onnx_save_path,                       # å¯¼å‡ºçš„ONNXæ¨¡å‹è·¯å¾„ 
        input_names=['input'],                  # ONNXæ¨¡å‹è¾“å…¥çš„åå­—(è‡ªå®šä¹‰)
        output_names=['output'],                # ONNXæ¨¡å‹è¾“å‡ºçš„åå­—(è‡ªå®šä¹‰)
        opset_version=11,                       # Opsetç®—å­é›†åˆçš„ç‰ˆæœ¬ï¼ˆé»˜è®¤ä¸º17ï¼‰
        dynamic_axes={                          # ä¿®æ”¹æŸä¸€ä¸ªç»´åº¦ä¸ºåŠ¨æ€
            'input': {0: 'B', 2: 'H', 3: 'W'}   # å°†åŸæœ¬çš„ [1, 3, 256, 256] ä¿®æ”¹ä¸º [B, 3, H, W]
        }
    )
    
print(f"ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼Œè·¯å¾„ä¸ºï¼š{onnx_save_path}\n")

# ------ éªŒè¯å¯¼å‡ºçš„æ¨¡å‹æ˜¯å¦æ­£ç¡®
# è¯»å–å¯¼å‡ºçš„æ¨¡å‹
onnx_model = onnx.load(onnx_save_path)

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£å¸¸
onnx.checker.check_model(onnx_model)

print(f"æ¨¡å‹å¯¼å‡ºæ­£å¸¸!")
```

```
æ­£åœ¨ä½¿ç”¨çš„è®¾å¤‡: cpu
output.shape: torch.Size([1, 1000])

ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼Œè·¯å¾„ä¸ºï¼šONNX/saves/resnet18_imagenet-with_dynamic_axis.onnx

æ¨¡å‹å¯¼å‡ºæ­£å¸¸!
```

æ­¤æ—¶æˆ‘ä»¬å†ç”¨ Netron çœ‹ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-25-11-55-28.png
    width=80%>
</div>

å¯ä»¥çœ‹åˆ°ï¼Œè¾“å…¥çš„ Batchã€Heightã€Width å‡å˜ä¸ºäº†åŠ¨æ€ç»´åº¦ï¼Œ<font color='green'>å³åªæœ‰å½“æ¨¡å‹è¿è¡Œçš„æ—¶å€™æ‰çŸ¥é“è¾“å…¥çš„è¿™ä¸‰ä¸ªç»´åº¦å…·ä½“çš„å€¼</font>ã€‚

## 1.8 ONNX Runtime éƒ¨ç½²ï¼šæ¨ç†å•å¼ å›¾ç‰‡

```python
import os
import random
import numpy as np
from PIL import Image
import onnxruntime
from torchvision import transforms
import torch
import torch.nn.functional as F
import pandas as pd


# ==================================== åŠ è½½ ONNX æ¨¡å‹ï¼Œåˆ›å»ºæ¨ç†ä¼šè¯ ==================================== 
ort_session = onnxruntime.InferenceSession(path_or_bytes='ONNX/saves/resnet18_imagenet-fix_axis.onnx')  # ort -> onnxruntime

# ==================================== æ¨¡å‹å†·å¯åŠ¨ ==================================== 
dummy_input = np.random.randn(1, 3, 256, 256).astype(np.float32)
ort_inputs = {'input': dummy_input}
ort_output = ort_session.run(output_names=['output'], input_feed=ort_inputs)[0]  # è¾“å‡ºè¢«[]åŒ…å›´äº†ï¼Œæ‰€ä»¥éœ€è¦å–å‡ºæ¥
print(f"æ¨¡å‹å†·å¯åŠ¨å®Œæ¯•! å…¶æ¨ç†ç»“æœçš„shapeä¸º: {ort_output.shape}")

# ==================================== åŠ è½½çœŸæ­£çš„å›¾åƒ ==================================== 
images_folder = 'Datasets/Web/images'
images_list = [os.path.join(images_folder, img) for img in os.listdir(images_folder) if img.lower().endswith(('.jpg', '.png', '.webp'))]

img_path = images_list[random.randint(0, len(images_list)-1)]
img = Image.open(fp=img_path)

# ==================================== å›¾åƒé¢„å¤„ç† ==================================== 
# å®šä¹‰é¢„å¤„ç†å‡½æ•°
img_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(256),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],  # imagenetä¸“ç”¨
        std=[0.229, 0.224, 0.225]),  # imagenetä¸“ç”¨
])

# å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
input_img = img_transform(img)
print(f"input_img.type: {type(input_img)}")
print(f"input_img.shape: {input_img.shape}")

# ä¸ºå›¾ç‰‡æ·»åŠ batchç»´åº¦
input_img = torch.unsqueeze(input_img, dim=0)

# ==================================== ONNXæ¨¡å‹æ¨ç† ==================================== 
# å› ä¸ºONNXRuntimeéœ€è¦çš„æ˜¯numpyè€Œétorchçš„tensor, æ‰€ä»¥å°†å…¶è½¬æ¢ä¸ºnumpy
input_img = input_img.numpy()
print(f"input_img.type: {type(input_img)}")
print(f"input_img.shape: {input_img.shape}")

# æ¨¡å‹æ¨ç†å›¾ç‰‡
ort_inputs = {'input': input_img, }
ort_results = ort_session.run(output_names=['output'], input_feed=ort_inputs)[0]  # å¾—åˆ° 1000 ä¸ªç±»åˆ«çš„åˆ†æ•°
print(f"æ¨¡å‹æ¨ç†å®Œæ¯•! æ­¤æ—¶ç»“æœçš„shapeä¸ºï¼š{ort_results.shape}")

# ==================================== åå¤„ç† ==================================== 
# ä½¿ç”¨ softmax å‡½æ•°å°†åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡
ort_results_softmax = F.softmax(input=torch.from_numpy(ort_results), dim=1)
print(f"ç»è¿‡softmaxåçš„è¾“å‡ºçš„shapeä¸ºï¼š{ort_results_softmax.shape}")

# å–æ¦‚ç‡æœ€å¤§çš„å‰ n ä¸ªç»“æœ
n = 3
top_n = torch.topk(input=ort_results_softmax, k=n)

probs = top_n.values.numpy()[0]
indices = top_n.indices.numpy()[0]

print(f"ç½®ä¿¡åº¦æœ€é«˜çš„å‰{n}ä¸ªç»“æœä¸ºï¼š\t{probs}\n"
      f"å¯¹åº”çš„ç±»åˆ«ç´¢å¼•ä¸ºï¼š\t\t{indices}")

# ==================================== æ˜¾ç¤ºç±»åˆ« ==================================== 
df = pd.read_csv('Datasets/imagenet_classes_indices.csv')

idx2labels = {}
for idx, row in df.iterrows():
    # idx2labels[row['ID']] = row['class']  # è‹±æ–‡æ ‡ç­¾
    idx2labels[row['ID']] = row['Chinese']  # ä¸­æ–‡æ ‡ç­¾

print(f"=============== æ¨ç†ç»“æœ ===============\n"
      f"å›¾ç‰‡è·¯å¾„: {img_path}")
for i, (class_prob, idx) in enumerate(zip(probs, indices)):
    class_name = idx2labels[idx]
    text = f"\tNo.{i}: {class_name:<30} --> {class_prob:>.4f}"
    print(text)
```

```
æ¨¡å‹å†·å¯åŠ¨å®Œæ¯•! å…¶æ¨ç†ç»“æœçš„shapeä¸º: (1, 1000)
input_img.type: <class 'torch.Tensor'>
input_img.shape: torch.Size([3, 256, 256])
input_img.type: <class 'numpy.ndarray'>
input_img.shape: (1, 3, 256, 256)
æ¨¡å‹æ¨ç†å®Œæ¯•! æ­¤æ—¶ç»“æœçš„shapeä¸ºï¼š(1, 1000)
ç»è¿‡softmaxåçš„è¾“å‡ºçš„shapeä¸ºï¼štorch.Size([1, 1000])
ç½®ä¿¡åº¦æœ€é«˜çš„å‰3ä¸ªç»“æœä¸ºï¼š       [9.9472505e-01 7.4335985e-04 5.2123831e-04]
å¯¹åº”çš„ç±»åˆ«ç´¢å¼•ä¸ºï¼š              [673 662 487]
=============== æ¨ç†ç»“æœ ===============
å›¾ç‰‡è·¯å¾„: Datasets/Web/images/mouse.jpg
        No.0: é¼ æ ‡,ç”µè„‘é¼ æ ‡                        --> 0.9947
        No.1: è°ƒåˆ¶è§£è°ƒå™¨                          --> 0.0007
        No.2: ç§»åŠ¨ç”µè¯,æ‰‹æœº                        --> 0.0005
```

> ğŸ’¡ å›¾ç‰‡é“¾æ¥ï¼š[Web/images](https://github.com/Le0v1n/Learning-Notebook-Codes/tree/main/Datasets/Web/images)
> ğŸ’¡ ImageNet ç±»åˆ«æ–‡ä»¶é“¾æ¥ï¼š[imagenet_classes_indices.csv](https://github.com/Le0v1n/Learning-Notebook-Codes/tree/main/Datasets/imagenet_classes_indices.csv)

## 1.9 ONNX Runtime å’Œ PyTorch é€Ÿåº¦å¯¹æ¯”

1. ä¸åŒå°ºåº¦ä¸‹å•å¼ å›¾ç‰‡æ¨ç† --> [å¯¹æ¯”ä»£ç é“¾æ¥]()
2. ä¸åŒå°ºåº¦ä¸‹å¤šå¼ å›¾ç‰‡æ¨ç† --> [å¯¹æ¯”ä»£ç é“¾æ¥]()

**å®éªŒç¯å¢ƒ**ï¼š
- CPUï¼šIntel i7-7700 @ 3.60GHz
- Memory: 8 x 2 = 16GB
- Disk: SSD
- OS: Windows 10 (WSL)
- Device: CPU
- æ¨¡å‹æ¨ç†æ¬¡æ•°: 50

**å®éªŒç»“æœ**

|Input Shape|ONNX(å›ºå®šç»´åº¦)|ONNX(å›ºå®šç»´åº¦+ç®€åŒ–)|ONNX(åŠ¨æ€ç»´åº¦)|ONNX(åŠ¨æ€ç»´åº¦+ç®€åŒ–)|PyTorch|
|:-|:-|:-|:-|:-|:-|
|[1, 3, 32, 32]      |0.0658s|0.0679s|0.0669s|0.0667s|0.0740s |
|[1, 3, 64, 64]      |0.0683s|0.0701s|0.0684s|0.0694s|0.0734s |
|[1, 3, 128, 128]    |0.0747s|0.0728s|0.0732s|0.0755s|0.0784s |
|[1, 3, 256, 256]    |0.0893s|0.0901s|0.0883s|0.0901s|0.1070s |
|[1, 3, 512, 512]    |0.1484s|0.1486s|0.1544s|0.1485s|0.1906s |
|[1, 3, 640, 640]    |0.1983s|0.1947s|0.1946s|0.1935s|0.2561s |
|[1, 3, 768, 768]    |0.2529s|0.2488s|0.2535s|0.2555s|0.3303s |
|[1, 3, 1024, 1024]  |0.3888s|0.3959s|0.4008s|0.3996s|0.5216s |
|[18, 3, 32, 32]     |0.3252s|0.3255s|0.3268s|0.3262s|0.3357s |
|[18, 3, 64, 64]     |0.3468s|0.3509s|0.3504s|0.3554s|0.3653s |
|[18, 3, 128, 128]   |0.4244s|0.4295s|0.4297s|0.4269s|0.4806s |
|[18, 3, 256, 256]   |0.6910s|0.6859s|0.7005s|0.7020s|0.8770s |
|[18, 3, 512, 512]   |1.7164s|1.7125s|1.7420s|1.7531s|3.6240s |
|[18, 3, 640, 640]   |2.4357s|2.4594s|2.4750s|2.5205s|4.3787s |
|[18, 3, 768, 768]   |3.5806s|3.5368s|3.6693s|3.6110s|10.3582s|
|[18, 3, 1024, 1024] |6.0836s|6.1163s|6.2694s|6.3470s|OOM     |

**ç”»å›¾ç»“æœ**

> âš ï¸ åœ¨ `[18, 3, 1024, 1024]` æ—¶ï¼ŒPyTorch å› ä¸ºå†…å­˜ä¸è¶³å¯¼è‡´æ— æ³•å®Œæˆï¼Œè¿™é‡Œç”¨çš„æ˜¯ `[18, 3, 768, 768]` çš„æ•°æ®

<div align=center>
    <img src=./imgs_markdown/speed_comparison-full.jpg
    width=100%>
</div>

<div align=center>
    <img src=./imgs_markdown/speed_comparison-single_batch.jpg
    width=100%>
</div>

<div align=center>
    <img src=./imgs_markdown/speed_comparison-multi_batch.jpg
    width=100%>
</div>

å¯ä»¥çœ‹åˆ°ï¼š
- é™æ€ç»´åº¦å’ŒåŠ¨æ€ç»´åº¦ç›¸å·®ä¸å¤§
- åœ¨ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†æ—¶ï¼ŒPyTorch æ¯” ONNX è¦æ…¢ï¼ˆå³ä¾¿å½“å›¾ç‰‡å°ºå¯¸æ¯”è¾ƒå°çš„æ—¶å€™ï¼‰
- å› ä¸º PyTorch æ²¡æœ‰å®Œæˆ `[18, 3, 1024, 1024]` çš„ç»“æœï¼Œå¯ä»¥è¯´æ˜ PyTorch åœ¨æ¨ç†æ—¶éœ€è¦çš„èµ„æºæ¯” ONNX è¦å¤š

































# çŸ¥è¯†æ¥æº

1. [å›¾åƒåˆ†ç±»æ¨¡å‹éƒ¨ç½²-Pytorchè½¬ONNX](https://www.bilibili.com/video/BV1cM4y187Xc)