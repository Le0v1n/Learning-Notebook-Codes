# 1. ONNX ç®€ä»‹

## 1.1 ä»€ä¹ˆæ˜¯ ONNX

å¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢ ONNXï¼ˆOpen Neural Network Exchangeï¼‰æ˜¯ä¸€å¥—è¡¨ç¤ºæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„å¼€æ”¾æ ¼å¼ï¼Œç”±å¾®è½¯å’Œ Facebook äº 2017 æ¨å‡ºï¼Œç„¶åè¿…é€Ÿå¾—åˆ°äº†å„å¤§å‚å•†å’Œæ¡†æ¶çš„æ”¯æŒã€‚é€šè¿‡çŸ­çŸ­å‡ å¹´çš„å‘å±•ï¼Œå·²ç»æˆä¸ºè¡¨ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å®é™…æ ‡å‡†ï¼Œå¹¶ä¸”é€šè¿‡ ONNX-MLï¼Œå¯ä»¥æ”¯æŒä¼ ç»Ÿéç¥ç»ç½‘ç»œæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¤§æœ‰ä¸€ç»Ÿæ•´ä¸ª AI æ¨¡å‹äº¤æ¢æ ‡å‡†ã€‚

## 1.2 ONNX çš„æ ¸å¿ƒæ€æƒ³

ONNX å®šä¹‰äº†ä¸€ç»„<font color='green'>ä¸ç¯å¢ƒå’Œå¹³å°æ— å…³çš„æ ‡å‡†æ ¼å¼</font>ï¼Œä¸º AI æ¨¡å‹çš„äº’æ“ä½œæ€§æä¾›äº†åŸºç¡€ï¼Œä½¿ AI æ¨¡å‹å¯ä»¥åœ¨ä¸åŒæ¡†æ¶å’Œç¯å¢ƒä¸‹äº¤äº’ä½¿ç”¨ã€‚ç¡¬ä»¶å’Œè½¯ä»¶å‚å•†å¯ä»¥åŸºäº ONNX æ ‡å‡†ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œè®©æ‰€æœ‰å…¼å®¹ ONNX æ ‡å‡†çš„æ¡†æ¶å—ç›Šã€‚ç›®å‰ï¼ŒONNX ä¸»è¦å…³æ³¨åœ¨æ¨¡å‹é¢„æµ‹æ–¹é¢ï¼ˆinferringï¼‰ï¼Œä½¿ç”¨ä¸åŒæ¡†æ¶è®­ç»ƒçš„æ¨¡å‹ï¼Œè½¬åŒ–ä¸º ONNX æ ¼å¼åï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„éƒ¨ç½²åœ¨å…¼å®¹ ONNX çš„è¿è¡Œç¯å¢ƒä¸­ã€‚

## 1.3 ONNX çš„å­˜å‚¨æ–¹å¼ â€”â€” ProtoBuf

ONNX ä½¿ç”¨çš„æ˜¯ Protobuf è¿™ä¸ª**åºåˆ—åŒ–æ•°æ®ç»“æ„**å»å­˜å‚¨ç¥ç»ç½‘ç»œçš„æƒé‡ä¿¡æ¯ã€‚

> Protobuf æ˜¯ä¸€ç§è½»ä¾¿é«˜æ•ˆçš„ç»“æ„åŒ–æ•°æ®å­˜å‚¨æ ¼å¼ï¼Œå¯ä»¥ç”¨äºç»“æ„åŒ–æ•°æ®ä¸²è¡ŒåŒ–ï¼Œæˆ–è€…è¯´åºåˆ—åŒ–ã€‚å®ƒå¾ˆé€‚åˆåšæ•°æ®å­˜å‚¨æˆ–æ•°æ®äº¤æ¢æ ¼å¼ã€‚å¯ç”¨äºé€šè®¯åè®®ã€æ•°æ®å­˜å‚¨ç­‰é¢†åŸŸçš„è¯­è¨€æ— å…³ã€å¹³å°æ— å…³ã€å¯æ‰©å±•çš„åºåˆ—åŒ–ç»“æ„æ•°æ®æ ¼å¼ã€‚ç›®å‰æä¾›äº† C++ã€Javaã€Python ä¸‰ç§è¯­è¨€çš„ APIã€‚

## 1.4 ONNX ç»„æˆéƒ¨åˆ† {##Opset}

ONNX è§„èŒƒç”±ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ç»„æˆï¼š

1. **ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—å›¾æ¨¡å‹**ï¼šå®šä¹‰äº†é€šç”¨çš„è®¡ç®—å›¾ä¸­é—´è¡¨ç¤ºæ³•ï¼ˆIntermediate Representationï¼‰ã€‚
2. **opset**ï¼š`ai.onnx` å’Œ `ai.onnx.ml`ã€‚
   + `ai.onnx` æ˜¯é»˜è®¤çš„æ“ä½œç¬¦é›†ï¼Œä¸»è¦é’ˆå¯¹ç¥ç»ç½‘ç»œæ¨¡å‹
   + `ai.onnx.ml` ä¸»è¦é€‚ç”¨äºä¼ ç»Ÿéç¥ç»ç½‘ç»œæœºå™¨å­¦ä¹ æ¨¡å‹
3. **æ ‡å‡†æ•°æ®ç±»å‹**ï¼šåŒ…æ‹¬å¼ é‡ï¼ˆtensorsï¼‰ã€åºåˆ—ï¼ˆsequencesï¼‰å’Œæ˜ å°„ï¼ˆmapsï¼‰ã€‚

> opsetï¼šoperator setï¼Œå¯ä»¥ç¿»è¯‘ä¸ºç®—å­é›†åˆã€‚

ç›®å‰ï¼ŒONNX è§„èŒƒæœ‰ä¸¤ä¸ªå®˜æ–¹å˜ä½“ï¼Œä¸»è¦åŒºåˆ«åœ¨ä¸æ”¯æŒçš„ç±»å‹å’Œé»˜è®¤çš„æ“ä½œç¬¦é›†ï¼ˆopsetï¼‰ã€‚ONNX ç¥ç»ç½‘ç»œå˜ä½“åªä½¿ç”¨å¼ é‡ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºï¼›è€Œä½œä¸ºæ”¯æŒä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹çš„ ONNX-MLï¼Œè¿˜å¯ä»¥è¯†åˆ«åºåˆ—å’Œæ˜ å°„ï¼ŒONNX-ML ä¸ºæ”¯æŒéç¥ç»ç½‘ç»œç®—æ³•æ‰©å±•äº† ONNX æ“ä½œç¬¦é›†ã€‚

## 1.5 ONNX ä¸»è¦åè®®

+ **ModelProtoï¼ˆæ¨¡å‹åè®®ï¼‰ï¼š** å®šä¹‰æ•´ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹çš„ç»“æ„ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„å…ƒæ•°æ®ã€å›¾ç»“æ„ä»¥åŠå…¶ä»–ç›¸å…³ä¿¡æ¯ã€‚
+ **GraphProtoï¼ˆå›¾åè®®ï¼‰ï¼š** æè¿°ç¥ç»ç½‘ç»œçš„è®¡ç®—å›¾ç»“æ„ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹ï¼ˆNodeProtoï¼‰ã€è¾¹ï¼ˆè¿æ¥èŠ‚ç‚¹çš„è¾¹ï¼‰ç­‰ä¿¡æ¯ã€‚
+ **NodeProtoï¼ˆèŠ‚ç‚¹åè®®ï¼‰ï¼š** ç”¨äºå®šä¹‰è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªæ“ä½œæˆ–è®¡ç®—æ­¥éª¤ï¼ŒåŒ…æ‹¬è¯¥èŠ‚ç‚¹çš„è¾“å…¥ã€è¾“å‡ºã€æ“ä½œç±»å‹ç­‰ä¿¡æ¯ã€‚
+ **ValueInfoProtoï¼ˆå€¼ä¿¡æ¯åè®®ï¼‰ï¼š** ç”¨äºæè¿°è®¡ç®—å›¾ä¸­çš„å€¼ï¼ˆå¦‚å¼ é‡ï¼‰çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬åç§°ã€æ•°æ®ç±»å‹ã€å½¢çŠ¶ç­‰ã€‚
+ **TensorProtoï¼ˆå¼ é‡åè®®ï¼‰ï¼š** ç”¨äºæè¿°ç¥ç»ç½‘ç»œä¸­çš„å¼ é‡ï¼ŒåŒ…æ‹¬å¼ é‡çš„æ•°æ®ã€å½¢çŠ¶ã€æ•°æ®ç±»å‹ç­‰ä¿¡æ¯ã€‚
+ **AttributeProtoï¼ˆå±æ€§åè®®ï¼‰ï¼š** ç”¨äºè¡¨ç¤ºèŠ‚ç‚¹æˆ–å›¾çš„å±æ€§ï¼Œè¿™äº›å±æ€§å¯èƒ½åŒ…å«æ“ä½œçš„å‚æ•°ã€è¶…å‚æ•°ç­‰ä¿¡æ¯ã€‚

## 1.6 ONNX çš„ç²’åº¦ä¸è¿è¡Œé€Ÿåº¦çš„å…³ç³»

ä¸»æµçš„æ¨¡å‹éƒ¨ç½²æœ‰ä¸¤ç§è·¯å¾„ï¼Œä»¥ TensorRT ä¸ºä¾‹ï¼Œä¸€ç§æ˜¯ `PyTorch->ONNX->TensorRT`ï¼Œå¦ä¸€ç§æ˜¯ `PyTorch->Caffe->TensorRT`ï¼Œä¸¤ç§è½¬æ¢è·¯å¾„çš„å¯¹æ¯”å¦‚ä¸‹ï¼š

|å±æ€§|ONNX|Caffe|
|:-|:-:|:-:|
|çµæ´»æ€§|<font color='green'>é«˜|<font color='red'>ä½|
|op ç²’åº¦|<font color='green'>ç»†ç²’åº¦|<font color='red'>ç²—ç²’åº¦|
|æ¡ä»¶åˆ†æ”¯|<font color='red'>ä¸æ”¯æŒ|<font color='green'>æ”¯æŒ|
|åŠ¨æ€ shape|<font color='green'>æ”¯æŒ|<font color='red'>ä¸æ”¯æŒ|

ä¸Šé¢çš„è¡¨åˆ—äº† ONNX å’Œ Caffe çš„å‡ ç‚¹åŒºåˆ«ï¼Œå…¶ä¸­æœ€é‡è¦çš„åŒºåˆ«å°±æ˜¯ op çš„ç²’åº¦ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœå¯¹ Bert çš„ Attention å±‚åšè½¬æ¢ï¼ŒONNX ä¼šæŠŠå®ƒå˜æˆ `MatMul, Scale, SoftMax` çš„ç»„åˆï¼Œè€Œ Caffe å¯èƒ½ä¼šç›´æ¥ç”Ÿæˆä¸€ä¸ªå«åš `Multi-Head Attention` çš„å±‚ï¼ŒåŒæ—¶å‘Šè¯‰ CUDA å·¥ç¨‹å¸ˆï¼šâ€œä½ å»ç»™æˆ‘å†™ä¸€ä¸ªå¤§ kernelâ€œï¼ˆå¾ˆæ€€ç–‘å‘å±•åˆ°æœ€åä¼šä¸ä¼šæŠŠ ResNet50 éƒ½å˜æˆä¸€ä¸ªå±‚ :joy:ï¼‰

å› æ­¤å¦‚æœæŸå¤©ä¸€ä¸ªç ”ç©¶å‘˜æäº†ä¸€ä¸ªæ–°çš„ SOTA çš„ opï¼Œå¾ˆå¯èƒ½å®ƒç›´æ¥å°±å¯ä»¥è¢«è½¬æ¢æˆ ONNXï¼ˆå¦‚æœè¿™ä¸ª op åœ¨ PyTorch çš„å®ç°å…¨éƒ½æ˜¯ç”¨ Aten çš„åº“æ‹¼æ¥çš„ï¼‰ï¼Œä½†æ˜¯å¯¹äº Caffe çš„å·¥ç¨‹å¸ˆï¼Œéœ€è¦é‡æ–°å†™ä¸€ä¸ª kernelã€‚

> ATen æ˜¯ PyTorch å†…ç½®çš„ C++ å¼ é‡è®¡ç®—åº“ï¼ŒPyTorch ç®—å­åœ¨åº•å±‚ç»å¤§å¤šæ•°è®¡ç®—éƒ½æ˜¯ç”¨ ATen å®ç°çš„ã€‚

ç»†ç²’åº¦ op çš„å¥½å¤„å°±æ˜¯éå¸¸çµæ´»ï¼Œ<font color='red'>åå¤„å°±æ˜¯é€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢</font>ã€‚è¿™å‡ å¹´æœ‰å¾ˆå¤šå·¥ä½œéƒ½æ˜¯åœ¨åš op fushionï¼ˆæ¯”å¦‚æŠŠå·ç§¯å’Œå®ƒåé¢çš„ ReLU åˆåˆ°ä¸€èµ·ç®—ï¼‰ï¼Œä¹Ÿå°±æ˜¯æŠŠå° op æ‹¼æˆå¤§ opã€‚

TensorRT æ˜¯ NVIDIA æ¨å‡ºçš„éƒ¨ç½²æ¡†æ¶ï¼Œè‡ªç„¶æ€§èƒ½æ˜¯é¦–è¦è€ƒé‡çš„ï¼Œå› æ­¤ Layer çš„ç²’åº¦éƒ½å¾ˆç²—ï¼ˆç²—ç²’åº¦ä»£è¡¨ç€æœ‰å¤§ opï¼Œä»è€Œé€Ÿåº¦ä¼šå¿«ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹æŠŠ Caffe è½¬æ¢è¿‡å»æœ‰å¤©ç„¶çš„ä¼˜åŠ¿ã€‚

é™¤æ­¤ä¹‹å¤–ç²—ç²’åº¦ä¹Ÿå¯ä»¥è§£å†³åˆ†æ”¯çš„é—®é¢˜ã€‚TensorRT çœ¼é‡Œçš„ç¥ç»ç½‘ç»œå°±æ˜¯ä¸€ä¸ªå•çº¯çš„ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ï¼šç»™å®šå›ºå®š shape çš„è¾“å…¥ï¼Œæ‰§è¡Œç›¸åŒçš„è¿ç®—ï¼Œå¾—åˆ°å›ºå®š shape çš„è¾“å‡ºã€‚

> åœ¨ [è¯„ä¼°ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠ‚ç‚¹](##è¯„ä¼°ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠ‚ç‚¹) ä¸­æœ‰ç›¸å…³çš„å®éªŒã€‚é€šè¿‡å®éªŒæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼Œå°†å¤šä¸ªç®—å­åˆåœ¨ä¸€èµ·ç§°ä¹‹ä¸º fusionï¼Œè¿™ä¸ª fusion æ˜¯å¯ä»¥å¿«åŠ æ¨¡å‹é€Ÿåº¦çš„ã€‚

# 2. ONNX ç¤ºä¾‹

## 2.1 çº¿æ€§å›å½’ï¼ˆLinear Regressionï¼‰{##example1}

çº¿æ€§å›å½’æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€ç®€å•çš„æ¨¡å‹ï¼Œç”±ä»¥ä¸‹è¡¨è¾¾å¼æè¿°ï¼š

$$
Y = XA + B
$$

æˆ‘ä»¬å¯ä»¥å°†å…¶çœ‹ä½œæ˜¯ä¸‰ä¸ªå˜é‡ $Y = f(X, A, B)$ åˆ†è§£æˆ `y = Add(MatMul(X, A), B)`ã€‚è¿™æ˜¯æˆ‘ä»¬éœ€è¦ç”¨ ONNX è¿ç®—ç¬¦è¡¨ç¤ºçš„å†…å®¹ã€‚é¦–å…ˆæ˜¯ä½¿ç”¨ ONNX è¿ç®—ç¬¦å®ç°ä¸€ä¸ªå‡½æ•°ã€‚ONNX æ˜¯å¼ºç±»å‹çš„ï¼Œ<font color='red'>å¿…é¡»ä¸ºå‡½æ•°çš„è¾“å…¥å’Œè¾“å‡ºå®šä¹‰å½¢çŠ¶å’Œç±»å‹</font>ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ**æˆ‘ä»¬éœ€è¦å››ä¸ªå‡½æ•°æ¥æ„å»ºå›¾**ï¼Œå…¶ä¸­åŒ…æ‹¬ `make` å‡½æ•°ï¼š

+ `make_tensor_value_info`ï¼šæ ¹æ®å…¶å½¢çŠ¶å’Œç±»å‹å£°æ˜å˜é‡ï¼ˆè¾“å…¥æˆ–è¾“å‡ºï¼‰
+ `make_node`ï¼šåˆ›å»ºç”±æ“ä½œï¼ˆop ç±»å‹ï¼‰ã€å…¶è¾“å…¥å’Œè¾“å‡ºå®šä¹‰çš„èŠ‚ç‚¹
+ `make_graph`ï¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰å‰ä¸¤ä¸ªå‡½æ•°åˆ›å»ºçš„å¯¹è±¡çš„ ONNX å›¾çš„å‡½æ•°
+ `make_model`ï¼šæœ€åä¸€ä¸ªå‡½æ•°ï¼Œå°†å›¾å’Œé™„åŠ å…ƒæ•°æ®åˆå¹¶

åœ¨æ•´ä¸ªåˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºå›¾çš„æ¯ä¸ªèŠ‚ç‚¹çš„æ¯ä¸ªè¾“å…¥å’Œè¾“å‡ºèµ‹äºˆä¸€ä¸ªåç§°ã€‚å›¾çš„è¾“å…¥å’Œè¾“å‡ºç”± ONNX å¯¹è±¡å®šä¹‰ï¼Œä½¿ç”¨å­—ç¬¦ä¸²å¼•ç”¨ä¸­é—´ç»“æœã€‚ä¸‹é¢æ˜¯ç¤ºä¾‹ä»£ç ã€‚

```python
import onnx
from onnx import TensorProto
from onnx.helper import (make_model, make_node, make_graph, 
                         make_tensor, make_tensor_value_info)
from onnx.checker import check_model


# -------------------------- inputs --------------------------
# 'X'æ˜¯åç§°ï¼ŒTensorProto.FLOATæ˜¯ç±»å‹ï¼Œ[None, None]æ˜¯å½¢çŠ¶ã€‚
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])

# -------------------------- outputs(å½¢çŠ¶æœªå®šä¹‰) --------------------------
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

# -------------------------- nodes --------------------------
# å®ƒåˆ›å»ºä¸€ä¸ªç”±è¿ç®—ç¬¦ç±»å‹MatMulå®šä¹‰çš„èŠ‚ç‚¹ï¼Œ'X'ã€'A'æ˜¯èŠ‚ç‚¹çš„è¾“å…¥ï¼Œ'XA'æ˜¯è¾“å‡ºã€‚
node1 = make_node(op_type='MatMul', 
                  inputs=['X', 'A'],
                  outputs=['XA'])

node2 = make_node(op_type='Add', 
                  inputs=['XA', 'B'],
                  outputs=['Y'])

# -------------------------- graph --------------------------
# ä»èŠ‚ç‚¹åˆ°å›¾ï¼Œå›¾æ˜¯ç”±èŠ‚ç‚¹åˆ—è¡¨ã€è¾“å…¥åˆ—è¡¨ã€è¾“å‡ºåˆ—è¡¨å’Œåç§°æ„å»ºçš„ã€‚
graph = make_graph(nodes=[node1, node2],  # èŠ‚ç‚¹
                   name='lr',  # åç§°
                   inputs=[X, A, B],  # è¾“å…¥èŠ‚ç‚¹
                   outputs=[Y])  # è¾“å‡ºèŠ‚ç‚¹

# -------------------------- model --------------------------
# ONNXå›¾ï¼Œè¿™ç§æƒ…å†µä¸‹æ²¡æœ‰å…ƒæ•°æ®ã€‚
onnx_model = make_model(graph=graph)

# è®©æˆ‘ä»¬æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸€è‡´ï¼Œè¿™ä¸ªå‡½æ•°åœ¨â€œChecker and Shape Inferenceâ€éƒ¨åˆ†æœ‰æè¿°ã€‚
check_model(model=onnx_model)  # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œå°†å¼•å‘å¼‚å¸¸

print(onnx_model)

# å°†è¿™ä¸ªæ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°
onnx.save_model(onnx_model, 'ONNX/saves/linear_regression.onnx')
```

æ¨¡å‹æ‰“å°ç»“æœï¼š

```
ir_version: 9
opset_import {
  version: 20
}
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
```

> âš ï¸ `check_model()` è¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸€ç›´ï¼Œå®ƒ<font color='red'>æ²¡æœ‰è¿”å›å€¼</font>ï¼Œå¦‚æœæ¨¡å‹æœ‰é—®é¢˜ï¼Œé‚£ä¹ˆè¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨æŠ›å‡ºå¼‚å¸¸ã€‚

æˆ‘ä»¬ç”¨ Netron çœ‹ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹ï¼š

<div align=center>
  <div align=half>
      <img src=./imgs_markdown/2024-01-23-10-06-01.png
      width=30%>
      <img src=./imgs_markdown/2024-01-23-10-06-26.png
      width=50%>
  </div>
</div>

## 2.2 æŸ¥çœ‹å¯¹è±¡çš„å­—æ®µ -> æ£€æŸ¥ ONNX

ç©ºå½¢çŠ¶ï¼ˆ`None`ï¼‰è¡¨ç¤ºä»»æ„å½¢çŠ¶ï¼Œå½¢çŠ¶å®šä¹‰ä¸º `[None, None]` è¡¨ç¤ºæ­¤å¯¹è±¡æ˜¯ä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªç»´åº¦ä¸”æ²¡æœ‰è¿›ä¸€æ­¥ç²¾ç¡®åº¦çš„å¼ é‡ã€‚è¿˜å¯ä»¥é€šè¿‡æŸ¥çœ‹å›¾ä¸­æ¯ä¸ªå¯¹è±¡çš„å­—æ®µæ¥æ£€æŸ¥ ONNX å›¾ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
import onnx
from onnx import TensorProto
from onnx.helper import (make_model, make_node, make_graph, 
                         make_tensor, make_tensor_value_info)
from onnx.checker import check_model


def shape2tuple(shape):
    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)


# -------------------------- inputs & outputs --------------------------
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

# -------------------------- nodes & graph --------------------------
node1 = make_node(op_type='MatMul', 
                  inputs=['X', 'A'],
                  outputs=['XA'])

node2 = make_node(op_type='Add', 
                  inputs=['XA', 'B'],
                  outputs=['Y'])

graph = make_graph(nodes=[node1, node2],  # èŠ‚ç‚¹
                   name='lr',  # åç§°
                   inputs=[X, A, B],  # è¾“å…¥èŠ‚ç‚¹
                   outputs=[Y])  # è¾“å‡ºèŠ‚ç‚¹

# -------------------------- model --------------------------
onnx_model = make_model(graph=graph)
check_model(model=onnx_model)  # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œå°†å¼•å‘å¼‚å¸¸

# -------------------------- Check: Inputs --------------------------
print(f"-------------------------- inputs --------------------------")
# print(onnx_model.graph.input)
"""
[name: "X"      
type {
  tensor_type { 
    elem_type: 1
    shape {     
      dim {     
      }
      dim {     
      }
    }
  }
}
, name: "A"     
type {
  tensor_type { 
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
, name: "B"
type {
  tensor_type {
    elem_type: 1
    shape {
      dim {
      }
      dim {
      }
    }
  }
}
]
"""

for obj in onnx_model.graph.input:
    print(f"name={obj.name!r} "
          f"dtype={obj.type.tensor_type.elem_type!r} "
          f"shape={shape2tuple(obj.type.tensor_type.shape)!r}")
    
# -------------------------- Check: Outputs --------------------------
print(f"------------------------- outputs -------------------------")
for obj in onnx_model.graph.output:
    print(f"name={obj.name!r} "
          f"dtype={obj.type.tensor_type.elem_type!r} "
          f"shape={shape2tuple(obj.type.tensor_type.shape)!r}")

# -------------------------- Check: Nodes --------------------------
print(f"-------------------------- nodes --------------------------")
for node in onnx_model.graph.node:
    print(f"name={node.name!r} "
          f"type={node.op_type!r} "
          f"input={node.input!r} "
          f"output={node.output!r}")
```

ç»“æœå¦‚ä¸‹ï¼š

```
-------------------------- inputs --------------------------
name='X' dtype=1 shape=(0, 0)
name='A' dtype=1 shape=(0, 0)
name='B' dtype=1 shape=(0, 0)
------------------------- outputs -------------------------
name='Y' dtype=1 shape=(0,)
-------------------------- nodes --------------------------
name='' type='MatMul' input=['X', 'A'] output=['XA']
name='' type='Add' input=['XA', 'B'] output=['Y']
```

> å’Œ `xml` å’Œ `json` ç±»ä¼¼

## 2.3 ONNX æ•°æ®ç±»å‹æŸ¥çœ‹å’Œä¸ Numpy æ•°æ®ç±»å‹çš„å…³ç³»

å¼ é‡ç±»å‹æ˜¯ä¸€ä¸ªæ•´æ•°ï¼ˆ= 1ï¼‰ã€‚è¾…åŠ©å‡½æ•° `onnx.helper.tensor_dtype_to_np_dtype()` å¯ä»¥ç”¨äºè·å–ä¸ numpy å¯¹åº”çš„æ•°æ®ç±»å‹ã€‚

```python
from onnx import TensorProto
from onnx.helper import tensor_dtype_to_np_dtype, \
                        tensor_dtype_to_string


np_dtype = tensor_dtype_to_np_dtype(TensorProto.FLOAT)
print(f"å°† ONNX çš„ [{tensor_dtype_to_string(TensorProto.FLOAT)}] æ•°æ®ç±»å‹è½¬æ¢ä¸º"
      f"Numpy çš„ [{np_dtype}] æ•°æ®ç±»å‹")
```

ç»“æœä¸ºï¼š

```
å°† ONNX çš„ [TensorProto.FLOAT] æ•°æ®ç±»å‹è½¬æ¢ä¸ºNumpy çš„ [float32] æ•°æ®ç±»å‹
```

## 2.4 åºåˆ—åŒ–

å‰é¢æˆ‘ä»¬è¯´äº†ï¼ŒONNX æ˜¯å»ºç«‹åœ¨ Protobuf ä¹‹ä¸Šçš„ã€‚å®ƒæ·»åŠ äº†æè¿°æœºå™¨å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„å®šä¹‰ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒONNX ç”¨äºåºåˆ—åŒ–æˆ–ååºåˆ—åŒ–æ¨¡å‹ã€‚æ¥ä¸‹æ¥å®ä¾‹æ“ä½œä¸€ä¸‹å¯¹æ•°æ®ï¼ˆå¦‚å¼ é‡ã€ç¨€ç–å¼ é‡ç­‰ï¼‰è¿›è¡Œåºåˆ—åŒ–å’Œååºåˆ—åŒ–çš„è¿‡ç¨‹ã€‚

### 2.4.1 æ¨¡å‹åºåˆ—åŒ–ï¼ˆä¿å­˜ï¼‰

ä¸ºäº†éƒ¨ç½²ï¼Œæ¨¡å‹éœ€è¦è¢«ä¿å­˜ã€‚ONNX åŸºäº protobufï¼Œå®ƒæœ€å°åŒ–äº†åœ¨ç£ç›˜ä¸Šä¿å­˜å›¾æ‰€éœ€çš„ç©ºé—´ã€‚ONNX ä¸­çš„æ¯ä¸ªå¯¹è±¡éƒ½å¯ä»¥ä½¿ç”¨ `SerializeToString` æ–¹æ³•è¿›è¡Œåºåˆ—åŒ–ã€‚æ•´ä¸ªæ¨¡å‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚

> âš ï¸ åœ¨ [2.1 çº¿æ€§å›å½’ï¼ˆLinear Regressionï¼‰](##example1) ä¸­æˆ‘ä»¬ä½¿ç”¨ `onnx.save()` è¿™ä¸ªå‡½æ•°å¯¹æˆ‘ä»¬åˆ›å»ºçš„ ONNX æ¨¡å‹è¿›è¡Œäº†ä¿å­˜ï¼Œè¿™é‡Œæˆ‘ä»¬æ¢å¯»ä¸€ä¸‹è¿™ä¸ªä¿å­˜æ˜¯å¦‚ä½•è¿›è¡Œçš„ã€‚

```python
from onnx import TensorProto
from onnx.helper import (make_model, make_node, make_graph, 
                         make_tensor, make_tensor_value_info)
from onnx.checker import check_model


def shape2tuple(shape):
    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)


# -------------------------- inputs & outputs --------------------------
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

# -------------------------- nodes & graph --------------------------
node1 = make_node(op_type='MatMul', 
                  inputs=['X', 'A'],
                  outputs=['XA'])

node2 = make_node(op_type='Add', 
                  inputs=['XA', 'B'],
                  outputs=['Y'])

graph = make_graph(nodes=[node1, node2],  # èŠ‚ç‚¹
                   name='lr',  # åç§°
                   inputs=[X, A, B],  # è¾“å…¥èŠ‚ç‚¹
                   outputs=[Y])  # è¾“å‡ºèŠ‚ç‚¹

# -------------------------- model --------------------------
onnx_model = make_model(graph=graph)
check_model(model=onnx_model)  # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œå°†å¼•å‘å¼‚å¸¸

# åºåˆ—åŒ–ä¿å­˜æ¨¡å‹
save_path = 'ONNX/saves/linear_regression-serialized.onnx'
with open(save_path, 'wb') as f:
  f.write(onnx_model.SerializeToString())

print(f"Serialized model has saved at {save_path}!")  
```

```
Serialized model has saved at ONNX/saves/linear_regression-serialized.onnx!
```

æˆ‘ä»¬ä½¿ç”¨ Netron æŸ¥çœ‹ä¸€ä¸‹ï¼Œå¹¶ä¸ä¹‹å‰ä½¿ç”¨ `onnx.save()` ä¿å­˜çš„å¯¹æ¯”ä¸€ä¸‹ï¼š

<div align=center>
  <div align=half>
      <img src=./imgs_markdown/2024-01-23-10-06-01.png
      width=25%>
      <img src=./imgs_markdown/2024-01-23-10-06-26.png
      width=25%>
  </div>
  <div align=half>
      <img src=./imgs_markdown/2024-01-23-10-50-40.png
      width=25%>
      <img src=./imgs_markdown/2024-01-23-10-50-46.png
      width=25%>
  </div>
</div>

å¯ä»¥çœ‹åˆ°ï¼Œä¸¤è€…æ˜¯ä¸€æ ·çš„ï¼ŒåŒæ—¶æˆ‘ä»¬ä¹Ÿé—®ä¸€ä¸‹ GPTï¼š

<kbd>GPT</kbd>ï¼šåœ¨ ONNX ä¸­ï¼Œ`onnx.save()` å’Œæ¨¡å‹åºåˆ—åŒ–ï¼ˆserializationï¼‰å®é™…ä¸Šæ˜¯ç›¸åŒçš„æ¦‚å¿µã€‚`onnx.save()` å‡½æ•°ç”¨äºå°†æ•´ä¸ª ONNX æ¨¡å‹ä¿å­˜åˆ°ç£ç›˜ä¸Šçš„æ–‡ä»¶ä¸­ï¼Œè¿™ä¸ªè¿‡ç¨‹å°±æ˜¯æ¨¡å‹çš„åºåˆ—åŒ–ã€‚è¿™ä¸ªå‡½æ•°çš„è°ƒç”¨ç±»ä¼¼äºå¯¹ ONNX æ¨¡å‹å¯¹è±¡è°ƒç”¨ `SerializeToString()` æ–¹æ³•ã€‚

> âš ï¸ <font color='green'>é€‰æ‹©ä½¿ç”¨ `onnx.save()` æ›´ç¬¦åˆ ONNX åº“çš„çº¦å®šï¼ŒåŒæ—¶æä¾›äº†æ›´æ–¹ä¾¿çš„æ¥å£</font>

### 2.4.2 æ¨¡å‹ååºåˆ—åŒ–ï¼ˆåŠ è½½ï¼‰

```python
from onnx import load


weights_path = 'ONNX/saves/linear_regression-serialized.onnx'
with open(weights_path, 'rb') as f:
  onnx_model = load(f)
  
print(onnx_model)
```

è¿™ä¸¤ç§æ–¹å¼çœ‹èµ·æ¥ç¡®å®æ˜¯ä¸€æ ·çš„ã€‚<font color='red'>é™¤éæ¨¡å‹å¤§å°è¶…è¿‡ 2 GBï¼Œä»»ä½•æ¨¡å‹éƒ½å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼è¿›è¡Œåºåˆ—åŒ–</font>ã€‚Protobuf å¯¹è±¡çš„å¤§å°å—åˆ° 2 GB é™åˆ¶ï¼Œå› æ­¤éœ€è¦é‡‡å–å…¶ä»–æ–¹æ³•æ¥å…‹æœè¿™ä¸€é™åˆ¶ã€‚æ¥ä¸‹æ¥çš„ç« èŠ‚å°†å±•ç¤ºå¦‚ä½•è§£å†³è¿™ä¸ªå¤§å°é™åˆ¶çš„é—®é¢˜ã€‚

---

ä¸‹é¢ä¸¤ç§è¯»å–æ¨¡å‹çš„æ–¹æ³•æœ‰ä»€ä¹ˆåŒºåˆ«å—ï¼Ÿ

```python
import onnx


# æ–¹æ³•1
weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model = onnx.load(weights_path)

# æ–¹æ³•2
with open(weights_path, 'rb') as f:
    onnx_model = f.read()
```

æ˜¯çš„ï¼Œè¿™ä¸¤ç§è¯»å–æ–¹å¼æœ‰å¾ˆå¤§çš„åŒºåˆ«ã€‚

1. **ç¬¬ä¸€ç§æ–¹å¼:**
   ```python
   weights_path = 'ONNX/saves/linear_regression.onnx'
   onnx_model = onnx.load(weights_path)
   ```
   è¿™ç§æ–¹å¼ä½¿ç”¨ `onnx.load` å‡½æ•°ä»æ–‡ä»¶ä¸­ç›´æ¥åŠ è½½ ONNX æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ç§å¸¸è§çš„æ–¹å¼ï¼Œç‰¹åˆ«é€‚ç”¨äºå¤§å‹çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ¯”å¦‚ ONNX æ¨¡å‹æ–‡ä»¶ã€‚

2. **ç¬¬äºŒç§æ–¹å¼:**
   ```python
   weights_path = 'ONNX/saves/linear_regression.onnx'
   with open(weights_path, 'rb') as f:
       onnx_model = f.read()
   ```
   è¿™ç§æ–¹å¼ä½¿ç”¨ Python çš„ `open` å‡½æ•°ä»¥äºŒè¿›åˆ¶è¯»å–æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ `read` æ–¹æ³•è¯»å–æ–‡ä»¶å†…å®¹ã€‚è¿™æ ·è·å¾—çš„æ˜¯æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œè€Œä¸æ˜¯ ONNX æ¨¡å‹å¯¹è±¡ã€‚

**åŒºåˆ«:**
- ç¬¬ä¸€ç§æ–¹å¼è¿”å›ä¸€ä¸ªç»è¿‡è§£æçš„ ONNX æ¨¡å‹å¯¹è±¡ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ ONNX åº“çš„å‡½æ•°å’Œæ–¹æ³•è¿›è¡Œæ“ä½œï¼Œæ¯”å¦‚æŸ¥çœ‹æ¨¡å‹çš„ç»“æ„ã€å…ƒæ•°æ®ç­‰ã€‚
- ç¬¬äºŒç§æ–¹å¼è¿”å›ä¸€ä¸ªåŒ…å«æ•´ä¸ªæ–‡ä»¶å†…å®¹çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œéœ€è¦é¢å¤–çš„æ­¥éª¤å°†å…¶è§£æä¸º ONNX æ¨¡å‹å¯¹è±¡ï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨ `onnx.load_model_from_string` ç­‰æ–¹æ³•ã€‚

é€šå¸¸æƒ…å†µä¸‹ï¼Œå¦‚æœéœ€è¦ç›´æ¥å¤„ç† ONNX æ¨¡å‹çš„ç»“æ„å’Œå…ƒæ•°æ®ï¼Œå»ºè®®ä½¿ç”¨ç¬¬ä¸€ç§æ–¹å¼ï¼Œè€Œå¦‚æœéœ€è¦å°† ONNX æ¨¡å‹æ–‡ä»¶çš„å†…å®¹ä½œä¸ºäºŒè¿›åˆ¶æ•°æ®è¿›è¡Œå…¶ä»–å¤„ç†ï¼Œå¯ä»¥é€‰æ‹©ç¬¬äºŒç§æ–¹å¼ã€‚

```python
import onnx


# ç¬¬ä¸€ç§æ–¹æ³•
weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model_1 = onnx.load(weights_path)
print(f"ç¬¬ä¸€ç§æ–¹æ³•: {type(onnx_model_1)}")

# ç¬¬äºŒç§æ–¹æ³•
with open(weights_path, 'rb') as f:
    onnx_model_2 = f.read()
print(f"ç¬¬äºŒç§æ–¹æ³•: {type(onnx_model_2)}")

# ä½¿ç”¨ onnx.load_model_from_string è§£æäºŒè¿›åˆ¶æ•°æ®ä¸º ONNX æ¨¡å‹å¯¹è±¡
onnx_model_2 = onnx.load_model_from_string(onnx_model_2)
print(f"ç¬¬äºŒç§æ–¹æ³•ï¼ˆè½¬æ¢åï¼‰: {type(onnx_model_2)}")
```

```
ç¬¬ä¸€ç§æ–¹æ³•: <class 'onnx.onnx_ml_pb2.ModelProto'>
ç¬¬äºŒç§æ–¹æ³•: <class 'bytes'>
ç¬¬äºŒç§æ–¹æ³•ï¼ˆè½¬æ¢åï¼‰: <class 'onnx.onnx_ml_pb2.ModelProto'>
```

### 2.4.3 æ•°æ®åºåˆ—åŒ–ï¼ˆä¿å­˜ï¼‰

Tensor çš„åºåˆ—åŒ–é€šå¸¸ä¼šæŒ‰ç…§ä»¥ä¸‹æ–¹å¼è¿›è¡Œï¼š

```python
import numpy as np
from onnx.numpy_helper import from_array


# åˆ›å»ºä¸€ä¸ª numpy çš„ Tensor
numpy_tensor = np.array([0, 1, 4, 5, 3], dtype=np.float32)
print(type(numpy_tensor))

# åˆ›å»ºä¸€ä¸ª onnx çš„ Tensor
onnx_tensor = from_array(numpy_tensor)
print(type(onnx_tensor))

# å°† onnx çš„ Tensor åºåˆ—åŒ–
serialized_tensor = onnx_tensor.SerializeToString()
print(type(serialized_tensor))

# å°†åºåˆ—åŒ–çš„ onnx Tensor ä¿å­˜åˆ°æœ¬åœ°
save_path = 'ONNX/saves/saved_serialized_tensor.pb'  # pb: Protocol Buffers 
with open(save_path, 'wb') as f:
  f.write(serialized_tensor)
print(f"The serialized onnx tensor has been saved at {save_path}!")
```

```
<class 'numpy.ndarray'>
<class 'onnx.onnx_ml_pb2.TensorProto'>
<class 'bytes'>
The serialized onnx tensor has been saved at ONNX/saves/saved_serialized_tensor.pb!
```

> ğŸ’¡ æ–‡ä»¶æ‰©å±•åä¸º `.pb` çš„æ–‡ä»¶é€šå¸¸æ˜¯ Protocol Buffersï¼ˆprotobufï¼‰æ ¼å¼çš„æ–‡ä»¶ã€‚Protocol Buffers æ˜¯ä¸€ç§ç”¨äºåºåˆ—åŒ–ç»“æ„åŒ–æ•°æ®çš„è½»é‡çº§æœºåˆ¶ï¼Œé€šå¸¸ç”¨äºè·¨ç½‘ç»œæˆ–æŒä¹…åŒ–å­˜å‚¨ã€‚

æˆ‘ä»¬ä½¿ç”¨ Netron æŸ¥çœ‹ä¸€ä¸‹è¿™ä¸ªä¿å­˜çš„åºåˆ—åŒ– onnx Tensorï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-23-11-11-35.png
    width=80%>
</div>

### 2.4.4 æ•°æ®ååºåˆ—åŒ–ï¼ˆåŠ è½½ï¼‰

æˆ‘ä»¬çœ‹ä¸€ä¸‹ååºåˆ—åŒ–ï¼ˆå³å°†åºåˆ—åŒ–çš„æ•°æ®åŠ è½½åˆ°ä»£ç ä¸­ï¼‰ï¼š

```python
from onnx import TensorProto
from onnx.numpy_helper import to_array


# è¯»å–åºåˆ—åŒ–æ•°æ®
data_path = 'ONNX/saves/saved_serialized_tensor.pb'  # pb: Protocol Buffers 
with open(data_path, 'rb') as f:
  serialized_tensor = f.read()
print(f"--------------------------- serialized_tensor ---------------------------\n"
      f"{type(serialized_tensor)}\n"  # <class 'bytes'>
      f"{serialized_tensor}\n")

"""
æˆ‘ä»¬å‘ç°æ­¤æ—¶ serialized_tensor çš„æ•°æ®ç±»å‹å¹¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ onnx.onnx_ml_pb2.TensorProto
è€Œæ˜¯ <class 'bytes'>ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸º onnx.onnx_ml_pb2.TensorProto æ ¼å¼
"""
# åˆ›å»ºä¸€ä¸ªç©ºçš„ onnx tensor
onnx_tensor = TensorProto()

# ä»äºŒè¿›åˆ¶å­—ç¬¦ä¸² serialized_tensor ä¸­è§£ææ•°æ®ï¼Œå¹¶å°†è§£æåçš„ç»“æœå­˜å‚¨åœ¨ onnx_tensor å¯¹è±¡ä¸­
onnx_tensor.ParseFromString(serialized_tensor)
print(f"--------------------------- onnx_tensor ---------------------------\n"
      f"{type(onnx_tensor)}\n"
      f"{onnx_tensor}\n")

# å°† onnx çš„ Tensor è½¬æ¢ä¸º numpy çš„Tensor
numpy_tensor = to_array(onnx_tensor)
print(f"--------------------------- numpy_tensor ---------------------------\n"
      f"{type(numpy_tensor)}\n"
      f"{numpy_tensor}")
```

```
--------------------------- serialized_tensor ---------------------------
<class 'bytes'>
b'\x08\x05\x10\x01J\x14\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x80@\x00\x00\xa0@\x00\x00@@'

--------------------------- onnx_tensor ---------------------------
<class 'onnx.onnx_ml_pb2.TensorProto'>
dims: 5
data_type: 1
raw_data: "\000\000\000\000\000\000\200?\000\000\200@\000\000\240@\000\000@@"

--------------------------- numpy_tensor ---------------------------
<class 'numpy.ndarray'>
[0. 1. 4. 5. 3.]
```

---

è¿™æ®µä»£ç å¯ä»¥ä½¿ç”¨ `load_tensor_from_string` å‡½æ•°è¿›è¡Œç®€åŒ–ï¼š

```python
from onnx import load_tensor_from_string
from onnx.numpy_helper import to_array


# è¯»å–åºåˆ—åŒ–æ•°æ®
data_path = 'ONNX/saves/saved_serialized_tensor.pb'  # pb: Protocol Buffers 
with open(data_path, 'rb') as f:
  serialized_tensor = f.read()
print(f"--------------------------- serialized_tensor ---------------------------\n"
      f"{type(serialized_tensor)}\n"  # <class 'bytes'>
      f"{serialized_tensor}\n")

# æ›´åŠ ä¾¿æ·åœ°åŠ è½½åºåˆ—åŒ–æ•°æ®
onnx_tensor = load_tensor_from_string(serialized_tensor)
print(f"--------------------------- onnx_tensor ---------------------------\n"
      f"{type(onnx_tensor)}\n"
      f"{onnx_tensor}\n")

# å°† onnx çš„ Tensor è½¬æ¢ä¸º numpy çš„Tensor
numpy_tensor = to_array(onnx_tensor)
print(f"--------------------------- numpy_tensor ---------------------------\n"
      f"{type(numpy_tensor)}\n"
      f"{numpy_tensor}")
```

```
--------------------------- serialized_tensor ---------------------------
<class 'bytes'>
b'\x08\x05\x10\x01J\x14\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x80@\x00\x00\xa0@\x00\x00@@'

--------------------------- onnx_tensor ---------------------------
<class 'onnx.onnx_ml_pb2.TensorProto'>
dims: 5
data_type: 1
raw_data: "\000\000\000\000\000\000\200?\000\000\200@\000\000\240@\000\000@@"

--------------------------- numpy_tensor ---------------------------
<class 'numpy.ndarray'>
[0. 1. 4. 5. 3.]
```

### 2.4.5 åºåˆ—åŒ–ä¸ååºåˆ—å¯ç”¨èŒƒå›´

ç›¸åŒçš„æ¨¡å¼ï¼ˆåºåˆ—åŒ–ä¸ååºåˆ—ï¼‰å¯ä»¥ç”¨äºä½†ä¸ä»…é™äº `TensorProto`ï¼š

```python
import onnx
import pprint


pprint.pprint([protocol for protocol in dir(onnx) 
               if protocol.endswith('Proto') and protocol[0] != '_'])
```

```
['AttributeProto',
 'FunctionProto',
 'GraphProto',
 'MapProto',
 'ModelProto',
 'NodeProto',
 'OperatorProto',
 'OperatorSetIdProto',
 'OperatorSetProto',
 'OptionalProto',
 'SequenceProto',
 'SparseTensorProto',
 'StringStringEntryProto',
 'TensorProto',
 'TensorShapeProto',
 'TrainingInfoProto',
 'TypeProto',
 'ValueInfoProto']
```

---

<kbd>Q</kbd>ï¼šåºåˆ—åŒ–å°±æ˜¯ä¿å­˜ï¼Œååºåˆ—åŒ–å°±æ˜¯åŠ è½½ï¼Ÿ
<kbd>GPT</kbd>ï¼šæ˜¯çš„ï¼Œä½ çš„ç†è§£æ˜¯æ­£ç¡®çš„ã€‚åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œåºåˆ—åŒ–æ˜¯å°†æ•°æ®ç»“æ„æˆ–å¯¹è±¡è½¬æ¢ä¸ºå¯å­˜å‚¨æˆ–ä¼ è¾“çš„æ ¼å¼çš„è¿‡ç¨‹ï¼Œé€šå¸¸ä»¥å­—èŠ‚æµçš„å½¢å¼ã€‚è¿™ä¸ªè¿‡ç¨‹å…è®¸å°†æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶ã€æ•°æ®åº“æˆ–é€šè¿‡ç½‘ç»œä¼ è¾“ã€‚ååºåˆ—åŒ–æ˜¯å°†ä¹‹å‰åºåˆ—åŒ–çš„æ•°æ®æ¢å¤ä¸ºåŸå§‹æ•°æ®ç»“æ„æˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥ä½¿ç”¨æˆ–å¤„ç†ã€‚å› æ­¤ï¼Œåºåˆ—åŒ–å’Œååºåˆ—åŒ–æ˜¯æ•°æ®çš„ä¿å­˜å’ŒåŠ è½½çš„è¿‡ç¨‹ã€‚

## 2.5 Initializerï¼ˆåˆå§‹åŒ–å™¨ï¼‰ï¼Œé»˜è®¤å€¼

å‰é¢çš„æ¨¡å‹å‡è®¾çº¿æ€§å›å½’çš„ç³»æ•°ä¹Ÿæ˜¯æ¨¡å‹çš„è¾“å…¥ï¼Œä½†è¿™å¹¶ä¸å¤ªæ–¹ä¾¿ã€‚å®ƒä»¬åº”è¯¥ä½œä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼ˆä½œä¸ºå¸¸æ•°æˆ–åˆå§‹åŒ–å™¨ï¼‰ï¼Œè¿™æ ·å°±ç¬¦åˆ ONNX çš„è¯­ä¹‰äº†ã€‚ä¸‹é¢è¿™ä¸ªä¾‹å­ä¿®æ”¹äº†å‰ä¸€ä¸ªä¾‹å­ï¼Œå°†è¾“å…¥ A å’Œ B æ”¹ä¸ºåˆå§‹åŒ–å™¨ã€‚è¯¥åŒ…å®ç°äº†ä¸¤ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨ numpy æ•°ç»„å’Œ ONNX æ ¼å¼ä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚

- `onnx.numpy_helper.to_array`: ä» ONNX è½¬æ¢ä¸º NumPy æ•°ç»„
- `onnx.numpy_helper.from_array`: ä» NumPy è½¬æ¢ä¸º ONNX

> è¿™ä¸¤ä¸ªå‡½æ•°æˆ‘ä»¬ä¸Šé¢çš„ä¾‹å­å°±å·²ç»ç”¨è¿‡äº†

```python
import numpy as np
import onnx
from onnx import numpy_helper, TensorProto
from onnx.helper import (make_tensor_value_info, 
                         make_node, make_graph, make_model)
from onnx.checker import check_model


# -------------------------- åˆ›å»º initializers --------------------------
value = np.array([0.5, -0.6], dtype=np.float32)
A = numpy_helper.from_array(value, name='A')

value = np.array([0.4], dtype=np.float32)
C = numpy_helper.from_array(value, name='C')

# -------------------------- åˆ›å»º è¾“å…¥ã€è¾“å‡ºã€èŠ‚ç‚¹ã€å›¾ã€æ¨¡å‹ --------------------------
X = make_tensor_value_info(name='X', elem_type=TensorProto.FLOAT, shape=[None, None])
Y = make_tensor_value_info(name='Y', elem_type=TensorProto.FLOAT, shape=[None])

# è¾“å…¥æ˜¯['X', 'A']ï¼Œè¾“å‡ºæ˜¯['AX']ï¼Œé‚£ä¹ˆæ„æ€å°±æ˜¯è¯´ï¼Œå°†è¾“å…¥Xä¸å‚æ•°Aç›¸ä¹˜ï¼Œå¾—åˆ°è¾“å‡ºAX
node1 = make_node(op_type='MatMul', inputs=['X', 'A'], outputs=['AX'])

# è¾“å…¥æ˜¯['AX', 'C']ï¼Œè¾“å‡ºæ˜¯['Y']ï¼Œé‚£ä¹ˆæ„æ€å°±æ˜¯è¯´ï¼Œå°†è¾“å…¥AXä¸å‚æ•°Cç›¸åŠ ï¼Œå¾—åˆ°è¾“å‡ºY --> Y <=> AX + C
node2 = make_node(op_type='Add', inputs=['AX', 'C'], outputs=['Y'])

# åˆ›å»ºå›¾çš„æ—¶å€™è¾“å…¥å°±æ˜¯æœ€ä¸€å¼€å§‹çš„è¾“å…¥ï¼Œè¾“å‡ºå°±æ˜¯æœ€ç»ˆçš„è¾“å‡º
graph = make_graph(nodes=[node1, node2], 
                   name='lr', 
                   inputs=[X], 
                   outputs=[Y], 
                   initializer=[A, C])

# æ ¹æ®å›¾åˆ›å»ºæ¨¡å‹
onnx_model = make_model(graph=graph)
check_model(onnx_model)  # æ£€æŸ¥æ¨¡å‹

model_save_path = 'ONNX/saves/onnx_with_initializer.onnx'
onnx.save(onnx_model, model_save_path)
print(f"ONNX model with initializer has been saved to {model_save_path}")
```

æˆ‘ä»¬ä½¿ç”¨ Netron æŸ¥çœ‹ä¸€ä¸‹è¿™ä¸ªæ¨¡å‹ï¼ˆå¹¶é™„ä¸Šä¹‹å‰çš„ç»“æœï¼‰ï¼š


<div align=center>
  <div align=half>
      <img src=./imgs_markdown/2024-01-23-10-06-01.png
      width=30%>
      <img src=./imgs_markdown/2024-01-23-10-06-26.png
      width=50%>
  </div>
  <div align=center>
      <img src=./imgs_markdown/2024-01-23-12-10-06.png
      width=80%>
  </div>
</div>

å¯ä»¥çœ‹åˆ°ï¼Œä¹‹å‰çš„æ¨¡å‹æ­¥éª¤çœ‹èµ·æ¥æœ‰ç‚¹ç¹çï¼Œè€ŒåŠ äº† initializer åçš„ç»“æœå°±ç®€æ´äº†å¾ˆå¤šï¼Œ`<2>` å’Œ `<1>` è¡¨ç¤ºæƒé‡æœ‰å‡ ä¸ªç»´åº¦ã€‚

åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥éå† ONNX ç»“æ„ï¼ŒæŸ¥çœ‹åˆå§‹åŒ–å™¨çš„å…·ä½“å†…å®¹ã€‚

```python
...  # ä»£ç åŒä¸Š

# æ ¹æ®å›¾åˆ›å»ºæ¨¡å‹
onnx_model = make_model(graph=graph)
check_model(onnx_model)  # æ£€æŸ¥æ¨¡å‹

# -------------------------- æŸ¥çœ‹åˆå§‹åŒ–å™¨ --------------------------
print(f" -------------------------- æŸ¥çœ‹åˆå§‹åŒ–å™¨ --------------------------")
for init in onnx_model.graph.initializer:
    print(init)
```

```
 -------------------------- æŸ¥çœ‹åˆå§‹åŒ–å™¨ --------------------------
dims: 2
data_type: 1
name: "A"
raw_data: "\000\000\000?\232\231\031\277"

dims: 1
data_type: 1
name: "C"
raw_data: "\315\314\314>"
```

ç±»å‹ä¹Ÿè¢«å®šä¹‰ä¸ºå…·æœ‰ç›¸åŒå«ä¹‰çš„æ•´æ•°ã€‚åœ¨ç¬¬äºŒä¸ªç¤ºä¾‹ä¸­ï¼Œåªå‰©ä¸‹ä¸€ä¸ªè¾“å…¥ã€‚ è¾“å…¥ A å’Œ B å·²è¢«åˆ é™¤ï¼ˆä»–ä»¬å¯ä»¥è¢«ä¿ç•™ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä»¬æ˜¯å¯é€‰çš„ï¼šæ¯ä¸ªä¸è¾“å…¥å…±äº«ç›¸åŒåç§°çš„ initializer éƒ½è¢«è§†ä¸ºé»˜è®¤å€¼ã€‚å¦‚æœæœªç»™å‡ºæ­¤è¾“å…¥ï¼Œå®ƒå°†æ›¿æ¢è¾“å…¥ã€‚

## 2.6 Attributesï¼Œå±æ€§

æœ‰äº›è¿ç®—ç¬¦éœ€è¦åƒè½¬ç½®è¿ç®—ç¬¦ï¼ˆtransposeï¼‰è¿™æ ·çš„å±æ€§ã€‚è®©æˆ‘ä»¬ä¸ºè¡¨è¾¾å¼ $y = XA' + B$ æˆ– `y = Add(MatMul(X, Transpose(A)) + B)` æ„å»ºå›¾ã€‚è½¬ç½®è¿ç®—ç¬¦éœ€è¦ä¸€ä¸ªå®šä¹‰è½´ç½®æ¢çš„å±æ€§ï¼š`perm=[1, 0]`ã€‚å®ƒè¢«æ·»åŠ ä¸ºå‡½æ•° `make_node` ä¸­çš„ä¸€ä¸ªå…·åå±æ€§ã€‚

```python
import onnx
from onnx import numpy_helper, TensorProto
from onnx.helper import (make_tensor_value_info, 
                         make_node, make_graph, make_model)
from onnx.checker import check_model


# -------------------------- ä¸å˜ --------------------------
X = make_tensor_value_info(name='X', elem_type=TensorProto.FLOAT, shape=[None, None])
A = make_tensor_value_info(name='A', elem_type=TensorProto.FLOAT, shape=[None, None])
B = make_tensor_value_info(name='B', elem_type=TensorProto.FLOAT, shape=[None, None])
Y = make_tensor_value_info(name='Y', elem_type=TensorProto.FLOAT, shape=[None])

# -------------------------- æ–°ç®—å­ï¼štranspose --------------------------
node_transpose = make_node(op_type='Transpose', inputs=['A'], outputs=['tA'], perm=[1, 0])

# -------------------------- åˆ›å»º è¾“å…¥ã€è¾“å‡ºã€èŠ‚ç‚¹ã€å›¾ã€æ¨¡å‹ --------------------------
node1 = make_node(op_type='MatMul', inputs=['X', 'tA'], outputs=['XA'])
node2 = make_node(op_type='Add', inputs=['XA', 'B'], outputs=['Y'])

graph = make_graph(nodes=[node_transpose, node1, node2], 
                   name='example', 
                   inputs=[X, A, B], 
                   outputs=[Y])

# æ ¹æ®å›¾åˆ›å»ºæ¨¡å‹
onnx_model = make_model(graph=graph)
check_model(onnx_model)  # æ£€æŸ¥æ¨¡å‹

model_save_path = 'ONNX/saves/attributes-transpose.onnx'
onnx.save(onnx_model, model_save_path)
print(f"ONNX model with initializer has been saved to {model_save_path}")
print(onnx_model)
```

```
ONNX model with initializer has been saved to ONNX/saves/attributes-transpose.onnx
ir_version: 9
opset_import {
  version: 20
}
graph {
  node {
    input: "A"
    output: "tA"
    op_type: "Transpose"
    attribute {
      name: "perm"
      type: INTS
      ints: 1
      ints: 0
    }
  }
  node {
    input: "X"
    input: "tA"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "example"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
```

æˆ‘ä»¬ç”¨ Netron çœ‹ä¸€ä¸‹ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-23-14-25-27.png
    width=100%>
</div>

ä»¥ä¸‹æ˜¯ä¸€ç³»åˆ— `make` å‡½æ•°çš„å®Œæ•´åˆ—è¡¨ï¼š

```python
import onnx
import pprint


pprint.pprint([k for k in dir(onnx.helper) if k.startswith('make')])
```

```
['make_attribute',
 'make_attribute_ref',
 'make_empty_tensor_value_info',
 'make_function',
 'make_graph',
 'make_map',
 'make_map_type_proto',
 'make_model',
 'make_model_gen_version',
 'make_node',
 'make_operatorsetid',
 'make_opsetid',
 'make_optional',
 'make_optional_type_proto',
 'make_sequence',
 'make_sequence_type_proto',
 'make_sparse_tensor',
 'make_sparse_tensor_type_proto',
 'make_sparse_tensor_value_info',
 'make_tensor',
 'make_tensor_sequence_value_info',
 'make_tensor_type_proto',
 'make_tensor_value_info',
 'make_training_info',
 'make_value_info']
```

## 2.7 Opset and metadataï¼Œç®—å­é›†ä¸å…ƒæ•°æ®

é¦–å…ˆå…ˆæ˜ç™½ä¸¤ä¸ªæ¦‚å¿µï¼š

1. ä»€ä¹ˆæ˜¯ Opsetï¼šåœ¨ [1.4 ONNX ç»„æˆéƒ¨åˆ†](##Opset) ä¸­æœ‰æåˆ°ï¼Œç®€è€Œè¨€ä¹‹ï¼ŒOp å°±æ˜¯ç®—å­ï¼ŒSet æ˜¯é›†åˆï¼Œé‚£ä¹ˆ Opset å°±æ˜¯ç®—å­é›†åˆã€‚
2. ä»€ä¹ˆæ˜¯ metadataï¼šè¿™ä¸ªéœ€è¦å¥½å¥½è¯´ä¸€ä¸‹ã€‚

---

æˆ‘ä»¬é¦–å…ˆçœ‹ä¸€ä¸‹[ç»´åŸºç™¾ç§‘çš„ä»‹ç»](https://zh.wikipedia.org/wiki/%E5%85%83%E6%95%B0%E6%8D%AE)ï¼š

å…ƒæ•°æ®ï¼ˆMetadataï¼Œåˆè¯‘ä½œè¯ é‡Šèµ„æ–™ï¼Œå…ƒèµ„æ–™ï¼‰ï¼Œæ˜¯ä¸€ç¾¤æ•°æ®ï¼Œå…¶å†…å®¹æä¾›äº†æœ‰å…³äºå¦ä¸€ç¾¤æ•°æ®çš„ä¿¡æ¯ã€‚è‹±æ–‡å‰ç¼€è¯ `meta-` çš„æ„æ€æ˜¯ä¹‹åï¼Œè¿›è€Œæœ‰è¶…å‡ºç•Œé™ï¼ˆtranscendingï¼‰ä¹‹æ„æ€ï¼Œå…¶è¯­ä¹‰æ¥è‡ªå½¢è€Œä¸Šå­¦çš„å¤–è¯­æ„è¯ meta-physics ï¼ˆå¸Œè…Šè¯­ï¼šÎ¼ÎµÏ„Î¬-Ï†Ï…ÏƒÎ¹ÎºÎ¬ï¼‰ ï¼Œå…·æœ‰æ¢æ±‚ç°è±¡æˆ–å¯¹è±¡èƒŒåä¹‹æœ¬è´¨çš„æ„å‘³ã€‚å› æ­¤ï¼Œå…ƒæ•°æ®ä¹Ÿå¸¦æœ‰ç›¸ä»¿çš„æ„ä¹‰ï¼ŒæŒ‡çš„å°±æ˜¯è¶…å‡ºäºâ€œç‰¹å®šä¸€ç¾¤æ•°æ®â€æ‰€å‘ˆç°çš„å†…å®¹æ•°æ®ä¹‹å¤–ï¼Œå…¶ç¬¬äºŒå±‚æ¬¡çš„æ•°æ®ã€‚å®è´¨ä¸Šï¼Œä¹Ÿå°±æ˜¯ç”¨äºæè¿°è¿™â€œç‰¹å®šä¸€ç¾¤æ•°æ®â€çš„æ•°æ®ï¼Œå…·ä½“æ¥è¯´ï¼Œå¦‚ï¼š

- ä¹¦ç±çš„ä¹¦åã€ä½œè€…ã€ä¸»é¢˜ã€ç›®æ¬¡ã€é¡µæ•°ã€è¯­è¨€ã€å‡ºç‰ˆæ—¶é—´ã€å‡ºç‰ˆç¤¾ç­‰
- æ–°é—»çš„æŠ¥å¯¼æ—¥æœŸã€ä¸»å‰¯æ ‡é¢˜ã€å…³é”®å­—ã€è®°è€…ã€æŠ¥åˆŠåã€ç‰ˆæ¬¡/ç‰ˆåã€è¯­è¨€ç­‰
- ç…§ç‰‡çš„ç›¸æœºå‹å·ã€æ‹æ‘„æ—¶é—´ã€æ‹æ‘„åœ°ç‚¹ã€ç…§ç‰‡å°ºå¯¸ã€åˆ†è¾¨ç‡ã€ç…§ç‰‡æ ‡é¢˜ã€æ ‡ç­¾ã€æ‘„å½±å¸ˆç­‰

ğŸ’¡ æ­£ç”±äºå…ƒæ•°æ®æ˜¯åœ¨æè¿°å…³äºâ€œç‰¹å®šä¸€ç¾¤æ•°æ®â€çš„==ä¿¡æ¯==ï¼Œ<font color='red'>ä½†å¹¶éæ˜¯è¿™â€œç‰¹å®šä¸€ç¾¤æ•°æ®â€å…¶è‡ªèº«çš„å†…å®¹æ•°æ®</font>ï¼Œæ‰€ä»¥æ‰å‘½åä¸º meta-dataï¼Œå³æ•°æ®èƒŒåçš„æ•°æ®ã€‚

---

å†çœ‹ä¸€ä¸‹[çŸ¥ä¹çš„è§£é‡Š](https://www.zhihu.com/question/517305994/answer/2354028741)ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-23-14-42-28.png
    width=80%>
</div>

---

æœ€åçœ‹ä¸€ä¸‹ GPT å¯¹ `meta` è¿™ä¸ªè¯çš„è§£é‡Šï¼š

"meta"ï¼ˆå…ƒï¼‰æ˜¯å¸Œè…Šè¯­çš„ä¸€ä¸ªå‰ç¼€ï¼Œè¡¨ç¤ºåœ¨æˆ–è¶…è¶ŠæŸäº‹ç‰©ä¹‹åçš„äº‹ç‰©ï¼Œæˆ–è€…è¡¨ç¤ºå¯¹è¯¥äº‹ç‰©çš„æ›´é«˜çº§åˆ«æˆ–æŠ½è±¡çš„æè¿°ã€‚åœ¨è‹±è¯­ä¸­ï¼Œ"meta" å¸¸è¢«ç”¨ä½œå‰ç¼€ï¼Œç”¨äºæ„å»ºä¸€äº›ä¸åŸå§‹äº‹ç‰©ç›¸å…³ä½†æ›´ä¸ºæŠ½è±¡æˆ–é«˜çº§çš„æ¦‚å¿µã€‚

ä¾‹å¦‚ï¼š

1. **å…ƒæ•°æ®ï¼ˆmetadataï¼‰ï¼š** "meta" åœ¨è¿™é‡Œè¡¨ç¤ºæ•°æ®çš„æè¿°ï¼Œå³å¯¹æ•°æ®çš„æ›´é«˜çº§åˆ«çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æ•°æ®æœ¬èº«ã€‚

2. **å…ƒåˆ†æï¼ˆmeta-analysisï¼‰ï¼š** "meta" è¡¨ç¤ºå¯¹å¤šä¸ªç‹¬ç«‹ç ”ç©¶çš„ç»¼åˆåˆ†æï¼Œæ˜¯å¯¹ç ”ç©¶çš„æ›´é«˜çº§åˆ«çš„åˆ†æã€‚

3. **å…ƒç¼–ç¨‹ï¼ˆmeta-programmingï¼‰ï¼š** "meta" è¡¨ç¤ºåœ¨ç¨‹åºä¸­å¯¹ç¨‹åºè¿›è¡Œæ“ä½œçš„èƒ½åŠ›ï¼Œå³åœ¨ç¨‹åºä¸­å¯¹ä»£ç è¿›è¡Œå¤„ç†çš„è¿‡ç¨‹ã€‚

ğŸ’¡ æ€»çš„æ¥è¯´ï¼Œ"meta" è¡¨ç¤ºå¯¹æŸä¸€é¢†åŸŸçš„æ›´é«˜çº§åˆ«ã€æ›´æŠ½è±¡æˆ–æ›´å…¨é¢çš„ç†è§£å’Œæè¿°ã€‚

---

å¥½çš„ï¼Œæˆ‘ä»¬ç°åœ¨å›åˆ°æ­£é¢˜ã€‚

è®©æˆ‘ä»¬åŠ è½½ä¹‹å‰åˆ›å»ºçš„ ONNX æ–‡ä»¶å¹¶æ£€æŸ¥å®ƒå…·æœ‰å“ªäº›ç±»å‹çš„å…ƒæ•°æ®ï¼š

```python
import onnx


# ç¬¬ä¸€ç§æ–¹æ³•
weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model = onnx.load(weights_path)

# -------------------------- è·å– metadata --------------------------
for field in ['doc_string', 'domain', 'functions',
              'ir_version', 'metadata_props', 'model_version',
              'opset_import', 'producer_name', 'producer_version',
              'training_info']:
    print(field, getattr(onnx_model, field))
```

```
doc_string 
domain
functions []
ir_version 9
metadata_props []
model_version 0
opset_import [version: 20
]
producer_name
producer_version
training_info []
```

> âš ï¸ æ³¨æ„ï¼šæˆ‘ä»¬ä¸èƒ½ä½¿ç”¨äºŒè¿›åˆ¶çš„æ–¹å¼è¯»å–æ¨¡å‹ï¼Œè¿™æ ·è¯»å–çš„æ¨¡å‹çš„æ•°æ®ç±»å‹æ˜¯ `<class 'bytes'>` è€Œé `<class 'onnx.onnx_ml_pb2.ModelProto'>`ã€‚å‰è€…æ˜¯æ²¡æœ‰ metadata è¿™äº›å±æ€§çš„ï¼Œéœ€è¦ä½¿ç”¨ `onnx.load_model_from_string()` æ–¹æ³•è¿›è¡Œè½¬æ¢ï¼Œå¾—åˆ°  `<class 'onnx.onnx_ml_pb2.ModelProto'>` è¿™æ ·æ•°æ®ç±»å‹çš„æ¨¡å‹æ‰ä¼šæœ‰ metadaã€‚

ä»ä¸Šé¢çš„ç»“æœæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªæ¨¡å‹ä¸­çš„ metadata å¤§å¤šæ•°éƒ½æ˜¯ç©ºçš„ï¼Œå› ä¸ºåœ¨åˆ›å»º ONNX å›¾æ—¶æ²¡æœ‰å¡«å……å®ƒä»¬ã€‚è¿™ä¸ªæ¨¡å‹åªæœ‰ä¸¤ä¸ª metada æœ‰æ•°å€¼ï¼š

```python
import onnx


weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model = onnx.load(weights_path)

print(f"[metadata] ir_version: {onnx_model.ir_version}")
for opset in onnx_model.opset_import:
    print(f"[metadata] opset domain={opset.domain!r} version={opset.version!r}")
```

```
[metadata] ir_version: 9
[metadata] opset domain='' version=20
```

`IR` å®šä¹‰äº† ONNX è¯­è¨€çš„ç‰ˆæœ¬ã€‚`Opset` å®šä¹‰äº†æ­£åœ¨ä½¿ç”¨çš„è¿ç®—ç¬¦çš„ç‰ˆæœ¬ã€‚å¦‚æœæ²¡æœ‰æŒ‡å®šç²¾åº¦ï¼ŒONNX å°†ä½¿ç”¨æ¥è‡ªå·²å®‰è£…åŒ…çš„æœ€æ–°ç‰ˆæœ¬ã€‚å½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–ç‰ˆæœ¬ã€‚

> ğŸ’¡ IR çš„è‹±æ–‡å…¨ç§°æ˜¯ "Intermediate Representation"ï¼Œæ„ä¸ºä¸­é—´è¡¨ç¤ºæˆ–ä¸­é—´è¡¨è¾¾å¼ã€‚åœ¨è®¡ç®—æœºç§‘å­¦å’Œç¼–ç¨‹é¢†åŸŸï¼ŒIR é€šå¸¸ç”¨æ¥è¡¨ç¤ºæºä»£ç å’Œç›®æ ‡ä»£ç ä¹‹é—´çš„ä¸€ç§ä¸­é—´å½¢å¼ï¼Œä¾¿äºåœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­è¿›è¡Œåˆ†æã€ä¼˜åŒ–å’Œè½¬æ¢ã€‚åœ¨ ONNX çš„ä¸Šä¸‹æ–‡ä¸­ï¼ŒIR æŒ‡çš„æ˜¯ ONNX æ¨¡å‹çš„ä¸­é—´è¡¨ç¤ºã€‚

```python
import onnx


weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model = onnx.load(weights_path)

# åˆ é™¤æ‰ç›®å‰æ¨¡å‹çš„ opset
del onnx_model.opset_import[:]

# æˆ‘ä»¬è‡ªå·±å®šä¹‰opset
opset = onnx_model.opset_import.add()
opset.domain = ''
opset.version = 14

print(f"[metadata] ir_version: {onnx_model.ir_version}")
for opset in onnx_model.opset_import:
    print(f"[metadata] opset domain={opset.domain!r} version={opset.version!r}")
```

```
[metadata] ir_version: 9
[metadata] opset domain='' version=14
```

åªè¦æ‰€æœ‰è¿ç®—ç¬¦æŒ‰ç…§ ONNX è§„å®šçš„æ–¹å¼è¿›è¡Œå®šä¹‰ï¼Œå°±å¯ä»¥ä½¿ç”¨ä»»æ„çš„ opsetã€‚ä¾‹å¦‚ï¼Œè¿ç®—ç¬¦ Reshape çš„ç¬¬ 5 ä¸ªç‰ˆæœ¬å°†å½¢çŠ¶å®šä¹‰ä¸ºä¸€ä¸ªè¾“å…¥ï¼Œè€Œä¸åƒç¬¬ 1 ä¸ªç‰ˆæœ¬é‚£æ ·å®šä¹‰ä¸ºå±æ€§ã€‚Opset æŒ‡å®šäº†æè¿°å›¾æ—¶éµå¾ªçš„è§„èŒƒã€‚

å…¶ä»–å…ƒæ•°æ®å¯ä»¥ç”¨äºå­˜å‚¨ä»»ä½•ä¿¡æ¯ï¼Œä»¥å­˜å‚¨æœ‰å…³æ¨¡å‹ç”Ÿæˆæ–¹å¼çš„ä¿¡æ¯ï¼Œæˆ–è€…ç”¨ç‰ˆæœ¬å·åŒºåˆ†ä¸€ä¸ªæ¨¡å‹å’Œå¦ä¸€ä¸ªæ¨¡å‹ã€‚ä¸‹é¢æˆ‘ä»¬ä¸¾ä¸ªä¾‹å­ï¼š

```python
import onnx


# -------------------------- åŠ è½½æ¨¡å‹ --------------------------
weights_path = 'ONNX/saves/linear_regression.onnx'
onnx_model = onnx.load(weights_path)

# -------------------------- ä¿®æ”¹metadata --------------------------
onnx_model.model_version = 15
onnx_model.producer_name = 'Le0v1n'
onnx_model.producer_version = 'v1.0'
onnx_model.doc_string = 'documentation about this onnx model by Le0v1n'

# è¯»å–æ¨¡å‹ç°åœ¨çš„metadataå±æ€§
prop = onnx_model.metadata_props
print(prop)  # []

# ç›®å‰ metadataå±æ€§ä¸­çš„å†…å®¹ä¸ºç©ºï¼Œæˆ‘ä»¬å¯ä»¥å¾€é‡Œé¢æ”¾ä¸€äº›ä¿¡æ¯
# âš ï¸ metadata_propsåªæ¥å—å­—å…¸
info1 = {'modelè¯´æ˜': 'è¿™æ˜¯ä¸€ä¸ªç”¨äºå­¦ä¹ çš„ONNXæ¨¡å‹', 
         'æ—¶é—´': '20240123'}
onnx.helper.set_model_props(onnx_model, info1)
print(onnx_model)
```

```
[]
ir_version: 9
opset_import {
  version: 20
}
producer_name: "Le0v1n"
producer_version: "v1.0"
model_version: 15
doc_string: "documentation about this onnx model by Le0v1n"
graph {
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  name: "lr"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
metadata_props {
  key: "modelè¯´æ˜"
  value: "è¿™æ˜¯ä¸€ä¸ªç”¨äºå­¦ä¹ çš„ONNXæ¨¡å‹"
}
metadata_props {
  key: "æ—¶é—´"
  value: "20240123"
}
```

ğŸ’¡ å­—æ®µ `training_info` å¯ä»¥ç”¨äºå­˜å‚¨é¢å¤–çš„å›¾å½¢ä¿¡æ¯ã€‚

## 2.8 Subgraph: test and loops â€”â€” IF

å®ƒä»¬é€šå¸¸è¢«åˆ†ç»„åœ¨ä¸€ä¸ªç§°ä¸ºæ§åˆ¶æµçš„ç±»åˆ«ä¸­ã€‚<font color='red'>é€šå¸¸æœ€å¥½é¿å…ä½¿ç”¨å®ƒä»¬ï¼Œå› ä¸ºå®ƒä»¬ä¸åƒçŸ©é˜µæ“ä½œé‚£æ ·é«˜æ•ˆå’Œä¼˜åŒ–</font>ã€‚

å¯ä»¥ä½¿ç”¨è¿ç®—ç¬¦ If æ¥å®ç°æµ‹è¯•ã€‚å®ƒæ ¹æ®ä¸€ä¸ªå¸ƒå°”å€¼æ‰§è¡Œä¸€ä¸ªå­å›¾æˆ–å¦ä¸€ä¸ªå­å›¾ã€‚è¿™é€šå¸¸ä¸ç»å¸¸ä½¿ç”¨ï¼Œå› ä¸ºå‡½æ•°é€šå¸¸éœ€è¦åœ¨æ‰¹å¤„ç†ä¸­è¿›è¡Œè®¸å¤šæ¯”è¾ƒçš„ç»“æœã€‚ä»¥ä¸‹ç¤ºä¾‹æ ¹æ®çŸ©é˜µä¸­çš„ç¬¦å·è®¡ç®—æ‰€æœ‰æµ®ç‚¹æ•°çš„å’Œï¼Œå¹¶è¿”å› 1 æˆ– -1ã€‚

```python
import numpy as np
import onnx
from onnx.helper import make_tensor_value_info, make_node, make_graph, make_model
from onnx.numpy_helper import from_array
from onnx.checker import check_model
from onnxruntime import InferenceSession

# -------------------------- åˆå§‹åŒ–å™¨ --------------------------
# åˆ›å»ºä¸€ä¸ªåŒ…å«å€¼ä¸º0çš„æµ®ç‚¹æ•°æ•°ç»„ï¼Œå¹¶æŒ‡å®šæ•°æ®ç±»å‹ä¸ºnp.float32
value = np.array([0], dtype=np.float32)

# ä½¿ç”¨onnx.numpy_helper.from_arrayå°†numpyæ•°ç»„è½¬æ¢ä¸ºONNXçš„TensorProtoå½¢å¼
zero = from_array(value, name='zero')

# -------------------------- è¾“å…¥ --------------------------
# åˆ›å»ºè¾“å…¥Tensorä¿¡æ¯ï¼Œåç§°ä¸º'X'ï¼Œæ•°æ®ç±»å‹ä¸ºonnx.TensorProto.FLOATï¼Œå½¢çŠ¶ä¸º[None, None]ï¼Œè¡¨ç¤ºå¯å˜ç»´åº¦
X = make_tensor_value_info('X', onnx.TensorProto.FLOAT, shape=[None, None])

# åˆ›å»ºè¾“å‡ºTensorä¿¡æ¯ï¼Œåç§°ä¸º'Y'ï¼Œæ•°æ®ç±»å‹ä¸ºonnx.TensorProto.FLOATï¼Œå½¢çŠ¶ä¸º[None]ï¼Œè¡¨ç¤ºå¯å˜ç»´åº¦
Y = make_tensor_value_info('Y', onnx.TensorProto.FLOAT, shape=[None])

# -------------------------- èŠ‚ç‚¹ --------------------------
# åˆ›å»º ReduceSum èŠ‚ç‚¹ï¼Œç”¨äºæ²¿ç€æŒ‡å®šè½´å¯¹è¾“å…¥Tensorè¿›è¡Œæ±‚å’Œï¼Œè¾“å…¥ä¸º 'X'ï¼Œè¾“å‡ºä¸º 'rsum'
rsum = make_node(op_type='ReduceSum', inputs=['X'], outputs=['rsum'])

# åˆ›å»º Greater èŠ‚ç‚¹ï¼Œç”¨äºæ¯”è¾ƒ 'rsum' å’Œ 'zero'ï¼Œè¾“å‡ºç»“æœä¿å­˜åœ¨ 'cond'
cond = make_node(op_type='Greater', inputs=['rsum', 'zero'], outputs=['cond'])

# -------------------------- å›¾å½¢ï¼ˆå¸¦æœ‰æ¡ä»¶ï¼‰ --------------------------
"""
    then <=> True:  è¡¨ç¤ºå½“æ¡ä»¶æ»¡è¶³çš„æ—¶å€™æ‰§è¡Œçš„
    else <=> False: è¡¨ç¤ºå½“æ¡ä»¶ä¸æ»¡è¶³çš„æ—¶å€™æ‰§è¡Œçš„
"""
# -------------------------- å›¾å½¢: True -> then --------------------------
# æ¡ä»¶ä¸ºTrueæ—¶çš„è¾“å‡ºTensorä¿¡æ¯
then_out = make_tensor_value_info(name='then_out', 
                                  elem_type=onnx.TensorProto.FLOAT, 
                                  shape=None)

# ç”¨äºè¿”å›çš„å¸¸é‡Tensor
then_cst = from_array(np.array([1]).astype(np.float32))

# åˆ›å»º Constant èŠ‚ç‚¹ï¼Œå°†å¸¸é‡Tensorä½œä¸ºè¾“å‡º 'then_out' çš„å€¼ï¼Œæ„æˆä¸€ä¸ªå•ä¸€èŠ‚ç‚¹
then_const_node = make_node(op_type='Constant', 
                            inputs=[], 
                            outputs=['then_out'], 
                            value=then_cst, 
                            name='cst1')

# åˆ›å»ºåŒ…è£¹è¿™äº›å…ƒç´ çš„å›¾å½¢ï¼Œè¡¨ç¤ºå½“æ¡ä»¶ä¸ºçœŸæ—¶æ‰§è¡Œ
then_body = make_graph(nodes=[then_const_node], 
                       name='then_body', 
                       inputs=[], 
                       outputs=[then_out])

# -------------------------- å›¾å½¢: False -> else --------------------------
# å¯¹äº else åˆ†æ”¯ï¼Œç›¸åŒçš„å¤„ç†è¿‡ç¨‹
else_out = make_tensor_value_info(name='else_out', 
                                  elem_type=onnx.TensorProto.FLOAT, 
                                  shape=[5])

else_cst = from_array(np.array([-1]).astype(np.float32))

else_const_node = make_node(op_type='Constant', 
                            inputs=[], 
                            outputs=['else_out'], 
                            value=else_cst, 
                            name='cst2')

else_body = make_graph(nodes=[else_const_node], name='else_body', inputs=[], outputs=[else_out])

# åˆ›å»º If èŠ‚ç‚¹ï¼Œæ¥å—æ¡ä»¶ 'cond'ï¼Œå¹¶æœ‰ä¸¤ä¸ªåˆ†æ”¯ï¼Œåˆ†åˆ«ä¸º 'then_body' å’Œ 'else_body'ã€‚
if_node = make_node(op_type='If', inputs=['cond'], outputs=['Y'], 
                    then_branch=then_body, 
                    else_branch=else_body)

# åˆ›å»ºæ•´ä½“çš„å›¾å½¢ï¼ŒåŒ…æ‹¬ ReduceSumã€Greater å’Œ If èŠ‚ç‚¹
graph = make_graph(nodes=[rsum, cond, if_node],
                   name='if',
                   inputs=[X],
                   outputs=[Y],
                   initializer=[zero])

# -------------------------- æ¨¡å‹ --------------------------
# åˆ›å»º ONNX æ¨¡å‹ï¼Œä½¿ç”¨ä¹‹å‰æ„å»ºçš„å›¾å½¢ä½œä¸ºå‚æ•°
onnx_model = make_model(graph=graph)

# æ£€æŸ¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿æ¨¡å‹ç»“æ„ç¬¦åˆ ONNX è§„èŒƒ
check_model(onnx_model)

# åˆ é™¤åŸæœ‰çš„ opset
del onnx_model.opset_import[:]

# æ·»åŠ æ–°çš„ opset
opset = onnx_model.opset_import.add()
opset.domain = ''
opset.version = 15

# è®¾ç½® ONNX æ¨¡å‹çš„ IR ç‰ˆæœ¬å’Œæ–‡æ¡£å­—ç¬¦ä¸²
onnx_model.ir_version = 8
onnx_model.doc_string = 'è¿™æ˜¯ä¸€ä¸ªæ¶‰åŠåˆ° if-else è¯­å¥çš„ ONNX æ¨¡å‹'

# ä¿å­˜æ¨¡å‹
model_save_path = 'ONNX/saves/if-else.onnx'
onnx.save(onnx_model, model_save_path)

print(onnx_model)

# -------------------------- æ¨ç† --------------------------
# åˆ›å»ºæ¨ç†ä¼šè¯ï¼ŒåŠ è½½ä¿å­˜çš„ ONNX æ¨¡å‹
session = InferenceSession(path_or_bytes=model_save_path, 
                           providers=['CPUExecutionProvider'])

# åˆ›å»ºè¾“å…¥å¼ é‡ï¼Œå…¨ä¸º1ï¼Œå½¢çŠ¶ä¸º[3, 2]ï¼Œæ•°æ®ç±»å‹ä¸ºnp.float32
input_tensor = np.ones(shape=[3, 2], dtype=np.float32)

# è¿è¡Œæ¨ç†ï¼Œè·å–è¾“å‡ºå¼ é‡
output_tensor = session.run(output_names=None, 
                            input_feed={'X': input_tensor})

# æ‰“å°è¾“å‡ºå¼ é‡
print(f"output: {output_tensor}")
```

```
ir_version: 8
opset_import {
  domain: ""
  version: 15
}
doc_string: "è¿™æ˜¯ä¸€ä¸ªæ¶‰åŠåˆ° if-else è¯­å¥çš„ ONNX æ¨¡å‹"
graph {
  node {
    input: "X"
    output: "rsum"
    op_type: "ReduceSum"
  }
  node {
    input: "rsum"
    input: "zero"
    output: "cond"
    op_type: "Greater"
  }
  node {
    input: "cond"
    output: "Y"
    op_type: "If"
    attribute {
      name: "else_branch"
      type: GRAPH
      g {
        node {
          output: "else_out"
          name: "cst2"
          op_type: "Constant"
          attribute {
            name: "value"
            type: TENSOR
            t {
              dims: 1
              data_type: 1
              raw_data: "\000\000\200\277"
            }
          }
        }
        name: "else_body"
        output {
          name: "else_out"
          type {
            tensor_type {
              elem_type: 1
              shape {
                dim {
                  dim_value: 5
                }
              }
            }
          }
        }
      }
    }
    attribute {
      name: "then_branch"
      type: GRAPH
      g {
        node {
          output: "then_out"
          name: "cst1"
          op_type: "Constant"
          attribute {
            name: "value"
            type: TENSOR
            t {
              dims: 1
              data_type: 1
              raw_data: "\000\000\200?"
            }
          }
        }
        name: "then_body"
        output {
          name: "then_out"
          type {
            tensor_type {
              elem_type: 1
            }
          }
        }
      }
    }
  }
  name: "if"
  initializer {
    dims: 1
    data_type: 1
    name: "zero"
    raw_data: "\000\000\000\000"
  }
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}

output: [array([1.], dtype=float32)]
```

ğŸ’¡ **å‚æ•°è¯´æ˜**ï¼š
1. åœ¨ ONNX Runtime ä¸­ï¼Œ`providers` å‚æ•°æŒ‡å®šäº†åœ¨æ¨ç†æ—¶ä½¿ç”¨çš„æ‰§è¡Œæä¾›ç¨‹åºï¼ˆExecution Providerï¼‰ã€‚Execution Provider æ˜¯ ONNX Runtime æä¾›çš„ä¸åŒåç«¯çš„å®ç°ï¼Œç”¨äºåœ¨ä¸åŒç¡¬ä»¶ä¸Šè¿›è¡Œæ¨ç†ã€‚å¸¸è§çš„ Execution Providers åŒ…æ‹¬ `CPUExecutionProvider`ã€`CUDAExecutionProvider`ï¼ˆç”¨äº NVIDIA GPUï¼‰ã€`DnnlExecutionProvider`ï¼ˆç”¨äº Intel CPU ä½¿ç”¨ DNNLï¼‰ã€`TensorRTExecutionProvider`ï¼ˆç”¨äº NVIDIA GPU ä½¿ç”¨ TensorRTï¼‰ç­‰ã€‚
2. `output_names` æ˜¯åœ¨ ONNX Runtime æ¨ç†è¿‡ç¨‹ä¸­ç”¨äºæŒ‡å®šè¾“å‡ºå¼ é‡çš„åç§°çš„å‚æ•°ã€‚å®ƒå…è®¸ç”¨æˆ·é€‰æ‹©æ€§åœ°è·å–æ¨¡å‹ä¸­ç‰¹å®šè¾“å‡ºå¼ é‡çš„å€¼ã€‚åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`output_names=None` è¡¨ç¤ºè·å–æ‰€æœ‰è¾“å‡ºå¼ é‡çš„å€¼ã€‚å¦‚æœæƒ³è¦ä»…è·å–æ¨¡å‹ä¸­ç‰¹å®šè¾“å‡ºå¼ é‡çš„å€¼ï¼Œå¯ä»¥å°† `output_names` è®¾ç½®ä¸ºä¸€ä¸ªåŒ…å«æ‰€éœ€è¾“å‡ºå¼ é‡åç§°çš„åˆ—è¡¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹æœ‰ä¸¤ä¸ªè¾“å‡ºå¼ é‡ï¼Œåˆ†åˆ«å‘½åä¸º `'output1'` å’Œ `'output2'`ï¼Œå¯ä»¥ä½¿ç”¨ `output_names=['output1']` æ¥æŒ‡å®šåªè·å– `'output1'` å¯¹åº”çš„è¾“å‡ºå¼ é‡çš„å€¼ã€‚
3. `input_feed` æ˜¯åœ¨ ONNX Runtime æ¨ç†è¿‡ç¨‹ä¸­ç”¨äºæä¾›è¾“å…¥æ•°æ®çš„å‚æ•°ã€‚å®ƒæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯æ¨¡å‹å®šä¹‰ä¸­è¾“å…¥å¼ é‡çš„åç§°ï¼Œè€Œå€¼æ˜¯å¯¹åº”çš„è¾“å…¥æ•°æ®ã€‚åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`input_feed={'X': input_tensor}` æ„å‘³ç€å°†è¾“å…¥å¼ é‡ `input_tensor` æä¾›ç»™æ¨¡å‹ä¸­åä¸º `'X'` çš„è¾“å…¥å¼ é‡ã€‚å…·ä½“æ¥è¯´ï¼Œ`'X'` æ˜¯é€šè¿‡ `make_tensor_value_info` åˆ›å»ºçš„è¾“å…¥å¼ é‡ä¿¡æ¯çš„åç§°ã€‚é€šè¿‡ `input_feed` å‚æ•°ï¼Œå¯ä»¥åœ¨è¿›è¡Œæ¨ç†æ—¶å°†æ¨¡å‹çš„è¾“å…¥ç”¨å…·ä½“çš„æ•°æ®å¡«å……ï¼Œä»¥è·å–å¯¹åº”çš„è¾“å‡ºã€‚

---

ä¸Šé¢ä»£ç çš„å¯è§†åŒ–å¦‚ä¸‹ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-01-23-17-33-07.png
    width=80%>
</div>

`else` å’Œ `then` åˆ†æ”¯éƒ½éå¸¸ç®€å•ã€‚`If` èŠ‚ç‚¹ç”šè‡³å¯ä»¥è¢«æ›¿æ¢ä¸ºä¸€ä¸ª `Where` èŠ‚ç‚¹ï¼Œè¿™æ ·å¯èƒ½æ›´å¿«ã€‚å½“ä¸¤ä¸ªåˆ†æ”¯éƒ½æ›´å¤§ä¸”è·³è¿‡å…¶ä¸­ä¸€ä¸ªæ›´æœ‰æ•ˆæ—¶ï¼Œæƒ…å†µå°±å˜å¾—æœ‰è¶£äº†ã€‚

## 2.9 Functions

æ­£å¦‚å‰é¢æ‰€æåˆ°çš„ï¼Œå‡½æ•°å¯ç”¨äºç¼©çŸ­æ„å»ºæ¨¡å‹çš„ä»£ç ï¼Œå¹¶ä¸”åœ¨è¿è¡Œé¢„æµ‹æ—¶æä¾›æ›´å¤šå¯èƒ½æ€§ï¼Œå¦‚æœå­˜åœ¨è¯¥å‡½æ•°çš„ç‰¹å®šå®ç°ï¼Œè¿è¡Œæ—¶å¯ä»¥æ›´å¿«ã€‚å¦‚æœä¸æ˜¯è¿™ç§æƒ…å†µï¼Œè¿è¡Œæ—¶ä»ç„¶å¯ä»¥ä½¿ç”¨åŸºäºç°æœ‰è¿ç®—ç¬¦çš„é»˜è®¤å®ç°ã€‚

`make_function` å‡½æ•°ç”¨äºå®šä¹‰ä¸€ä¸ªå‡½æ•°ã€‚å®ƒç±»ä¼¼äºä¸€ä¸ªå›¾ï¼Œä½†ç±»å‹æ›´å°‘ï¼Œæ›´åƒæ˜¯ä¸€ä¸ªæ¨¡æ¿ã€‚è¿™ä¸ª API å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚å®ƒä¹Ÿä¸åŒ…æ‹¬åˆå§‹åŒ–å™¨ã€‚

### 2.9.1 A function with no attributeï¼Œæ²¡æœ‰å±æ€§çš„å‡½æ•°

è¿™æ˜¯æ›´ç®€å•çš„æƒ…å†µï¼Œå³å‡½æ•°çš„æ¯ä¸ªè¾“å…¥éƒ½æ˜¯åœ¨æ‰§è¡Œæ—¶å·²çŸ¥çš„åŠ¨æ€å¯¹è±¡ã€‚

```python
import numpy as np
import onnx
from onnx import numpy_helper, TensorProto
from onnx.helper import (make_tensor_value_info, make_tensor, make_function, 
                         make_node, make_graph, make_model, set_model_props,
                         make_opsetid)
from onnx.checker import check_model


# -------------------------- å®šä¹‰ä¸€ä¸ªçº¿æ€§å›å½’çš„å‡½æ•° --------------------------
# æ–°çš„é¢†åŸŸåç§°
new_domain = 'custom_domain'

# æ„å»º opset_imports åˆ—è¡¨ï¼ŒåŒ…å«ä¸¤ä¸ª OpsetIDï¼Œåˆ†åˆ«ä¸ºé»˜è®¤é¢†åŸŸå’Œè‡ªå®šä¹‰é¢†åŸŸ
opset_imports = [
    make_opsetid(domain="", version=14),
    make_opsetid(domain=new_domain, version=1)
]

# åˆ›å»ºçŸ©é˜µç›¸ä¹˜èŠ‚ç‚¹ï¼Œè¾“å…¥ä¸º 'X' å’Œ 'A'ï¼Œè¾“å‡ºä¸º 'XA'
node1 = make_node('MatMul', ['X', 'A'], ['XA'])

# åˆ›å»ºåŠ æ³•èŠ‚ç‚¹ï¼Œè¾“å…¥ä¸º 'XA' å’Œ 'B'ï¼Œè¾“å‡ºä¸º 'Y'
node2 = make_node('Add', ['XA', 'B'], ['Y'])

linear_regression = make_function(
    domain=new_domain,  # ä½œç”¨åŸŸåç§°ï¼ˆæŒ‡å®šå‡½æ•°çš„ä½œç”¨åŸŸåç§°ï¼‰
    fname='LinearRegression',  # å‡½æ•°åç§°ï¼ˆæŒ‡å®šå‡½æ•°çš„åç§°ï¼‰
    inputs=['X', 'A', 'B'],  # è¾“å…¥çš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„è¾“å…¥å¼ é‡çš„åç§°åˆ—è¡¨ï¼‰
    outputs=['Y'],  # è¾“å‡ºçš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„è¾“å‡ºå¼ é‡çš„åç§°åˆ—è¡¨ï¼‰
    nodes=[node1, node2],  # ä½¿ç”¨åˆ°çš„èŠ‚ç‚¹ï¼ˆå®šä¹‰å‡½æ•°ä½¿ç”¨åˆ°çš„èŠ‚ç‚¹åˆ—è¡¨ï¼‰
    opset_imports=opset_imports,  # opsetï¼ˆæŒ‡å®š OpsetID åˆ—è¡¨ï¼Œå®šä¹‰å‡½æ•°ä½¿ç”¨çš„è¿ç®—ç¬¦ç‰ˆæœ¬ï¼‰
    attributes=[],  # å±æ€§çš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„å±æ€§åˆ—è¡¨ï¼‰
)

# -------------------------- å®šä¹‰å›¾ --------------------------
X = make_tensor_value_info(name='X', elem_type=TensorProto.FLOAT, shape=[None, None])
A = make_tensor_value_info(name='A', elem_type=TensorProto.FLOAT, shape=[None, None])
B = make_tensor_value_info(name='B', elem_type=TensorProto.FLOAT, shape=[None, None])
Y = make_tensor_value_info(name='Y', elem_type=TensorProto.FLOAT, shape=[None])

graph = make_graph(
    nodes=[make_node(op_type='LinearRegression', inputs=['X', 'A', 'B'], outputs=['Y1'], domain=new_domain),
           make_node(op_type='Abs', inputs=['Y1'], outputs=['Y'])],
    name='example',
    inputs=[X, A, B],
    outputs=[Y]
)

# -------------------------- å®šä¹‰æ¨¡å‹ --------------------------
onnx_model = make_model(graph=graph, 
                        opset_imports=opset_imports,
                        functions=[linear_regression])
check_model(onnx_model)

print(onnx_model)
```

```
ir_version: 9
opset_import {
  domain: ""
  version: 14
}
opset_import {
  domain: "custom_domain"
  version: 1
}
graph {
  node {
    input: "X"
    input: "A"
    input: "B"
    output: "Y1"
    op_type: "LinearRegression"
    domain: "custom_domain"
  }
  node {
    input: "Y1"
    output: "Y"
    op_type: "Abs"
  }
  name: "example"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "B"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
functions {
  name: "LinearRegression"
  input: "X"
  input: "A"
  input: "B"
  output: "Y"
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  opset_import {
    domain: ""
    version: 14
  }
  opset_import {
    domain: "custom_domain"
    version: 1
  }
  domain: "custom_domain"
}
```

<div align=center>
  <div align=half>
      <img src=./imgs_markdown/2024-01-24-11-12-43.png
      width=50%>
      <img src=./imgs_markdown/2024-01-24-11-13-00.png
      width=50%>
  </div>
</div>

### 2.9.2 A function with attributeï¼Œæœ‰å±æ€§çš„å‡½æ•°

ä¸‹é¢çš„å‡½æ•°ä¸å‰ä¸€ä¸ªå‡½æ•°ç­‰æ•ˆï¼Œåªæ˜¯ä¸€ä¸ªè¾“å…¥ $B$ è¢«è½¬æ¢ä¸ºåä¸º $bias$ çš„å‚æ•°ã€‚ä»£ç å‡ ä¹ç›¸åŒï¼Œåªæ˜¯ç°åœ¨åç½®æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚åœ¨å‡½æ•°å®šä¹‰å†…éƒ¨ï¼Œåˆ›å»ºäº†ä¸€ä¸ªèŠ‚ç‚¹ $Constant$ï¼Œå°†å‚æ•°æ’å…¥ä¸ºä¸€ä¸ªç»“æœã€‚å®ƒä¸å‚æ•°ä¹‹é—´é€šè¿‡å±æ€§ `ref_attr_name` è¿›è¡Œå…³è”ã€‚

```python
import numpy as np
import onnx
from onnx import numpy_helper, TensorProto, AttributeProto
from onnx.helper import (make_tensor_value_info, make_tensor, make_function, 
                         make_node, make_graph, make_model, set_model_props,
                         make_opsetid)
from onnx.checker import check_model


# -------------------------- å®šä¹‰ä¸€ä¸ªçº¿æ€§å›å½’çš„å‡½æ•° --------------------------
# æ–°çš„é¢†åŸŸåç§°
new_domain = 'custom_domain'

# æ„å»º opset_imports åˆ—è¡¨ï¼ŒåŒ…å«ä¸¤ä¸ª OpsetIDï¼Œåˆ†åˆ«ä¸ºé»˜è®¤é¢†åŸŸå’Œè‡ªå®šä¹‰é¢†åŸŸ
opset_imports = [
    make_opsetid(domain="", version=14),
    make_opsetid(domain=new_domain, version=1)
]

# ç¬¬ä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªä¸å‡½æ•°çš„è¾“å…¥å‚æ•°ç›¸ç­‰çš„å¸¸æ•°
cst = make_node(op_type='Constant', inputs=[], outputs=['B'])

att = AttributeProto()
att.name = 'value'

# è¿™è¡Œä»£ç æŒ‡ç¤ºè¯¥å€¼æ¥è‡ªå‡½æ•°æ‰€ç»™å®šçš„åä¸º 'bias' çš„å‚æ•°
att.ref_attr_name = 'bias'
att.type = AttributeProto.TENSOR
cst.attribute.append(att)

node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

linear_regression = make_function(
    domain=new_domain,  # ä½œç”¨åŸŸåç§°ï¼ˆæŒ‡å®šå‡½æ•°çš„ä½œç”¨åŸŸåç§°ï¼‰
    fname='LinearRegression',  # å‡½æ•°åç§°ï¼ˆæŒ‡å®šå‡½æ•°çš„åç§°ï¼‰
    inputs=['X', 'A'],  # è¾“å…¥çš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„è¾“å…¥å¼ é‡çš„åç§°åˆ—è¡¨ï¼‰
    outputs=['Y'],  # è¾“å‡ºçš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„è¾“å‡ºå¼ é‡çš„åç§°åˆ—è¡¨ï¼‰
    nodes=[cst, node1, node2],  # ä½¿ç”¨åˆ°çš„èŠ‚ç‚¹ï¼ˆå®šä¹‰å‡½æ•°ä½¿ç”¨åˆ°çš„èŠ‚ç‚¹åˆ—è¡¨ï¼‰
    opset_imports=opset_imports,  # opsetï¼ˆæŒ‡å®š OpsetID åˆ—è¡¨ï¼Œå®šä¹‰å‡½æ•°ä½¿ç”¨çš„è¿ç®—ç¬¦ç‰ˆæœ¬ï¼‰
    attributes=[],  # å±æ€§çš„åç§°ï¼ˆå®šä¹‰å‡½æ•°çš„å±æ€§åˆ—è¡¨ï¼‰
)

# -------------------------- å®šä¹‰å›¾ --------------------------
X = make_tensor_value_info(name='X', elem_type=TensorProto.FLOAT, shape=[None, None])
A = make_tensor_value_info(name='A', elem_type=TensorProto.FLOAT, shape=[None, None])
B = make_tensor_value_info(name='B', elem_type=TensorProto.FLOAT, shape=[None, None])
Y = make_tensor_value_info(name='Y', elem_type=TensorProto.FLOAT, shape=[None])

graph = make_graph(
    nodes=[make_node(op_type='LinearRegression', 
                     inputs=['X', 'A'], outputs=['Y1'], 
                     domain=new_domain, bias=make_tensor('former_B', TensorProto.FLOAT, 
                                                         dims=[1], vals=[0.67])),
           make_node(op_type='Abs', inputs=['Y1'], outputs=['Y'])],
    name='example',
    inputs=[X, A],
    outputs=[Y]
)

# -------------------------- å®šä¹‰æ¨¡å‹ --------------------------
onnx_model = make_model(graph=graph, 
                        opset_imports=opset_imports,
                        functions=[linear_regression])
check_model(onnx_model)

print(onnx_model)

model_save_path = 'ONNX/saves/function-with_attribute.onnx'
onnx.save(onnx_model, model_save_path)
```

```
ir_version: 9
opset_import {
  domain: ""
  version: 14
}
opset_import {
  domain: "custom_domain"
  version: 1
}
graph {
  node {
    input: "X"
    input: "A"
    output: "Y1"
    op_type: "LinearRegression"
    domain: "custom_domain"
    attribute {
      name: "bias"
      type: TENSOR
      t {
        dims: 1
        data_type: 1
        float_data: 0.67
        name: "former_B"
      }
    }
  }
  node {
    input: "Y1"
    output: "Y"
    op_type: "Abs"
  }
  name: "example"
  input {
    name: "X"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  input {
    name: "A"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
          dim {
          }
        }
      }
    }
  }
  output {
    name: "Y"
    type {
      tensor_type {
        elem_type: 1
        shape {
          dim {
          }
        }
      }
    }
  }
}
functions {
  name: "LinearRegression"
  input: "X"
  input: "A"
  output: "Y"
  node {
    output: "B"
    op_type: "Constant"
    attribute {
      name: "value"
      ref_attr_name: "bias"
      type: TENSOR
    }
  }
  node {
    input: "X"
    input: "A"
    output: "XA"
    op_type: "MatMul"
  }
  node {
    input: "XA"
    input: "B"
    output: "Y"
    op_type: "Add"
  }
  opset_import {
    domain: ""
    version: 14
  }
  opset_import {
    domain: "custom_domain"
    version: 1
  }
  domain: "custom_domain"
}
```

<div align=center>
  <div align=half>
      <img src=./imgs_markdown/2024-01-24-11-34-35.png
      width=50%>
      <img src=./imgs_markdown/2024-01-24-11-34-51.png
      width=50%>
  </div>
</div>

# 3. Evaluation and Runtimeï¼Œæ¨¡å‹è¯„ä¼°å’Œè¿è¡Œæ—¶é—´

ONNX æ ‡å‡†å…è®¸æ¡†æ¶ä»¥ ONNX æ ¼å¼å¯¼å‡ºè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¹¶ä¸”æ”¯æŒä½¿ç”¨ä»»ä½•æ”¯æŒ ONNX æ ¼å¼çš„åç«¯è¿›è¡Œæ¨ç†ã€‚onnxruntime æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„é€‰æ‹©ï¼Œå¯åœ¨è®¸å¤šå¹³å°ä¸Šä½¿ç”¨ã€‚å®ƒç»è¿‡ä¼˜åŒ–ï¼Œä»¥å®ç°å¿«é€Ÿæ¨ç†ã€‚å…¶è¦†ç›–èŒƒå›´å¯ä»¥åœ¨ ONNX åç«¯ä»ªè¡¨æ¿ä¸Šè·Ÿè¸ªã€‚onnx è¿˜å®ç°äº†ä¸€ä¸ªç”¨äºå¸®åŠ©ç†è§£æ¨¡å‹çš„ Python è¿è¡Œæ—¶ã€‚<font color='blue'>å®ƒå¹¶ä¸æ‰“ç®—ç”¨äºç”Ÿäº§ï¼Œæ€§èƒ½ä¹Ÿä¸æ˜¯å…¶ç›®æ ‡</font>ã€‚

> ğŸ’¡ åªæ˜¯ç”¨äºç†è§£æ¨¡å‹æ—¶æ€§èƒ½ä¸æ˜¯ç›®æ ‡ï¼Œæ—¥å¸¸ä½¿ç”¨çš„è¯ï¼ŒONNX è¿˜æ˜¯æŒºé«˜æ•ˆçš„ã€‚

## 3.1 Evaluation of a linear regressionï¼Œè¯„ä¼°ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹

å®Œæ•´çš„ API æ–‡æ¡£å¯ä»¥åœ¨ `onnx.reference` ä¸­æ‰¾åˆ°ã€‚å®ƒæ¥å—ä¸€ä¸ªæ¨¡å‹ï¼ˆä¸€ä¸ª ModelProtoï¼Œä¸€ä¸ªæ–‡ä»¶åç­‰ï¼‰ã€‚`run` æ–¹æ³•æ ¹æ®åœ¨å­—å…¸ä¸­æŒ‡å®šçš„ä¸€ç»„è¾“å…¥è¿”å›è¾“å‡ºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator


# -------------------------- ä¸å˜ --------------------------
X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])

graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])

onnx_model = make_model(graph)
check_model(onnx_model)

# -------------------------- æ¨¡å‹è¯„ä¼° --------------------------
# åˆ›å»º ReferenceEvaluator å¯¹è±¡ï¼Œç”¨äºè¿è¡Œ ONNX æ¨¡å‹
sess = ReferenceEvaluator(onnx_model)

# ç”Ÿæˆéšæœºè¾“å…¥æ•°æ®
x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 1).astype(numpy.float32)
b = numpy.random.randn(1, 1).astype(numpy.float32)

# å°†è¾“å…¥æ•°æ®æ”¾å…¥å­—å…¸ä¸­
feeds = {'X': x, 'A': a, 'B': b}

# ä½¿ç”¨ ReferenceEvaluator å¯¹è±¡è¿è¡Œæ¨¡å‹ï¼Œè·å–è¾“å‡ºç»“æœ
result = sess.run(None, feeds)

print(f"The model result is: \n{result}\n"
      f"It's type: {type(result)}\n"
      f"Specific type: {type(result[0])}")
```

```
The model result is: 
[array([[0.49450195],
       [0.5288675 ],
       [0.25783658],
       [1.0908649 ]], dtype=float32)]
It's type: <class 'list'>
Specific type: <class 'numpy.ndarray'>
```

## 3.2 Evaluation of a node, è¯„ä¼°æŸä¸€ä¸ªèŠ‚ç‚¹

è¯„ä¼°å™¨è¿˜å¯ä»¥è¯„ä¼°ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ï¼Œä»¥æ£€æŸ¥è¿ç®—ç¬¦åœ¨ç‰¹å®šè¾“å…¥ä¸Šçš„è¡Œä¸ºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import make_node
from onnx.reference import ReferenceEvaluator


node = make_node('EyeLike', ['X'], ['Y'])

sess = ReferenceEvaluator(node)

x = numpy.random.randn(4, 2).astype(numpy.float32)
feeds = {'X': x}

result = sess.run(None, feeds)

print(f"The node result is: \n{result}\n"
      f"It's type: {type(result)}\n"
      f"Specific type: {type(result[0])}")
```

```
The node result is: 
[array([[1., 0.],
       [0., 1.],
       [0., 0.],
       [0., 0.]], dtype=float32)]
It's type: <class 'list'>
Specific type: <class 'numpy.ndarray'>
```

> ğŸ’¡ ç±»ä¼¼çš„ä»£ç ä¹Ÿå¯ä»¥åœ¨ GraphProto æˆ– FunctionProto ä¸Šè¿è¡Œã€‚

## 3.3 Evaluation Step by Stepï¼Œä¸€æ­¥ä¸€æ­¥çš„è¯„ä¼°

è½¬æ¢åº“æ¥æ”¶ä¸€ä¸ªç”¨æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ `pytorch`ã€`scikit-learn` ç­‰ï¼‰è®­ç»ƒçš„ç°æœ‰æ¨¡å‹ï¼Œå°†è¯¥æ¨¡å‹è½¬æ¢ä¸ºä¸€ä¸ª ONNX å›¾ã€‚é€šå¸¸ï¼Œå¤æ‚çš„æ¨¡å‹åœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œï¼ŒæŸ¥çœ‹ä¸­é—´ç»“æœå¯èƒ½æœ‰åŠ©äºæ‰¾åˆ°ä¸æ­£ç¡®è½¬æ¢çš„éƒ¨åˆ†ï¼Œä½¿ç”¨å‚æ•° `verbose` ç”¨äºæ˜¾ç¤ºæœ‰å…³ä¸­é—´ç»“æœçš„ä¿¡æ¯ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ï¼š

```python
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator


X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node1 = make_node('MatMul', ['X', 'A'], ['XA'])
node2 = make_node('Add', ['XA', 'B'], ['Y'])
graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)

for verbose in [1, 2, 3, 4]:
      print()
      print(f"------ verbose={verbose}")
      print()
      sess = ReferenceEvaluator(onnx_model, verbose=verbose)

      x = numpy.random.randn(4, 2).astype(numpy.float32)
      a = numpy.random.randn(2, 1).astype(numpy.float32)
      b = numpy.random.randn(1, 1).astype(numpy.float32)
      feeds = {'X': x, 'A': a, 'B': b}

      result = sess.run(None, feeds)

      print(f"No.{verbose} result is: \n{result}")
```

```
------ verbose=1

No.1 result is: 
[array([[1.3466744],
       [1.4322073],
       [1.4926268],
       [1.3633491]], dtype=float32)]

------ verbose=2

MatMul(X, A) -> XA
Add(XA, B) -> Y
No.2 result is:
[array([[ 0.6492353 ],
       [ 0.22668248],
       [-1.3016735 ],
       [-0.14969295]], dtype=float32)]

------ verbose=3

 +I X: float32:(4, 2) in [-1.3570822477340698, 0.5996934771537781]
 +I A: float32:(2, 1) in [-1.163417100906372, -0.8546339869499207]
 +I B: float32:(1, 1) in [0.16759172081947327, 0.16759172081947327]
MatMul(X, A) -> XA
 + XA: float32:(4, 1) in [-1.0257296562194824, 1.317176342010498]
Add(XA, B) -> Y
 + Y: float32:(4, 1) in [-0.8581379652023315, 1.484768033027649]
No.3 result is:
[array([[ 1.484768  ],
       [ 0.24345586],
       [-0.85813797],
       [ 1.3841225 ]], dtype=float32)]

------ verbose=4

 +I X: float32:(4, 2):-0.06228995695710182,-0.5402382016181946,0.855003833770752,0.023194529116153717,-1.138258934020996...
 +I A: float32:(2, 1):[2.67880916595459, 1.616241216659546]
 +I B: float32:(1, 1):[-0.08334967494010925]
MatMul(X, A) -> XA
 + XA: float32:(4, 1):[-1.040018081665039, 2.3278801441192627, -3.307098865509033, -1.5567586421966553]
Add(XA, B) -> Y
 + Y: float32:(4, 1):[-1.1233677864074707, 2.244530439376831, -3.390448570251465, -1.640108346939087]
No.4 result is:
[array([[-1.1233678],
       [ 2.2445304],
       [-3.3904486],
       [-1.6401083]], dtype=float32)]
```

## 3.4 Evaluate a custom nodeï¼Œè¯„ä¼°ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠ‚ç‚¹ {##è¯„ä¼°ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠ‚ç‚¹}

ä¸‹é¢çš„ä¾‹å­ä»ç„¶å®ç°äº†ä¸€ä¸ªçº¿æ€§å›å½’ï¼Œä½†åœ¨ $A$ ä¸Šæ·»åŠ äº†å•ä½çŸ©é˜µï¼š

$$
Y = X(A + I) + B
$$

```python
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info)
from onnx.checker import check_model
from onnx.reference import ReferenceEvaluator

X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])
node0 = make_node('EyeLike', ['A'], ['Eye'])
node1 = make_node('Add', ['A', 'Eye'], ['A1'])
node2 = make_node('MatMul', ['X', 'A1'], ['XA1'])
node3 = make_node('Add', ['XA1', 'B'], ['Y'])
graph = make_graph([node0, node1, node2, node3], 'lr', [X, A, B], [Y])
onnx_model = make_model(graph)
check_model(onnx_model)
with open("ONNX/saves/linear_regression.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

sess = ReferenceEvaluator(onnx_model, verbose=2)

x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 2).astype(numpy.float32) / 10
b = numpy.random.randn(1, 2).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

result = sess.run(None, feeds)

print(f"Result is: \n{result}")
```

```
EyeLike(A) -> Eye
Add(A, Eye) -> A1
MatMul(X, A1) -> XA1
Add(XA1, B) -> Y
Result is:
[array([[ 0.48974502,  1.777401  ],
       [-0.90059066, -0.81312126],
       [-1.9505675 ,  0.43714556],
       [-1.9263479 , -1.0114272 ]], dtype=float32)]
```

å¦‚æœæˆ‘ä»¬å°†è¿ç®—ç¬¦ $EyeLike$ å’Œ $Add$ ç»“åˆæˆ $AddEyeLike$ï¼Œé‚£ä¹ˆæ˜¯å¦å¯ä»¥æ˜¯çš„æ¨ç†æ›´åŠ é«˜æ•ˆå‘¢ï¼Ÿä¸‹ä¸€ä¸ªä¾‹å­å°†è¿™ä¸¤ä¸ªè¿ç®—ç¬¦æ›¿æ¢ä¸ºæ¥è‡ªé¢†åŸŸ `'optimized'` çš„å•ä¸ªè¿ç®—ç¬¦ã€‚

```python
import numpy
from onnx import numpy_helper, TensorProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid)
from onnx.checker import check_model


X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])
A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])
B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])
Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])

node01 = make_node('AddEyeLike', ['A'], ['A1'], domain='optimized')

node2 = make_node('MatMul', ['X', 'A1'], ['XA1'])
node3 = make_node('Add', ['XA1', 'B'], ['Y'])
graph = make_graph([node01, node2, node3], 'lr', [X, A, B], [Y])

onnx_model = make_model(graph, opset_imports=[
    make_opsetid('', 18), make_opsetid('optimized', 1)
])

check_model(onnx_model)
with open("ONNX/saves/linear_regression_improved.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())
```

æˆ‘ä»¬éœ€è¦è¯„ä¼°è¿™ä¸ªæ¨¡å‹æ˜¯å¦ç­‰ä»·äºç¬¬ä¸€ä¸ªæ¨¡å‹ã€‚è¿™éœ€è¦ä¸ºè¿™ä¸ªç‰¹å®šçš„èŠ‚ç‚¹å®ç°ä¸€ä¸ªåŠŸèƒ½ã€‚

```python
import numpy
from onnx.reference import ReferenceEvaluator
from onnx.reference.op_run import OpRun


class AddEyeLike(OpRun):
    op_domain = "optimized"

    def _run(self, X, alpha=1.):
        assert len(X.shape) == 2
        assert X.shape[0] == X.shape[1]
        X = X.copy()
        ind = numpy.diag_indices(X.shape[0])
        X[ind] += alpha
        return (X,)

sess = ReferenceEvaluator("ONNX/saves/linear_regression_improved.onnx", verbose=2, new_ops=[AddEyeLike])

x = numpy.random.randn(4, 2).astype(numpy.float32)
a = numpy.random.randn(2, 2).astype(numpy.float32) / 10
b = numpy.random.randn(1, 2).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

print(sess.run(None, feeds))

# Let's check with the previous model.
sess0 = ReferenceEvaluator("ONNX/saves/linear_regression.onnx",)
sess1 = ReferenceEvaluator("ONNX/saves/linear_regression_improved.onnx", new_ops=[AddEyeLike])

y0 = sess0.run(None, feeds)[0]
y1 = sess1.run(None, feeds)[0]
print(y0)
print(y1)
print(f"difference: {numpy.abs(y0 - y1).max()}")
```

```
AddEyeLike(A) -> A1
MatMul(X, A1) -> XA1
Add(XA1, B) -> Y
[array([[-0.42936724, -0.59607476],
       [-1.8834507 , -0.9946752 ],
       [ 1.0796697 , -0.16089936],
       [ 0.3997272 , -1.9825854 ]], dtype=float32)]
[[-0.42936724 -0.59607476]
 [-1.8834507  -0.9946752 ]
 [ 1.0796697  -0.16089936]
 [ 0.3997272  -1.9825854 ]]
[[-0.42936724 -0.59607476]
 [-1.8834507  -0.9946752 ]
 [ 1.0796697  -0.16089936]
 [ 0.3997272  -1.9825854 ]]
difference: 0.0
```

é¢„æµ‹æ˜¯ç›¸åŒçš„ã€‚è®©æˆ‘ä»¬æ¯”è¾ƒåœ¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„çŸ©é˜µä¸Šçš„æ€§èƒ½ï¼Œä»¥ä¾¿çœ‹åˆ°æ˜¾è‘—çš„å·®å¼‚ã€‚

```python
import timeit
import numpy
from onnx.reference import ReferenceEvaluator
from onnx.reference.op_run import OpRun


class AddEyeLike(OpRun):
    op_domain = "optimized"

    def _run(self, X, alpha=1.):
        assert len(X.shape) == 2
        assert X.shape[0] == X.shape[1]
        X = X.copy()
        ind = numpy.diag_indices(X.shape[0])
        X[ind] += alpha
        return (X,)


sess = ReferenceEvaluator("ONNX/saves/linear_regression_improved.onnx", verbose=2, new_ops=[AddEyeLike])

x = numpy.random.randn(4, 100).astype(numpy.float32)
a = numpy.random.randn(100, 100).astype(numpy.float32) / 10
b = numpy.random.randn(1, 100).astype(numpy.float32)
feeds = {'X': x, 'A': a, 'B': b}

sess0 = ReferenceEvaluator("ONNX/saves/linear_regression.onnx")
sess1 = ReferenceEvaluator("ONNX/saves/linear_regression_improved.onnx", new_ops=[AddEyeLike])

y0 = sess0.run(None, feeds)[0]
y1 = sess1.run(None, feeds)[0]
print(f"difference: {numpy.abs(y0 - y1).max()}")
print(f"time with EyeLike+Add: {timeit.timeit(lambda: sess0.run(None, feeds), number=1000)}")
print(f"time with AddEyeLike: {timeit.timeit(lambda: sess1.run(None, feeds), number=1000)}")
```

```
difference: 0.0
time with EyeLike+Add: 0.09205669999937527
time with AddEyeLike: 0.12604709999868646
```

åœ¨è¿™ç§æƒ…å†µä¸‹ä¼¼ä¹å€¼å¾—æ·»åŠ ä¸€ä¸ªä¼˜åŒ–èŠ‚ç‚¹ã€‚è¿™ç§ä¼˜åŒ–é€šå¸¸è¢«ç§°ä¸º `fusion`ã€‚ä¸¤ä¸ªè¿ç»­çš„è¿ç®—ç¬¦è¢«èåˆæˆå®ƒä»¬çš„ä¼˜åŒ–ç‰ˆæœ¬ã€‚ç”Ÿäº§ç¯å¢ƒé€šå¸¸ä¾èµ–äº `onnxruntime`ï¼Œä½†ç”±äºè¿™ç§ä¼˜åŒ–ä½¿ç”¨åŸºæœ¬çš„çŸ©é˜µæ“ä½œï¼Œå®ƒåº”è¯¥åœ¨ä»»ä½•å…¶ä»–è¿è¡Œæ—¶ä¸Šå¸¦æ¥ç›¸åŒçš„æ€§èƒ½æå‡ã€‚

# 4. Implementation detailsï¼Œå®ç°ç»†èŠ‚

## 4.1 Python and C++

ONNX ä¾èµ–äº Protobuf æ¥å®šä¹‰å…¶ç±»å‹ã€‚ä½ å¯èƒ½ä¼šè®¤ä¸ºä¸€ä¸ª Python å¯¹è±¡åªæ˜¯åœ¨å†…éƒ¨ç»“æ„ä¸ŠåŒ…è£…äº†ä¸€ä¸ª C æŒ‡é’ˆã€‚å› æ­¤ï¼Œåº”è¯¥å¯ä»¥ä»æ¥æ”¶ `ModelProto` ç±»å‹çš„ Python å¯¹è±¡çš„å‡½æ•°ä¸­è®¿é—®å†…éƒ¨æ•°æ®ã€‚ä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚æ ¹æ® Protobuf 4 çš„æ›´æ”¹ï¼Œåœ¨ç‰ˆæœ¬ 4 ä¹‹åä¸å†å¯èƒ½è¿™æ ·åšï¼Œæ›´å®‰å…¨çš„åšæ³•æ˜¯å‡è®¾è·å–å†…å®¹çš„å”¯ä¸€æ–¹æ³•æ˜¯å°†æ¨¡å‹åºåˆ—åŒ–ä¸ºå­—èŠ‚ï¼Œä¼ é€’ç»™ C å‡½æ•°ï¼Œç„¶åå†è¿›è¡Œååºåˆ—åŒ–ã€‚åƒ `check_model` æˆ– `shape_inference` è¿™æ ·çš„å‡½æ•°åœ¨ä½¿ç”¨ C ä»£ç æ£€æŸ¥æ¨¡å‹ä¹‹å‰ï¼Œä¼šè°ƒç”¨ `SerializeToString`ï¼Œç„¶åå†è°ƒç”¨ `ParseFromString`ã€‚

## 4.2 Attributes and inputsï¼Œå±æ€§å’Œè¾“å…¥

è¿™ä¸¤è€…ä¹‹é—´æœ‰æ˜æ˜¾çš„åŒºåˆ«ã€‚è¾“å…¥æ˜¯åŠ¨æ€çš„ï¼Œå¯èƒ½åœ¨æ¯æ¬¡æ‰§è¡Œæ—¶éƒ½ä¼šæ”¹å˜ã€‚<font color='green'>å±æ€§ä»ä¸æ”¹å˜</font>ï¼Œä¼˜åŒ–å™¨å¯ä»¥å‡è®¾å®ƒæ°¸è¿œä¸ä¼šæ”¹å˜æ¥ä¼˜åŒ–æ‰§è¡Œå›¾ã€‚å› æ­¤ï¼Œâš ï¸ <u>å°†è¾“å…¥è½¬æ¢ä¸ºå±æ€§æ˜¯ä¸å¯èƒ½çš„</u>ã€‚ğŸ’¡ è€Œå¸¸é‡è¿ç®—ç¬¦æ˜¯å”¯ä¸€å°†å±æ€§è½¬æ¢ä¸ºè¾“å…¥çš„è¿ç®—ç¬¦ã€‚

## 4.3 Shape or no shapeï¼Œæœ‰å½¢çŠ¶å’Œæ²¡æœ‰å½¢çŠ¶

ONNX é€šå¸¸æœŸæœ›æ¯ä¸ªè¾“å…¥æˆ–è¾“å‡ºéƒ½æœ‰ä¸€ä¸ªå½¢çŠ¶ï¼Œå‡è®¾å·²çŸ¥ç§©ï¼ˆæˆ–ç»´åº¦çš„æ•°é‡ï¼‰ã€‚ä½†å¦‚æœæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªç»´åº¦åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„å›¾å‘¢ï¼Ÿè¿™ç§æƒ…å†µä»ç„¶ä»¤äººå›°æƒ‘ã€‚

```python
import numpy
from onnx import numpy_helper, TensorProto, FunctionProto
from onnx.helper import (
    make_model, make_node, set_model_props, make_tensor,
    make_graph, make_tensor_value_info, make_opsetid,
    make_function)
from onnx.checker import check_model
from onnxruntime import InferenceSession


def create_model(shapes):
    new_domain = 'custom'
    opset_imports = [make_opsetid("", 14), make_opsetid(new_domain, 1)]

    node1 = make_node('MatMul', ['X', 'A'], ['XA'])
    node2 = make_node('Add', ['XA', 'A'], ['Y'])

    X = make_tensor_value_info('X', TensorProto.FLOAT, shapes['X'])
    A = make_tensor_value_info('A', TensorProto.FLOAT, shapes['A'])
    Y = make_tensor_value_info('Y', TensorProto.FLOAT, shapes['Y'])

    graph = make_graph([node1, node2], 'example', [X, A], [Y])

    onnx_model = make_model(graph, opset_imports=opset_imports)
    # Let models runnable by onnxruntime with a released ir_version
    onnx_model.ir_version = 8

    return onnx_model


print("----------- case 1: 2D x 2D -> 2D")
onnx_model = create_model({'X': [None, None], 'A': [None, None], 'Y': [None, None]})
check_model(onnx_model)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2, 2).astype(numpy.float32)})
print(res)


print("----------- case 2: 2D x 1D -> 1D")
onnx_model = create_model({'X': [None, None], 'A': [None], 'Y': [None]})
check_model(onnx_model)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2).astype(numpy.float32)})
print(res)


print("----------- case 3: 2D x 0D -> 0D")
onnx_model = create_model({'X': [None, None], 'A': [], 'Y': []})
check_model(onnx_model)
try:
    InferenceSession(onnx_model.SerializeToString(),
                     providers=["CPUExecutionProvider"])
except Exception as e:
    print(e)


print("----------- case 4: 2D x None -> None")
onnx_model = create_model({'X': [None, None], 'A': None, 'Y': None})
try:
    check_model(onnx_model)
except Exception as e:
    print(type(e), e)
sess = InferenceSession(onnx_model.SerializeToString(),
                        providers=["CPUExecutionProvider"])
res = sess.run(None, {
    'X': numpy.random.randn(2, 2).astype(numpy.float32),
    'A': numpy.random.randn(2).astype(numpy.float32)})
print(res)
print("----------- end")
```

```
----------- case 1: 2D x 2D -> 2D
[array([[-0.17025554, -0.19959664],
       [ 2.4781291 ,  1.6193585 ]], dtype=float32)]
----------- case 2: 2D x 1D -> 1D
[array([-0.84798825, -0.75835514], dtype=float32)]
----------- case 3: 2D x 0D -> 0D
[ONNXRuntimeError] : 1 : FAIL : Node () Op (MatMul) [ShapeInferenceError] Input tensors of wrong rank (0).
----------- case 4: 2D x None -> None
<class 'onnx.onnx_cpp2py_export.checker.ValidationError'> Field 'shape' of 'type' is required but missing.
[array([ 0.6613703, -1.9580202], dtype=float32)]
----------- end
```

# çŸ¥è¯†æ¥æº

1. [ä½¿ç”¨ONNXéƒ¨ç½²æ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹](https://zhuanlan.zhihu.com/p/86867138)
2. [PyTorchè½¬ONNX-ç†è®ºç¯‡](https://zhuanlan.zhihu.com/p/272767300)
3. [ONNXå­¦ä¹ ç¬”è®°](https://zhuanlan.zhihu.com/p/346511883)
4. [ONNX Concepts](https://onnx.ai/onnx/intro/concepts.html#input-output-node-initializer-attributes)
5. [ONNX with Python](https://onnx.ai/onnx/intro/python.html)