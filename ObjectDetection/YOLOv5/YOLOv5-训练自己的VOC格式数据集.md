<center><b><font size=12>YOLOv5ï¼šè®­ç»ƒè‡ªå·±çš„ VOC æ ¼å¼æ•°æ®é›†</font></b></center>

# 1. è‡ªå®šä¹‰æ•°æ®é›†

## 1.1 ç¯å¢ƒå®‰è£…

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**æ³¨æ„**ï¼š
1. å®‰è£… `lxml`
2. Pillow ç‰ˆæœ¬è¦ä½äº 10.0.0ï¼Œè§£é‡Šé“¾æ¥: [module 'PIL.Image' has no attribute 'ANTIALIAS' é—®é¢˜å¤„ç†](https://baijiahao.baidu.com/s?id=1775432196700665405)

## 1.2 åˆ›å»ºæ•°æ®é›†

æˆ‘ä»¬è‡ªå·±ä¸‹è½½ PASCAL VOC ä¹Ÿè¡Œï¼ŒæŒ‰ç…§ PASCAL VOC è‡ªå»ºä¸€ä¸ªä¹Ÿè¡Œï¼Œå…·ä½“è¿‡ç¨‹è§ [PASCAL VOC 2012æ•°æ®é›†è®²è§£ä¸åˆ¶ä½œè‡ªå·±çš„æ•°æ®é›†](https://blog.csdn.net/weixin_44878336/article/details/124540069)ã€‚

> æ–‡ç« ä¸é•¿

## 1.3 PASCAL VOC æ•°æ®é›†ç»“æ„

PASCAL VOC æ•°æ®é›†ç»“æ„å¦‚ä¸‹æ‰€ç¤ºã€‚

```txt
PASCAL VOC 2012 æ•°æ®é›†
|
â”œâ”€â”€ VOC2012
|   â”œâ”€â”€ JPEGImages    # åŒ…å«æ‰€æœ‰å›¾åƒæ–‡ä»¶
|   |   â”œâ”€â”€ 2007_000027.jpg
|   |   â”œâ”€â”€ 2007_000032.jpg
|   |   â”œâ”€â”€ ...
|   |
|   â”œâ”€â”€ Annotations    # åŒ…å«æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶ï¼ˆXMLæ ¼å¼ï¼‰
|   |   â”œâ”€â”€ 2007_000027.xml
|   |   â”œâ”€â”€ 2007_000032.xml
|   |   â”œâ”€â”€ ...
|   |
|   â”œâ”€â”€ ImageSets
|   |   â”œâ”€â”€ Main
|   |   |   â”œâ”€â”€ train.txt  # è®­ç»ƒé›†çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨
|   |   |   â”œâ”€â”€ val.txt    # éªŒè¯é›†çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨
|   |   |   â”œâ”€â”€ test.txt   # æµ‹è¯•é›†çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨
|   |
|   â”œâ”€â”€ SegmentationClass  # è¯­ä¹‰åˆ†å‰²çš„æ ‡æ³¨
|   |   â”œâ”€â”€ 2007_000032.png
|   |   â”œâ”€â”€ ...
|   |
|   â”œâ”€â”€ SegmentationObject  # ç‰©ä½“åˆ†å‰²çš„æ ‡æ³¨
|   |   â”œâ”€â”€ 2007_000032.png
|   |   â”œâ”€â”€ ...
|   |
|   â”œâ”€â”€ ...               # å…¶ä»–å¯èƒ½çš„å­æ–‡ä»¶å¤¹
|
â”œâ”€â”€ VOCdevkit
|   â”œâ”€â”€ VOCcode          # åŒ…å«ç”¨äºå¤„ç†æ•°æ®é›†çš„å·¥å…·ä»£ç 
|
â”œâ”€â”€ README
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸¤ä¸ªæ–‡ä»¶å¤¹å°±å¯ä»¥äº†ã€‚

1. JPEGImages: å­˜æ”¾æ‰€æœ‰çš„å›¾ç‰‡
2. Annotations: å­˜æ”¾æ‰€æœ‰çš„æ ‡æ³¨ä¿¡æ¯

è¿™é‡Œæˆ‘ä»¬ä» PASCAL VOC ä¸­æå–å‡ºå‡ å¼ å›¾ç‰‡ï¼Œç»„æˆ VOC2012-Liteï¼š

<div align=center>
    <img src=./imgs_markdown/2023-10-18-17-19-28.png
    width=30%>
</div>

å³æ­¤æ—¶æˆ‘ä»¬çš„æ•°æ®é›†ç»“æ„ä¸ºï¼š

```txt
VOCdevkit
â””â”€VOC2012-Lite
    â”œâ”€Annotations
    â”‚      2007_000027.xml
    â”‚      2007_000032.xml
    â”‚      2007_000033.xml
    â”‚      2007_000039.xml
    â”‚      2007_000042.xml
    â”‚      2007_000061.xml
    â”‚      ...
    â”‚
    â””â”€JPEGImages
            2007_000027.jpg
            2007_000032.jpg
            2007_000033.jpg
            2007_000039.jpg
            2007_000042.jpg
            2007_000061.jpg
            ...
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒYOLOv5 çš„è¦æ±‚æ ‡æ³¨æ–‡ä»¶åç¼€ä¸º `.txt`ï¼Œä½† Annotations ä¸­çš„æ–‡ä»¶åç¼€æ˜¯ `.xml`ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›è¡Œè½¬æ¢ã€‚

<details>
<summary>YOLO æ ‡æ³¨æ–‡ä»¶è¯´æ˜ </summary>

æ ‡æ³¨æ–‡ä»¶ä¸¾ä¾‹ï¼š

```txt
0 0.481719 0.634028 0.690625 0.713278
1 0.741094 0.524306 0.314750 0.933389
2 0.254162 0.247742 0.574520 0.687422
```

å…¶ä¸­ï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªç‰©ä½“çš„æ ‡æ³¨ï¼Œæ¯ä¸ªæ ‡æ³¨åŒ…æ‹¬äº”ä¸ªå€¼ï¼Œåˆ†åˆ«æ˜¯ï¼š

1. `<class_id>`ï¼šç‰©ä½“çš„ç±»åˆ«æ ‡è¯†ç¬¦ã€‚åœ¨è¿™é‡Œï¼Œæœ‰ä¸‰ä¸ªä¸åŒçš„ç±»åˆ«ï¼Œåˆ†åˆ«ç”¨ 0ã€1 å’Œ 2 è¡¨ç¤ºã€‚
2. `<center_x>`ï¼šç‰©ä½“è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ x åæ ‡ï¼Œå½’ä¸€åŒ–åˆ°å›¾åƒå®½åº¦ã€‚è¿™äº›å€¼çš„èŒƒå›´åº”åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚
3. `<center_y>`ï¼šç‰©ä½“è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ y åæ ‡ï¼Œå½’ä¸€åŒ–åˆ°å›¾åƒé«˜åº¦ã€‚åŒæ ·ï¼Œè¿™äº›å€¼çš„èŒƒå›´åº”åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚
4. `<width>`ï¼šç‰©ä½“è¾¹ç•Œæ¡†çš„å®½åº¦ï¼Œå½’ä¸€åŒ–åˆ°å›¾åƒå®½åº¦ã€‚
5. `<height>`ï¼šç‰©ä½“è¾¹ç•Œæ¡†çš„é«˜åº¦ï¼Œå½’ä¸€åŒ–åˆ°å›¾åƒé«˜åº¦ã€‚

ä»¥ç¬¬ä¸€è¡Œä¸ºä¾‹ï¼š

- `<class_id>` æ˜¯ 0ï¼Œè¡¨ç¤ºè¿™ä¸ªç‰©ä½“å±äºç±»åˆ« 0ã€‚
- `<center_x>` æ˜¯ 0.481719ï¼Œè¿™æ„å‘³ç€ç‰©ä½“è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ x åæ ‡ä½äºå›¾åƒå®½åº¦çš„ 48.17% å¤„ã€‚
- `<center_y>` æ˜¯ 0.634028ï¼Œä¸­å¿ƒç‚¹ y åæ ‡ä½äºå›¾åƒé«˜åº¦çš„ 63.40% å¤„ã€‚
- `<width>` æ˜¯ 0.690625ï¼Œè¾¹ç•Œæ¡†å®½åº¦å å›¾åƒå®½åº¦çš„ 69.06%ã€‚
- `<height>` æ˜¯ 0.713278ï¼Œè¾¹ç•Œæ¡†é«˜åº¦å å›¾åƒé«˜åº¦çš„ 71.33%ã€‚

</details>

## 1.4 YOLO æƒ³è¦çš„æ•°æ®é›†ç»“æ„

### 1.4.1 YOLOv3

ä¸€èˆ¬è€Œè¨€ï¼ŒYOLOv3 æƒ³è¦çš„æ•°æ®ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

```txt
YOLOv3 æ•°æ®é›†
|
â”œâ”€â”€ images         # åŒ…å«æ‰€æœ‰å›¾åƒæ–‡ä»¶
|   â”œâ”€â”€ image1.jpg
|   â”œâ”€â”€ image2.jpg
|   â”œâ”€â”€ ...
|
â”œâ”€â”€ labels         # åŒ…å«æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶ï¼ˆæ¯ä¸ªå›¾åƒå¯¹åº”ä¸€ä¸ªæ ‡æ³¨æ–‡ä»¶ï¼‰
|   â”œâ”€â”€ image1.txt
|   â”œâ”€â”€ image2.txt
|   â”œâ”€â”€ ...
|
â”œâ”€â”€ classes.names  # ç±»åˆ«æ–‡ä»¶ï¼ŒåŒ…å«æ‰€æœ‰ç±»åˆ«çš„åç§°
|
â”œâ”€â”€ train.txt      # è®­ç»ƒé›†çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨
â”œâ”€â”€ valid.txt      # éªŒè¯é›†çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨
```

### 1.4.2 YOLOv5

ä¸ YOLOv3 ä¸åŒï¼ŒYOLOv5 æ‰€éœ€è¦çš„æ•°æ®é›†ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

```txt
|-- test
|   |-- images
|   |   |-- 000000000036.jpg
|   |   `-- 000000000042.jpg
|   `-- labels
|       |-- 000000000036.txt
|       `-- 000000000042.txt
|-- train
|   |-- images
|   |   |-- 000000000009.jpg
|   |   `-- 000000000025.jpg
|   `-- labels
|       |-- 000000000009.txt
|       `-- 000000000025.txt
`-- val
    |-- images
    |   |-- 000000000030.jpg
    |   `-- 000000000034.jpg
    `-- labels
        |-- 000000000030.txt
        `-- 000000000034.txt
```

æ—¢ç„¶æˆ‘ä»¬å·²ç»çŸ¥é“äº† YOLOv5 æ‰€éœ€è¦çš„æ•°æ®é›†æ ¼å¼ï¼Œé‚£ä¹ˆå°±å¯ä»¥åŠ¨æ‰‹äº†ï¼

## 1.5 å°† PASCAL VOC æ•°æ®é›†è½¬æ¢ä¸º YOLOv5 æ•°æ®é›†æ ¼å¼

<details><summary>voc2yolo.py</summary>

```python
"""
æœ¬è„šæœ¬æœ‰ä¸¤ä¸ªåŠŸèƒ½ï¼š
    1. å°† voc æ•°æ®é›†æ ‡æ³¨ä¿¡æ¯(.xml)è½¬ä¸º yolo æ ‡æ³¨æ ¼å¼(.txt)ï¼Œå¹¶å°†å›¾åƒæ–‡ä»¶å¤åˆ¶åˆ°ç›¸åº”æ–‡ä»¶å¤¹
    2. æ ¹æ® json æ ‡ç­¾æ–‡ä»¶ï¼Œç”Ÿæˆå¯¹åº” names æ ‡ç­¾(my_data_label.names)
    3. å…¼å®¹ YOLOv3 å’Œ YOLOv5
"""
import os
from tqdm import tqdm
from lxml import etree
import json
import shutil
import argparse
from tqdm import tqdm
from prettytable import PrettyTable
from sklearn.model_selection import train_test_split


def args_table(args):
    # åˆ›å»ºä¸€ä¸ªè¡¨æ ¼
    table = PrettyTable(["Parameter", "Value"])
    table.align["Parameter"] = "l"  # ä½¿ç”¨ "l" è¡¨ç¤ºå·¦å¯¹é½
    table.align["Value"] = "l"  # ä½¿ç”¨ "l" è¡¨ç¤ºå·¦å¯¹é½

    # å°†argså¯¹è±¡çš„é”®å€¼å¯¹æ·»åŠ åˆ°è¡¨æ ¼ä¸­
    for key, value in vars(args).items():
        # å¤„ç†åˆ—è¡¨çš„ç‰¹æ®Šæ ¼å¼
        if isinstance(value, list):
            value = ', '.join(map(str, value))
        table.add_row([key, value])

    # è¿”å›è¡¨æ ¼çš„å­—ç¬¦ä¸²è¡¨ç¤º
    return str(table)


def generate_train_and_val_txt(args):
    
    target_train_file = args.train_txt_path
    target_val_file = args.val_txt_path

    # è·å–æºæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    files = os.listdir(args.voc_images_path)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_images, val_images = train_test_split(files, test_size=args.val_size, random_state=args.seed)

    # æ‰“å¼€ç›®æ ‡æ–‡ä»¶ä»¥å†™å…¥æ¨¡å¼
    with open(target_train_file, 'w', encoding='utf-8') as f:
        # ä½¿ç”¨tqdmåˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡ï¼Œè¿­ä»£æºæ–‡ä»¶åˆ—è¡¨
        for file in tqdm(train_images, desc=f"\033[1;33mProcessing Files for train\033[0m"):
            file_name, _ = os.path.splitext(file)
            # å†™å…¥æ–‡ä»¶å
            f.write(f'{file_name}\n')

    with open(target_val_file, 'w', encoding='utf-8') as f:
        # ä½¿ç”¨tqdmåˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡ï¼Œè¿­ä»£æºæ–‡ä»¶åˆ—è¡¨
        for file in tqdm(val_images, desc=f"\033[1;33mProcessing Files for val\033[0m"):
            file_name, _ = os.path.splitext(file)
            # å†™å…¥æ–‡ä»¶å
            f.write(f'{file_name}\n')

    print(f"\033[1;32mæ–‡ä»¶åå·²å†™å…¥åˆ° {target_train_file} å’Œ {target_val_file} æ–‡ä»¶ä¸­!\033[0m")

def parse_args():
    # åˆ›å»ºè§£æå™¨
    parser = argparse.ArgumentParser(description="å°† .xml è½¬æ¢ä¸º .txt")
    
    # æ·»åŠ å‚æ•°
    parser.add_argument('--voc_root', type=str, default="VOCdevkit", help="PASCAL VOCè·¯å¾„(ä¹‹åçš„æ‰€æœ‰è·¯å¾„éƒ½åœ¨voc_rootä¸‹)")
    parser.add_argument('--voc_version', type=str, default="VOC2012-Lite", help="VOC ç‰ˆæœ¬")
    parser.add_argument('--save_path', type=str, default="VOC2012-YOLO", help="è½¬æ¢åçš„ä¿å­˜ç›®å½•è·¯å¾„")
    parser.add_argument('--train_list_name', type=str, default="train.txt", help="è®­ç»ƒå›¾ç‰‡åˆ—è¡¨åç§°")
    parser.add_argument('--val_list_name', type=str, default="val.txt", help="éªŒè¯å›¾ç‰‡åˆ—è¡¨åç§°")
    parser.add_argument('--val_size', type=float, default=0.1, help="éªŒè¯é›†æ¯”ä¾‹")
    parser.add_argument('--seed', type=int, default=42, help="éšæœºæ•°ç§å­")
    parser.add_argument('--no_create_txt_for_pure_negative_sample', action='store_true', help='æ˜¯å¦ä¸ºçº¯è´Ÿæ ·æœ¬åˆ›å»ºtxtæ–‡ä»¶(é»˜è®¤åˆ›å»º)')
    parser.add_argument('--num_classes', type=int, default=20, help="æ•°æ®é›†ç±»åˆ«æ•°(ç”¨äºæ ¡éªŒ)")
    parser.add_argument('--classes', help="æ•°æ®é›†å…·ä½“ç±»åˆ«æ•°(ç”¨äºç”Ÿæˆ classes.json æ–‡ä»¶)", 
                        default=['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',
                                 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 
                                 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'])
    
    return parser.parse_args()


def configure_path(args):
    # è½¬æ¢çš„è®­ç»ƒé›†ä»¥åŠéªŒè¯é›†å¯¹åº”txtæ–‡ä»¶
    args.train_txt = "train.txt"
    args.val_txt = "val.txt"

    # è½¬æ¢åçš„æ–‡ä»¶ä¿å­˜ç›®å½•
    args.save_file_root = os.path.join(args.voc_root, args.save_path)

    # ç”Ÿæˆjsonæ–‡ä»¶
    # labelæ ‡ç­¾å¯¹åº”jsonæ–‡ä»¶
    args.label_json_path = os.path.join(args.voc_root, "classes.json")
    
    # åˆ›å»ºä¸€ä¸ªå°†ç±»åˆ«ä¸æ•°å€¼å…³è”çš„å­—å…¸
    class_mapping = {class_name: index + 1 for index, class_name in enumerate(args.classes)}
    with open(args.label_json_path, 'w', encoding='utf-8') as json_file:
        json.dump(class_mapping, json_file, ensure_ascii=False, indent=4)

    print(f'\033[1;31mç±»åˆ«åˆ—è¡¨å·²ä¿å­˜åˆ° {args.label_json_path}\033[0m')

    # æ‹¼æ¥å‡ºvocçš„imagesç›®å½•ï¼Œxmlç›®å½•ï¼Œtxtç›®å½•
    args.voc_images_path = os.path.join(args.voc_root, args.voc_version, "JPEGImages")
    args.voc_xml_path = os.path.join(args.voc_root, args.voc_version, "Annotations")
    args.train_txt_path = os.path.join(args.voc_root, args.voc_version, args.train_txt)
    args.val_txt_path = os.path.join(args.voc_root, args.voc_version, args.val_txt)
    
    # ç”Ÿæˆå¯¹åº”çš„ train.txt å’Œ val.txt
    generate_train_and_val_txt(args)

    # æ£€æŸ¥æ–‡ä»¶/æ–‡ä»¶å¤¹éƒ½æ˜¯å¦å­˜åœ¨
    assert os.path.exists(args.voc_images_path), f"VOC images path not exist...({args.voc_images_path})"
    assert os.path.exists(args.voc_xml_path), f"VOC xml path not exist...({args.voc_xml_path})"
    assert os.path.exists(args.train_txt_path), f"VOC train txt file not exist...({args.train_txt_path})"
    assert os.path.exists(args.val_txt_path), f"VOC val txt file not exist...({args.val_txt_path})"
    assert os.path.exists(args.label_json_path), f"label_json_path does not exist...({args.label_json_path})"
    if os.path.exists(args.save_file_root) is False:
        os.makedirs(args.save_file_root)
        print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{args.save_file_root}")


def parse_xml_to_dict(xml):
    """
    å°†xmlæ–‡ä»¶è§£ææˆå­—å…¸å½¢å¼ï¼Œå‚è€ƒtensorflowçš„recursive_parse_xml_to_dict
    Argsï¼š
        xml: xml tree obtained by parsing XML file contents using lxml.etree

    Returns:
        Python dictionary holding XML contents.
    """

    if len(xml) == 0:  # éå†åˆ°åº•å±‚ï¼Œç›´æ¥è¿”å›tagå¯¹åº”çš„ä¿¡æ¯
        return {xml.tag: xml.text}

    result = {}
    for child in xml:
        child_result = parse_xml_to_dict(child)  # é€’å½’éå†æ ‡ç­¾ä¿¡æ¯
        if child.tag != 'object':
            result[child.tag] = child_result[child.tag]
        else:
            if child.tag not in result:  # å› ä¸ºobjectå¯èƒ½æœ‰å¤šä¸ªï¼Œæ‰€ä»¥éœ€è¦æ”¾å…¥åˆ—è¡¨é‡Œ
                result[child.tag] = []
            result[child.tag].append(child_result[child.tag])
    return {xml.tag: result}


def translate_info(file_names: list, save_root: str, class_dict: dict, train_val='train', args=None):
    """
    å°†å¯¹åº”xmlæ–‡ä»¶ä¿¡æ¯è½¬ä¸ºyoloä¸­ä½¿ç”¨çš„txtæ–‡ä»¶ä¿¡æ¯
    """
    save_txt_path = os.path.join(save_root, train_val, "labels")
    if os.path.exists(save_txt_path) is False:
        os.makedirs(save_txt_path)
    save_images_path = os.path.join(save_root, train_val, "images")
    if os.path.exists(save_images_path) is False:
        os.makedirs(save_images_path)

    for file in tqdm(file_names, desc="translate {} file...".format(train_val)):
        # æ£€æŸ¥ä¸‹å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå¼ºæŠ¥é”™ï¼ï¼‰
        img_path = os.path.join(args.voc_images_path, file + ".jpg")
        assert os.path.exists(img_path), "file:{} not exist...".format(img_path)

        # æ£€æŸ¥xmlæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå¼ºæŠ¥é”™ï¼ï¼‰
        xml_path = os.path.join(args.voc_xml_path, file + ".xml")
        assert os.path.exists(xml_path), "file:{} not exist...".format(xml_path)

        # è¯»å– xml æ–‡ä»¶ï¼ˆè¿™é‡Œä¿®å¤äº†ä¸€ä¸‹ï¼‰
        # with open(xml_path) as fid:
        #     xml_str = fid.read()
        # xml = etree.fromstring(xml_str)

        with open(xml_path) as fid:
            xml_str = fid.read()
            
        # å°†XMLå­—ç¬¦ä¸²ç¼–ç ä¸ºå­—èŠ‚åºåˆ—
        xml_bytes = xml_str.encode('utf-8')

        # ä½¿ç”¨lxmlè§£æå­—èŠ‚åºåˆ—çš„XMLæ•°æ®
        xml = etree.fromstring(xml_bytes)
        data = parse_xml_to_dict(xml)["annotation"]
        img_height = int(data["size"]["height"])
        img_width = int(data["size"]["width"])

        # write object info into txt
        # assert "object" in data.keys(), "file: '{}' lack of object key.".format(xml_path)
        if (not "object" in data.keys()) or (len(data["object"]) == 0):  # æ²¡æœ‰ç›®æ ‡ï¼Œè¯´æ˜æ˜¯çº¯è´Ÿæ ·æœ¬
            if args.no_create_txt_for_pure_negative_sample:  # ä¸ä¸ºçº¯è´Ÿæ ·æœ¬åˆ›å»ºtxtæ–‡ä»¶
                continue
            else:  # ä¸ºçº¯è´Ÿæ ·æœ¬åˆ›å»ºtxtæ–‡ä»¶
                # æŠŠçº¯è´Ÿæ ·æœ¬å›¾ç‰‡æ‹·è´åˆ°æŒ‡å®šä¸ºæ­¢
                path_copy_to = os.path.join(save_images_path, img_path.split(os.sep)[-1])
                if os.path.exists(path_copy_to) is False:
                    shutil.copyfile(img_path, path_copy_to)
                
                # åˆ›å»ºä¸€ä¸ªç©ºçš„ .txt æ–‡ä»¶
                with open(os.path.join(save_txt_path, file + ".txt"), "w") as f:
                    ...

                # åé¢çš„ä¸éœ€è¦æ‰§è¡Œ
                continue
                
        with open(os.path.join(save_txt_path, file + ".txt"), "w") as f:
            for index, obj in enumerate(data["object"]):
                # è·å–æ¯ä¸ªobjectçš„boxä¿¡æ¯
                xmin = float(obj["bndbox"]["xmin"])
                xmax = float(obj["bndbox"]["xmax"])
                ymin = float(obj["bndbox"]["ymin"])
                ymax = float(obj["bndbox"]["ymax"])
                class_name = obj["name"]
                
                class_index = class_dict[class_name] - 1  # ç›®æ ‡idä»0å¼€å§‹

                # è¿›ä¸€æ­¥æ£€æŸ¥æ•°æ®ï¼Œæœ‰çš„æ ‡æ³¨ä¿¡æ¯ä¸­å¯èƒ½æœ‰wæˆ–hä¸º0çš„æƒ…å†µï¼Œè¿™æ ·çš„æ•°æ®ä¼šå¯¼è‡´è®¡ç®—å›å½’lossä¸ºnan
                if xmax <= xmin or ymax <= ymin:
                    print("Warning: in '{}' xml, there are some bbox w/h <=0".format(xml_path))
                    continue

                # å°†boxä¿¡æ¯è½¬æ¢åˆ°yoloæ ¼å¼
                xcenter = xmin + (xmax - xmin) / 2
                ycenter = ymin + (ymax - ymin) / 2
                w = xmax - xmin
                h = ymax - ymin

                # ç»å¯¹åæ ‡è½¬ç›¸å¯¹åæ ‡ï¼Œä¿å­˜6ä½å°æ•°
                xcenter = round(xcenter / img_width, 6)
                ycenter = round(ycenter / img_height, 6)
                w = round(w / img_width, 6)
                h = round(h / img_height, 6)

                info = [str(i) for i in [class_index, xcenter, ycenter, w, h]]

                if index == 0:
                    f.write(" ".join(info))
                else:
                    f.write("\n" + " ".join(info))

        # copy image into save_images_path
        path_copy_to = os.path.join(save_images_path, img_path.split(os.sep)[-1])
        if os.path.exists(path_copy_to) is False:
            shutil.copyfile(img_path, path_copy_to)


def create_class_names(class_dict: dict, args):
    keys = class_dict.keys()
    with open(os.path.join(args.voc_root, "my_data_label.names"), "w") as w:
        for index, k in enumerate(keys):
            if index + 1 == len(keys):
                w.write(k)
            else:
                w.write(k + "\n")


def main(args):
    # read class_indict
    json_file = open(args.label_json_path, 'r')
    class_dict = json.load(json_file)

    # è¯»å–train.txtä¸­çš„æ‰€æœ‰è¡Œä¿¡æ¯ï¼Œåˆ é™¤ç©ºè¡Œ
    with open(args.train_txt_path, "r") as r:
        train_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]
        
    # vocä¿¡æ¯è½¬yoloï¼Œå¹¶å°†å›¾åƒæ–‡ä»¶å¤åˆ¶åˆ°ç›¸åº”æ–‡ä»¶å¤¹
    translate_info(train_file_names, args.save_file_root, class_dict, "train", args=args)

    # è¯»å–val.txtä¸­çš„æ‰€æœ‰è¡Œä¿¡æ¯ï¼Œåˆ é™¤ç©ºè¡Œ
    with open(args.val_txt_path, "r") as r:
        val_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]
        
    # vocä¿¡æ¯è½¬yoloï¼Œå¹¶å°†å›¾åƒæ–‡ä»¶å¤åˆ¶åˆ°ç›¸åº”æ–‡ä»¶å¤¹
    translate_info(val_file_names, args.save_file_root, class_dict, "val", args=args)

    # åˆ›å»ºmy_data_label.namesæ–‡ä»¶
    create_class_names(class_dict, args=args)


if __name__ == "__main__":
    args = parse_args()
    configure_path(args)
    
    # ç¾åŒ–æ‰“å° args
    print(f"\033[1;34m{args_table(args)}\033[0m")
    
    # æ‰§è¡Œ .xml è½¬ .txt
    main(args)
```
</details>


æˆ‘ä»¬åœ¨è¿è¡Œä¸‹é¢å‘½ä»¤å³å¯å®Œæˆè½¬æ¢ï¼š

```bash
python voc2yolo.py --voc_root ./VOCdevkit \
                   --voc_version VOC2012-Lite \
                   --num_classes 20 \
                   --save_path VOC2012-YOLO
```

è½¬æ¢åçš„ç›®å½•ç»“æ„ä¸ºï¼š

```txt
VOCdevkit
â”‚  classes.json
â”‚  my_data_label.names
â”‚  
â”œâ”€VOC2012-Lite
â”‚  â”‚  train.txt
â”‚  â”‚  val.txt
â”‚  â”‚  
â”‚  â”œâ”€Annotations
â”‚  â”‚      2007_000027.xml
â”‚  â”‚      2007_000032.xml
â”‚  â”‚      2007_000033.xml
â”‚  â”‚      2007_000039.xml
â”‚  â”‚      2007_000042.xml
â”‚  â”‚      2007_000061.xml
â”‚  â”‚      ...
â”‚  â”‚      
â”‚  â””â”€JPEGImages
â”‚          2007_000027.jpg
â”‚          2007_000032.jpg
â”‚          2007_000033.jpg
â”‚          2007_000039.jpg
â”‚          2007_000042.jpg
â”‚          2007_000061.jpg
â”‚          ...
â”‚
â””â”€VOC2012-YOLO
    â”œâ”€train
    â”‚  â”œâ”€images
    â”‚  â”‚      2007_000032.jpg
    â”‚  â”‚      2007_000033.jpg
    â”‚  â”‚      2007_000039.jpg
    â”‚  â”‚      2007_000042.jpg
    â”‚  â”‚      2007_000061.jpg
    â”‚  â”‚      ...
    â”‚  â”‚
    â”‚  â””â”€labels
    â”‚          2007_000032.txt
    â”‚          2007_000033.txt
    â”‚          2007_000039.txt
    â”‚          2007_000042.txt
    â”‚          2007_000061.txt
    â”‚          ...
    â”‚
    â””â”€val
        â”œâ”€images
        â”‚      2007_000027.jpg
        â”‚      ...
        â”‚
        â””â”€labels
                2007_000027.txt
                ...
```

<div align=center>
    <img src=./imgs_markdown/2023-10-18-21-14-28.png
    width=50%>
</div>

## 1.6 YOLOv5 é…ç½®æ–‡ä»¶å˜åŠ¨

æ ¹æ® `.yaml` é…ç½®æ–‡ä»¶å˜åŠ¨è€Œå˜åŠ¨çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¤åˆ¶ `coco128.yaml` ä¸º `custom_dataset.yaml` ä¸ºä¾‹:

```yaml
# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# â”œâ”€â”€ yolov5
# â””â”€â”€ datasets
#     â””â”€â”€ coco128  â† downloads here (7 MB)


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: VOCdevkit/VOC2012-YOLO  # dataset root dir
train: train/images  # train images (relative to 'path') 128 images
val: val/images  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  4: airplane
  5: bus
  6: train
  7: truck
  8: boat
  9: traffic light
  10: fire hydrant
  ...


# Download script/URL (optional)
download: https://ultralytics.com/assets/coco128.zip
```

æ­¤æ—¶æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†è¿›è¡Œ YOLOv5 çš„æ¨¡å‹è®­ç»ƒäº†ï¼

## 1.7 ã€è¡¥å……ã€‘å¦‚æœæ ‡ç­¾æ ¼å¼ä¸º .json

### 1.7.1 å°†è´Ÿæ ·æœ¬æ”¾åœ¨æ­£æ ·æœ¬æ‰€å±æ–‡ä»¶å¤¹ä¸‹

**è¯´æ˜**ï¼šæˆ‘ä»¬åº”è¯¥æŠŠæ­£è´Ÿæ ·æœ¬æ”¾åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼Œå¦‚ `JPEGImages`ï¼Œè¿™æ ·æˆ‘ä»¬å†ä¸ºæ²¡æœ‰æ ‡ç­¾æ–‡ä»¶çš„è´Ÿæ ·æœ¬ç”Ÿæˆ .json æ–‡ä»¶ã€‚

> å•ç‹¬ä¸ºè´Ÿæ ·æœ¬ç”Ÿæˆ .json æ–‡ä»¶ï¼Œä¹‹åå†åˆå¹¶ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚

```python
"""
    æè¿°ï¼š
        1. æ£€æŸ¥è´Ÿæ ·æœ¬æ•°é‡æ˜¯å¦æ­£ç¡®ï¼›
        2. æ£€æŸ¥æ­£æ ·æœ¬æ•°é‡æ˜¯å¦æ­£ç¡®ï¼›
        3. æ£€æŸ¥Annotationsæ•°é‡æ˜¯å¦æ­£ç¡®
"""
import os
import shutil
import tqdm


"""============================ éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ ==================================="""
# æ•°æ®æ‰€åœ¨è·¯å¾„
BASE_PATH = 'EXAMPLE_DATASET/DATASET_A'
CHECK_NUM = False  # æ˜¯å¦æ£€æŸ¥æ ·æœ¬æ•°é‡
POS_SAMPLE_NUM = 6914  # æ­£æ ·æœ¬æ•°é‡ -> 6914
NEG_SAMPLE_NUM = 515  # è´Ÿæ ·æœ¬æ•°é‡ -> 515
"""==============================================================================="""

# ç»„åˆè·¯å¾„
source_path = os.path.join(BASE_PATH, "VOC2007")  # EXAMPLE_DATASET/VOC2007
pos_image_path = os.path.join(source_path, "JPEGImages")  # EXAMPLE_DATASET/VOC2007/JPEGImages
annotation_path = os.path.join(source_path, "Annotations")  # EXAMPLE_DATASET/VOC2007/Annotations
neg_image_path = os.path.join(source_path, "neg_samples")  # EXAMPLE_DATASET/VOC2007/neg_samples

# è·å–æ‰€æœ‰å›¾ç‰‡å’Œæ ‡ç­¾
pos_image_list = os.listdir(pos_image_path)
annotation_list = os.listdir(annotation_path)
neg_image_list = os.listdir(neg_image_path)

# è¿‡æ»¤åªåŒ…æ‹¬ç‰¹å®šç±»å‹çš„å›¾åƒæ–‡ä»¶ï¼ˆè¿™é‡Œæ˜¯.jpgå’Œ.pngï¼‰
pos_image_list = [file for file in pos_image_list if file.lower().endswith(('.jpg', '.png'))]
annotation_list = [file for file in annotation_list if file.lower().endswith(('.json', '.xml'))]
neg_image_list = [file for file in neg_image_list if file.lower().endswith(('.jpg', '.png'))]

# è®°å½•å®é™…æ•°æ®æ•°é‡
POS_IMG_NUM = len(pos_image_list)
ANNOTATIONS_NUM = len(annotation_list)
NEG_IMG_NUM = len(neg_image_list)

# æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®
if CHECK_NUM:
    assert POS_SAMPLE_NUM == POS_IMG_NUM, f"\033[1;31mæ­£æ ·æœ¬æ•°é‡({POS_SAMPLE_NUM})å’Œå®é™…æ­£æ ·æœ¬æ•°é‡({POS_IMG_NUM})ä¸ä¸€è‡´ï¼\033[0m"
    assert CHECK_NUM and POS_IMG_NUM == ANNOTATIONS_NUM, f"\033[1;31må®é™…æ­£æ ·æœ¬æ•°é‡({POS_IMG_NUM})å’Œå®é™…æ ‡ç­¾æ•°é‡({ANNOTATIONS_NUM})ä¸ä¸€è‡´ï¼\033[0m"
    assert CHECK_NUM and NEG_SAMPLE_NUM == NEG_IMG_NUM, f"\033[1;31mè´Ÿæ ·æœ¬æ•°é‡({NEG_SAMPLE_NUM})å’Œå®é™…è´Ÿæ ·æœ¬æ•°é‡({NEG_IMG_NUM})ä¸ä¸€è‡´ï¼\033[0m"
else:
    print("\033[1;31mğŸ’¡è¯·æ³¨æ„ï¼šè·³è¿‡äº†æ•°æ®æ£€æŸ¥ï¼\033[0m")

SKIP_NUM = 0
SUCCEED_NUM = 0

# åˆ›å»ºè¿›åº¦æ¡
progress_bar = tqdm.tqdm(total=NEG_IMG_NUM, desc="Copy neg2pos", unit=" img")
for neg_image_name in neg_image_list:
    # åˆ†ç¦»æ–‡ä»¶åå’Œåç¼€
    image_pre, image_ext = os.path.splitext(neg_image_name)

    # ç¡®å®šå›¾ç‰‡çš„è·¯å¾„ -> EXAMPLE_DATASET/VOC2007/neg_samples/xxxx_yyyy_xxxx_yyyy.jpg
    src_img_path = os.path.join(neg_image_path, neg_image_name)
    # ç¡®å®šä¿å­˜çš„è·¯å¾„ -> EXAMPLE_DATASET/VOC2007/JPEGImages/xxxx_yyyy_xxxx_yyyy.jpg
    target_img_path = os.path.join(pos_image_path, neg_image_name)

    # åˆ¤æ–­å¯¹åº”çš„jsonæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(target_img_path):
        SKIP_NUM += 1
        progress_bar.update(1)
        continue
    
    # å¼€å§‹å¤åˆ¶
    shutil.copy(src=src_img_path, dst=target_img_path)
    SUCCEED_NUM += 1
    progress_bar.update(1)

print(f"SUCCEED NUM: {SUCCEED_NUM}/{NEG_IMG_NUM}")
print(f"SKIP NUM: {SKIP_NUM}/{NEG_IMG_NUM}")

if SUCCEED_NUM + SKIP_NUM == NEG_SAMPLE_NUM:
    print("\n\033[1;36mNo Problems in Copying\033[0m\n")
    # å†æ¬¡æ£€æŸ¥æ•°æ®æ•°é‡
    if POS_SAMPLE_NUM + NEG_SAMPLE_NUM == POS_IMG_NUM + SUCCEED_NUM:
        print(f"\n\033[1;36mğŸ‘Œé¢„æƒ³æ­£è´Ÿæ ·æœ¬æ•°é‡({POS_SAMPLE_NUM} + {NEG_SAMPLE_NUM}) == å®é™…çš„æ­£è´Ÿæ ·æœ¬æ•°é‡({POS_IMG_NUM} + {SUCCEED_NUM})\033[0m\n")
    else:
        print(f"\n\033[1;31mğŸ¤¡å‡ºç°äº†é—®é¢˜ï¼šé¢„æƒ³æ­£è´Ÿæ ·æœ¬æ•°é‡({POS_SAMPLE_NUM} + {NEG_SAMPLE_NUM}) != å®é™…çš„æ­£è´Ÿæ ·æœ¬æ•°é‡({POS_IMG_NUM} + {SUCCEED_NUM})\033[0m\n")
else:
    print(f"\n\033[1;31mğŸ¤¡æœ‰é—®é¢˜: æˆåŠŸ/è´Ÿæ ·æœ¬æ•°é‡ -> {SUCCEED_NUM}/{NEG_SAMPLE_NUM}\033[0m\n")
```

### 1.7.2 ä¸ºè´Ÿæ ·æœ¬ç”Ÿæˆç©ºçš„ .json æ–‡ä»¶

æ²¡å•¥å¥½è¯´çš„ï¼Œç›´æ¥ç”Ÿæˆå°±è¡Œäº†ã€‚

```python
"""
    æè¿°ï¼šä¸ºæ‰€æœ‰å›¾ç‰‡åˆ›å»ºç©ºçš„jsonæ–‡ä»¶ï¼ˆå¦‚æœjsonæ–‡ä»¶å­˜åœ¨åˆ™è·³è¿‡ï¼‰
    ä½œç”¨ï¼šä¸ºè´Ÿæ ·æœ¬ç”Ÿæˆå¯¹åº”çš„jsonæ–‡ä»¶
"""

import numpy as np
import os
import cv2
import json
import tqdm


"""============================ éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ ==================================="""
# å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹è·¯å¾„
source_folder_path = 'EXAMPLE_DATASET/VOC2007/JPEGImages'

# jsonæ–‡ä»¶è·¯å¾„
target_folder_path = 'EXAMPLE_DATASET/VOC2007/Annotations'

# è´Ÿæ ·æœ¬æ•°é‡
NEG_SAMPLE_NUM = 1024
"""==============================================================================="""

# è·å–æ‰€æœ‰å›¾ç‰‡
image_list = os.listdir(source_folder_path)
# è¿‡æ»¤åªåŒ…æ‹¬ç‰¹å®šç±»å‹çš„å›¾åƒæ–‡ä»¶ï¼ˆè¿™é‡Œæ˜¯.jpgå’Œ.pngï¼‰
image_list = [file for file in image_list if file.lower().endswith(('.jpg', '.png'))]
TOTAL_NUM = len(image_list)
SKIP_NUM = 0
SUCCEED_NUM = 0

# åˆ›å»ºè¿›åº¦æ¡
progress_bar = tqdm.tqdm(total=len(image_list), desc="json2yolo", unit=" .json")
for image_name in image_list:
    # åˆ†ç¦»æ–‡ä»¶åå’Œåç¼€
    image_pre, image_ext = os.path.splitext(image_name)

    # ç¡®å®šä¿å­˜çš„è·¯å¾„
    target_path = os.path.join(target_folder_path, image_pre) + '.json'
    # ç¡®å®šå›¾ç‰‡çš„è·¯å¾„
    img_file = os.path.join(source_folder_path, image_name)

    # åˆ¤æ–­å¯¹åº”çš„jsonæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(target_path):
        SKIP_NUM += 1
        progress_bar.update(1)
        continue

    img = cv2.imdecode(np.fromfile(img_file, dtype=np.uint8), cv2.IMREAD_COLOR)
    height, width, _ = img.shape
    content = {"version": "0.2.2",
               "flags": {},
               "shapes": [],
               "imagePath": "{}.jpg".format(image_pre),
               "imageData": None,
               "imageHeight": height,
               "imageWidth": width
               }
    if not os.path.exists(target_folder_path):
        os.makedirs(target_folder_path)

    with open(target_path, 'w') as f:
        json.dump(content, f, indent=2)
    SUCCEED_NUM += 1
    progress_bar.update(1)

print(f"SUCCEED NUM: {SUCCEED_NUM}/{TOTAL_NUM}")
print(f"SKIP NUM: {SKIP_NUM}/{TOTAL_NUM}")

if SUCCEED_NUM == NEG_SAMPLE_NUM:
    print("\n\033[1;36mğŸ‘ŒNo Problems\033[0m\n")
else:
    print(f"\n\033[1;31mğŸ¤¡æœ‰é—®é¢˜: æˆåŠŸ/è´Ÿæ ·æœ¬æ•°é‡ -> {SUCCEED_NUM}/{NEG_SAMPLE_NUM}\033[0m\n")
```

### 1.7.3 json è½¬ yolo çš„ txt

```python
"""
    jsonè½¬yoloçš„txt
"""

import os
import cv2
import json
import numpy as np
import tqdm

"""============================ éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ ==================================="""
# æ ‡ç­¾å­—å…¸
label_dict = {'cls_1': 0,
              'cls_2': 1,
              }
# æ–‡ä»¶å¤¹è·¯å¾„
base_path = 'EXAMPLE_DATASET/VOC2007'

OVERRIDE = False  # æ˜¯å¦è¦è¦†ç›–å·²å­˜åœ¨txtæ–‡ä»¶
use_kpt_check = False
"""==============================================================================="""

path = os.path.join(base_path, 'Annotations')
all_json_list = os.listdir(path)
TOTAL_NUM = len(all_json_list)
SUCCESSES_NUM = 0
SKIP_NUM = 0
ERROR_NUM = 0
ERROR_LIST = []

# åˆ›å»ºè¿›åº¦æ¡
progress_bar = tqdm.tqdm(total=len(all_json_list), desc="json2yolo", unit=" .txt")

for idx, anno_name in enumerate(all_json_list):  # anno_json = 'xxxxxx_yyyyyyy_ccccc.json'
    target_path = os.path.join(base_path, 'labels', anno_name.replace('.json', '.txt'))
    if not OVERRIDE and os.path.exists(target_path):
        SKIP_NUM += 1
        continue

    progress_bar.set_description(f"\033[1;31m{anno_name}\033[0m")

    with open(os.path.join(path, anno_name), 'r') as fr:
        result = json.load(fr)

    img = cv2.imread(os.path.join(base_path, 'JPEGImages',
                     anno_name).replace('.json', '.jpg'))
    h_, w_ = img.shape[0:2]
    object_info = result['shapes']

    # exist_ok=True è¡¨ç¤ºå¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šå¼•å‘å¼‚å¸¸ï¼Œè€Œæ˜¯é»˜é»˜åœ°è·³è¿‡åˆ›å»ºè¯¥ç›®å½•çš„æ­¥éª¤
    os.makedirs(os.path.join(base_path, 'labels'), exist_ok=True)
    with open(target_path, 'w') as target_file:
        try:
            for line in object_info:
                label = label_dict[line['label']]
                # label = 0 if line['label'] == 'chepai' else 1
                kpt = np.array(line['points'])
                if use_kpt_check and (kpt[1][0] > kpt[3][0] and kpt[1][1] > kpt[3][1]):
                    continue
                else:
                    x1, y1, x2, y2 = kpt[0][0], kpt[0][1], kpt[1][0], kpt[1][1]
                    xc, yc, w, h = x1 + (x2-x1)/2, y1 + (y2-y1)/2, x2-x1, y2-y1

                    line = '{} {} {} {} {}'.format(
                        label, xc/w_, yc/h_, w/w_, h/h_)
                    target_file.write(line+'\n')
            SUCCESSES_NUM += 1

        except:
            ERROR_NUM += 1
            ERROR_LIST.append(os.path.join(path, anno_name))

    progress_bar.update(1)
progress_bar.close()

for _ef in ERROR_LIST:
    print(_ef)

print(f"json2yoloå·²å®Œæˆï¼Œè¯¦æƒ…å¦‚ä¸‹ï¼š\n\t"
      f"ğŸ‘ŒæˆåŠŸ: {SUCCESSES_NUM}/{TOTAL_NUM}\n\t"
      f"ğŸ‘Œè·³è¿‡: {SKIP_NUM}/{TOTAL_NUM}\n\t"
      f"ğŸ¤¡å¤±è´¥: {ERROR_NUM}/{TOTAL_NUM}")
```

### 1.7.4 åˆ’åˆ†æ•°æ®ï¼Œå¹¶ç”Ÿæˆæ•°æ®é›†

```python
"""
    ç”Ÿæˆæ•°æ®é›†
"""
# å¯¼å…¥æ‰€éœ€åº“
import os
from sklearn.model_selection import train_test_split
import shutil
import tqdm


"""============================ éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ ==================================="""
test_size = 0.01
OVERRIDE = False

# å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
target_image_folder = "EXAMPLE_DATASET/VOC2007/JPEGImages"

# txtæ–‡ä»¶å¤¹è·¯å¾„
target_label_folder = "EXAMPLE_DATASET/VOC2007/labels"

# è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
output_folder = "EXAMPLE_DATASET"
"""==============================================================================="""

# è¯»å–æ‰€æœ‰.txtæ–‡ä»¶
labels = [label for label in os.listdir(target_label_folder) if label.endswith(".txt")]

TOTAL_NUM = len(labels)

print(f"é¢„è®¡éªŒè¯é›†æ ·æœ¬æ•°é‡ä¸º: \033[1;31m{round(TOTAL_NUM * test_size)}\033[0mï¼Œè¯·è¾“å…¥ \033[1;31myes\033[0m ç»§ç»­ | è¾“å…¥å…¶ä»–é€€å‡º")

_INPUT = input()
if _INPUT != "yes":
    exit()

# ä½¿ç”¨sklearnè¿›è¡Œæ•°æ®é›†åˆ’åˆ†
train_list, val_list = train_test_split(labels, test_size=test_size, random_state=42)
print(f"è®­ç»ƒé›†å¤§å°: {len(train_list)}/{TOTAL_NUM} | éªŒè¯é›†å¤§å°: {len(val_list)}/{TOTAL_NUM}")

# å®šä¹‰ä¿å­˜è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ–‡ä»¶å¤¹è·¯å¾„
train_image_folder = os.path.join(output_folder, "train", "images")
train_label_folder = os.path.join(output_folder, "train", "labels")
val_image_folder = os.path.join(output_folder, "val", "images")
val_label_folder = os.path.join(output_folder, "val", "labels")
print(f"train_image_folder: {train_image_folder}")
print(f"train_label_folder: {train_label_folder}")
print(f"val_image_folder: {val_image_folder}")
print(f"val_label_folder: {val_label_folder}")

# åˆ›å»ºä¿å­˜æ–‡ä»¶å¤¹
os.makedirs(train_image_folder, exist_ok=True)
os.makedirs(train_label_folder, exist_ok=True)
os.makedirs(val_image_folder, exist_ok=True)
os.makedirs(val_label_folder, exist_ok=True)

print("=" * 50)

# å°†è®­ç»ƒé›†çš„å›¾ç‰‡å’Œæ ‡ç­¾æ‹·è´åˆ°å¯¹åº”æ–‡ä»¶å¤¹
progress_bar = tqdm.tqdm(total=len(train_list), desc="Copying in \033[1;31mtrain\033[0m", unit=" file")
TRAIN_SUCCESSES_NUM = 0
TRAIN_SKIP_NUM = 0
for label in train_list:
    label_path = os.path.join(target_label_folder, label)
    image_path = os.path.join(target_image_folder, label.replace(".txt", ".jpg"))
    
    # å®šä¹‰ç›®æ ‡è·¯å¾„
    target_img = os.path.join(train_image_folder, label.replace(".txt", ".jpg"))
    target_label = os.path.join(train_label_folder, label)
    if not OVERRIDE and os.path.exists(target_img) and target_label:
        TRAIN_SKIP_NUM += 1
        progress_bar.update(1)
        continue

    shutil.copy(image_path, target_img)
    shutil.copy(label_path, target_label)
    TRAIN_SUCCESSES_NUM += 1
    progress_bar.update(1)
progress_bar.close()

# å°†éªŒè¯é›†çš„å›¾ç‰‡å’Œæ ‡ç­¾æ‹·è´åˆ°å¯¹åº”æ–‡ä»¶å¤¹
progress_bar = tqdm.tqdm(total=len(train_list), desc="Copying in \033[1;31mvalidation\033[0m", unit=" file")
VAL_SUCCESSES_NUM = 0
VAL_SKIP_NUM = 0
for label in val_list:
    label_path = os.path.join(target_label_folder, label)
    image_path = os.path.join(target_image_folder, label.replace(".txt", ".jpg"))

    # å®šä¹‰ç›®æ ‡è·¯å¾„
    target_img = os.path.join(val_image_folder, label.replace(".txt", ".jpg"))
    target_label = os.path.join(val_label_folder, label)
    
    if not OVERRIDE and os.path.exists(target_img) and target_label:
        VAL_SKIP_NUM += 1
        progress_bar.update(1)
        continue

    shutil.copy(image_path, target_img)
    shutil.copy(label_path, target_label)
    VAL_SUCCESSES_NUM += 1
    progress_bar.update(1)
progress_bar.close()

print(
    f"\næ•°æ®é›†åˆ›å»ºå®Œæ¯•ï¼Œè¯¦æƒ…å¦‚ä¸‹ï¼š\n\t"
    f"è®­ç»ƒé›†:\n\t\t"
    f"å›¾ç‰‡è·¯å¾„: {train_image_folder}\n\t\t"
    f"æ ‡ç­¾è·¯å¾„: {train_label_folder}\n\t\t\t"
    f"ğŸ‘ŒæˆåŠŸ: {TRAIN_SUCCESSES_NUM}/{len(train_list)}\n\t\t\t"
    f"ğŸ‘Œè·³è¿‡: {TRAIN_SKIP_NUM}/{len(train_list)}\n\t"
    
    f"éªŒè¯é›†:\n\t\t"
    f"å›¾ç‰‡è·¯å¾„: {val_image_folder}\n\t\t"
    f"æ ‡ç­¾è·¯å¾„: {val_label_folder}\n\t\t\t"
    f"ğŸ‘ŒæˆåŠŸ: {VAL_SUCCESSES_NUM}/{len(val_list)}\n\t\t\t"
    f"ğŸ‘Œè·³è¿‡: {VAL_SKIP_NUM}/{len(val_list)}"
)
```

## 1.8 ã€è¡¥å……ã€‘éšæœºæŒ‘é€‰æ•°æ®ç»„æˆæµ‹è¯•é›†

å¦‚æœæˆ‘ä»¬æœ‰ä¸€æ‰¹æ¨¡å‹ä»æ¥æ²¡æœ‰è§è¿‡çš„ï¼ˆå·®å¼‚éå¸¸å¤§ï¼‰çš„æ•°æ®ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥éšæœºæŒ‘é€‰æ•°æ®ç»„æˆæµ‹è¯•é›†ï¼Œä»è€Œå¿«é€Ÿæµ‹è¯•ã€‚

```python
import os
import tqdm
import random
import shutil
import subprocess


"""============================ éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ ==================================="""
# æºè§†é¢‘è·¯å¾„
src_folder = 'Addition_dataset'

# ä¿å­˜çš„è·¯å¾„
dst_folder_origin = 'data-test'

TEST_IMG_NUM = 100  # æµ‹è¯•å›¾ç‰‡æ•°é‡
record_time = "20231114"  # æ—¶é—´
other_content = ""  # å…¶ä»–å¤‡æ³¨
"""==============================================================================="""

# è¯»å–ç›®æ ‡æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
imgs_list = os.listdir(src_folder)
# è¿‡æ»¤åªåŒ…æ‹¬ç‰¹å®šç±»å‹çš„å›¾åƒæ–‡ä»¶ï¼ˆè¿™é‡Œæ˜¯.jpgå’Œ.pngï¼‰
imgs_list = [file for file in imgs_list if file.lower().endswith(('.jpg', '.png'))]

# éšæœºæ•°ç»„
random.shuffle(imgs_list)  # in-placeæ“ä½œ

# ç»„æˆè·¯å¾„å¹¶åˆ›å»ºæ–‡ä»¶å¤¹
if other_content:
    dst_folder = dst_folder_origin + f"-{record_time}-{other_content}"
else:    
    dst_folder = dst_folder_origin + f"-{record_time}"
if not os.path.exists(dst_folder):
    os.makedirs(dst_folder, exist_ok=True)

# åˆ›å»ºä¸€ä¸ªtqdmè¿›åº¦æ¡å¯¹è±¡
progress_bar = tqdm.tqdm(total=TEST_IMG_NUM, desc="éšæœºæŠ½å–å›¾ç‰‡ç»„æˆæµ‹è¯•é›†", unit="img")
for count, img_name in enumerate(imgs_list):
    if count >= TEST_IMG_NUM:
        break
    progress_bar.set_description(f"selected \033[1;31m{img_name}\033[0m")
    
    # ç¡®å®šè·¯å¾„
    src_path = os.path.join(src_folder, img_name)
    dst_path = os.path.join(dst_folder, img_name)
    
    # å¼€å§‹å¤åˆ¶
    shutil.copy(src=src_path, dst=dst_path)
    
    progress_bar.update(1)
progress_bar.close()

# å‹ç¼©æ–‡ä»¶å¤¹
# åˆ‡æ¢å½“å‰å·¥ä½œç›®å½•åˆ°æºæ–‡ä»¶å¤¹æ‰€åœ¨çš„ä½ç½®
os.chdir(dst_folder_origin)

if other_content:
    zip_file_name = f"{record_time}-{other_content}.7z"
else:
    zip_file_name = f"{record_time}.7z"
zip_command = f"7z a {zip_file_name} {dst_folder.split('/')[-1]}/*"

subprocess.run(zip_command, shell=True)

print(f"å¤åˆ¶å®Œæˆï¼Œä¸€å…±è·å¾—äº† {TEST_IMG_NUM} å¼ æµ‹è¯•å›¾ç‰‡ï¼Œè·¯å¾„ä¸º: {dst_folder}")
print(f"å‹ç¼©å®Œæˆï¼Œå‹ç¼©åŒ…è·¯å¾„ä¸º: {os.path.join(dst_folder_origin, zip_file_name)}")
```

åœ¨ Linux ä¸­ï¼Œå¦‚æœæœ€åçš„å‹ç¼©ç¨‹åºæ²¡æœ‰è¿è¡Œï¼Œè¯·å®‰è£… `7zip`ï¼š

```bash
sudo apt install p7zip-full
```

## 1.9 ã€è¡¥å……ã€‘å¦‚æœæ•°æ®é›†æœ‰å¥½å‡ éƒ¨åˆ† | åˆå¹¶å¤šä¸ªè®­ç»ƒæ–‡ä»¶å¤¹

æœ‰æ—¶å€™æˆ‘ä»¬çš„æ•°æ®é›†æ˜¯ç”±å¥½å‡ éƒ¨åˆ†ç»„æˆçš„ï¼Œæ¯”å¦‚ï¼š
1. `DATASET_PART_A`
2. `DATASET_PART_B`
3. `DATASET_PART_C`

<kbd>Q</kbd>ï¼šé‚£ä¹ˆæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬åˆåœ¨ä¸€èµ·ç»„æˆ `DATASET_PART_FULL` å—ï¼Ÿ
<kbd>A</kbd>ï¼šè¯´å®è¯ï¼Œæˆ‘ä¹‹å‰ä¸€ç›´æ˜¯è¿™æ ·åšçš„ï¼Œé‚£æ˜¯æˆ‘å‘ç°è¿™æ ·æ˜¯éå¸¸è ¢çš„ â€”â€” æ•°æ®é›†è€¦åˆæ€§æ‹‰æ»¡ï¼Œè€Œä¸”åŸæ¥çš„ç¢ç‰‡ä¹Ÿä¸èƒ½ä¸¢æ‰ï¼ˆå½“åšå¤‡ä»½ï¼‰ã€‚åœ¨ YOLOv5 ä¸­ï¼Œå…¶å®æ˜¯æ”¯æŒå¤šä¸ªæ–‡ä»¶å¤¹çš„ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

```yaml
path: ../datasets/coco
train: train2017.txt
val: val2017.txt
test: test-dev2017.txt

# Classes
names:
  0: person
  1: bicycle
  2: car
  ...
```

ä¸Šé¢æ˜¯ `coco.yaml` æ–‡ä»¶çš„å†…å®¹ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾æˆ‘ä»¬çš„æ•°æ®ä¹Ÿä¿å­˜åœ¨ `../datasets/coco` ä¸­ï¼Œä½†æœ‰ 3 ä¸ªå­æ–‡ä»¶å¤¹ï¼š

1. `../datasets/coco/partA`
2. `../datasets/coco/partB`
3. `../datasets/coco/partC`

æ­¤æ—¶æˆ‘ä»¬å¯ä»¥å°† yaml æ–‡ä»¶æ”¹ä¸ºå¦‚ä¸‹æ‰€ç¤ºçš„ï¼š

```yaml
path: ../datasets/coco
train: 
  - partA/train2017.txt
  - partB/train2017.txt
  - partC/train2017.txt
val:
  - partA/val2017.txt
  - partB/val2017.txt
  - partC/val2017.txt
test:
  - partA/test-dev2017.txt
  - partB/test-dev2017.txt
  - partC/test-dev2017.txt

# Classes
names:
  0: person
  1: bicycle
  2: car
  ...
```

è¿™æ · YOLOv5 åœ¨åŠ è½½æ•°æ®é›†çš„æ—¶å€™ä¼šå°†ä¸‰éƒ¨åˆ†çš„æ•°æ®éƒ½åŠ è½½ä¸Šã€‚ä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ä¹Ÿæ›´åŠ æ–¹ä¾¿ç®¡ç†ã€‚

**æ³¨æ„**ï¼šYOLOv5 é»˜è®¤ä¼šä¸ºæ•°æ®é›†ä¿ç•™ä¸€ä¸ª `.cache` æ–‡ä»¶ï¼Œä»¥ä¾¿ä¸‹æ¬¡å¿«é€ŸåŠ è½½æ•°æ®é›†ï¼Œç”±äºæˆ‘ä»¬çš„æ•°æ®é›†åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œå› æ­¤ `.cache` åªä¼šä¿å­˜åœ¨ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œå³ `partA` æ–‡ä»¶å¤¹ä¸‹ã€‚

# 2. æ¨¡å‹é€‰æ‹©

æˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„æ¨¡å‹æ¥è¿›è¡Œè®­ç»ƒï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹© YOLOv5sï¼Œè¿™æ˜¯ç¬¬äºŒå°å’Œé€Ÿåº¦æœ€å¿«çš„å¯ç”¨æ¨¡å‹ã€‚

<div align=center>
    <img src=./imgs_markdown/2023-10-18-21-18-35.png
    width=100%>
</div>

# 3. æ¨¡å‹è®­ç»ƒ

é€šè¿‡æŒ‡å®šæ•°æ®é›†ã€æ‰¹æ¬¡å¤§å°ã€å›¾åƒå¤§å°ä»¥åŠé¢„è®­ç»ƒæƒé‡ `--weights yolov5s.pt`åœ¨æˆ‘ä»¬è‡ªå»ºçš„æ•°æ®é›†ä¸Šè®­ç»ƒ YOLOv5s æ¨¡å‹ã€‚

```bash
export CUDA_VISIBLE_DEVICES=4
python train.py --img 640 \
                --epochs 150 \
                --data custom_dataset.yaml \
                --weights weights/yolov5s.pt \
                --batch-size 32 \
                --single-cls \
                --project runs/train \
                --cos-lr
```



ä¸ºäº†åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œå¯ä»¥æ·»åŠ  `--cache ram` æˆ– `--cache disk` é€‰é¡¹ï¼ˆéœ€è¦å¤§é‡çš„å†…å­˜/ç£ç›˜èµ„æºï¼‰ã€‚æ‰€æœ‰è®­ç»ƒç»“æœéƒ½ä¼šä¿å­˜åœ¨ `runs/train/` ç›®å½•ä¸‹ï¼Œæ¯æ¬¡è®­ç»ƒéƒ½ä¼šåˆ›å»ºä¸€ä¸ªé€’å¢çš„è¿è¡Œç›®å½•ï¼Œä¾‹å¦‚ `runs/train/exp2`ã€`runs/train/exp3` ç­‰ç­‰ã€‚

## 2.5 å¯è§†åŒ–

è®­ç»ƒç»“æœä¼šè‡ªåŠ¨è®°å½•åœ¨ Tensorboard å’Œ CSV æ—¥å¿—è®°å½•å™¨ä¸­ï¼Œä¿å­˜åœ¨ `runs/train` ç›®å½•ä¸‹ï¼Œæ¯æ¬¡æ–°çš„è®­ç»ƒéƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„å®éªŒç›®å½•ï¼Œä¾‹å¦‚ `runs/train/exp2`ã€`runs/train/exp3` ç­‰ã€‚

è¯¥ç›®å½•åŒ…å«äº†è®­ç»ƒå’ŒéªŒè¯çš„ç»Ÿè®¡æ•°æ®ã€é©¬èµ›å…‹å›¾åƒã€æ ‡ç­¾ã€é¢„æµ‹ç»“æœã€ä»¥åŠç»è¿‡å¢å¼ºçš„é©¬èµ›å…‹å›¾åƒï¼Œè¿˜åŒ…æ‹¬ Precision-Recallï¼ˆPRï¼‰æ›²çº¿å’Œæ··æ·†çŸ©é˜µç­‰åº¦é‡å’Œå›¾è¡¨ã€‚

<div align=center>
    <img src=./imgs_markdown/2023-10-18-21-25-37.png
    width=100%>
</div>

ç»“æœæ–‡ä»¶ `results.csv` åœ¨æ¯ä¸ª Epoch åæ›´æ–°ï¼Œç„¶ååœ¨è®­ç»ƒå®Œæˆåç»˜åˆ¶ä¸º `results.png`ï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥æ‰‹åŠ¨ç»˜åˆ¶ä»»ä½• `results.csv` æ–‡ä»¶ï¼š

```python
from utils.plots import plot_results

plot_results('path/to/results.csv')  # plot 'results.csv' as 'results.png'
```

<div align=center>
    <img src=./imgs_markdown/2023-10-18-21-25-55.png
    width=100%>
</div>

# 4. <kbd>è¡¥å……</kbd> ç°å®åœºæ™¯ä¸­æ•°æ®é›†æ„å»ºé‡åˆ°çš„é—®é¢˜

## 4.1 æ•°æ®é›†ä¸­å›¾ç‰‡å’Œæ ‡æ³¨æ•°é‡ä¸ä¸€è‡´æ€ä¹ˆåŠï¼Ÿ

æœ‰æ—¶å€™æˆ‘ä»¬æ ‡æ³¨å®Œæ‰€æœ‰çš„å›¾ç‰‡åï¼Œä¼šæ‰‹åŠ¨æ£€æŸ¥ä¸€éï¼Œåˆ é™¤æ‰ä¸€äº›ä¸åˆç†çš„å›¾ç‰‡ã€‚åˆ é™¤å›¾ç‰‡æˆ‘æ¨èä½¿ç”¨ Windows è‡ªå¸¦çš„å›¾ç‰‡è½¯ä»¶ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<div align=center>
    <img src=./imgs_markdown/2023-10-24-15-41-02.png
    width=50%>
</div>

ä¹‹åæˆ‘ä»¬æ‰“å¼€å›¾ç‰‡ï¼Œä½¿ç”¨ <kbd>â†</kbd><kbd>â†’</kbd> æ–¹å‘é”®å³å¯æµè§ˆä¸Šä¸€å¼ å›¾ç‰‡å’Œä¸‹ä¸€å¼ å›¾ç‰‡ã€‚å¯¹äºä¸åˆç†çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨é”®ç›˜å¿«æ·é”® <kbd>Delete</kbd> æ¥åˆ é™¤æ­¤æ—¶æ˜¾ç¤ºçš„å›¾ç‰‡ã€‚

åœ¨åˆ é™¤å®Œæ‰€æœ‰ä¸åˆç†çš„å›¾ç‰‡åï¼Œæˆ‘ä»¬ä¼šå‘ç°ï¼Œæ­¤æ—¶å›¾ç‰‡æ•°é‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´äº†ï¼Œéœ€è¦è¿›è¡Œå¤„ç†ï¼Œè¿™é‡Œæˆ‘æ¨èä½¿ç”¨ä¸‹é¢çš„è„šæœ¬ï¼š

> <kbd>Note</kbd>ï¼š<font color='red'>åœ¨è¿è¡Œä¸‹é¢è„šæœ¬çš„æ—¶å€™ä¸€å®šè¦å¤‡ä»½æ•°æ®é›†ï¼</font>

```python
import os
from tqdm import tqdm


# å®šä¹‰å›¾ç‰‡æ–‡ä»¶å¤¹å’Œæ ‡ç­¾æ–‡ä»¶å¤¹çš„è·¯å¾„
images_folder = '/mnt/c/Users/Le0v1n/Desktop/æµ‹è¯•æ¡ˆä¾‹/Datasets/exp_1/JPEGImages'
annotations_folder = '/mnt/c/Users/Le0v1n/Desktop/æµ‹è¯•æ¡ˆä¾‹/Datasets/exp_1/Annotations'

# è·å–imagesæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg') or f.endswith('.png')]

# è·å–annotationsæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰.xmlæ–‡ä»¶
annotation_files = [f for f in os.listdir(annotations_folder) if f.endswith('.xml')]

if len(image_files) == len(annotation_files):
    print(f"ä¸¤ç§æ–‡ä»¶å¤¹ä¸­æ–‡ä»¶æ•°é‡ç›¸åŒ({len(image_files)} v.s. {len(annotation_files)})ï¼Œç¨‹åºé€€å‡º!")
    exit()

# è·å–imagesæ–‡ä»¶å¤¹ä¸­å­˜åœ¨çš„å›¾ç‰‡æ–‡ä»¶çš„æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
existing_image_names = set(os.path.splitext(f)[0] for f in image_files)

# ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
deleted_num = 0
with tqdm(total=len(annotation_files), desc="åˆ é™¤æ ‡ç­¾æ–‡ä»¶è¿›åº¦") as pbar:
    # éå†annotationsæ–‡ä»¶å¤¹ï¼Œåˆ é™¤æ²¡æœ‰å¯¹åº”å›¾ç‰‡çš„.xmlæ–‡ä»¶
    for annotation_file in annotation_files:
        annotation_name = os.path.splitext(annotation_file)[0]
        
        if annotation_name not in existing_image_names:
            # æ„å»ºè¦åˆ é™¤çš„.xmlæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
            annotation_path = os.path.join(annotations_folder, annotation_file)
            # åˆ é™¤æ–‡ä»¶
            os.remove(annotation_path)
            pbar.update(1)  # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix(deleted=annotation_file)  # æ˜¾ç¤ºå·²åˆ é™¤çš„æ–‡ä»¶å
            deleted_num += 1

print(f"åˆ é™¤æ“ä½œå®Œæˆ, å…±åˆ é™¤ {deleted_num} ä¸ª .xml æ–‡ä»¶")

# å†æ£€æŸ¥ä¸€é
# è·å–imagesæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg') or f.endswith('.png')]

# è·å–annotationsæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰.xmlæ–‡ä»¶
annotation_files = [f for f in os.listdir(annotations_folder) if f.endswith('.xml')]

if len(image_files) == len(annotation_files):
    print(f"ä¸¤ç§æ–‡ä»¶å¤¹ä¸­æ–‡ä»¶æ•°é‡ç›¸åŒ({len(image_files)} v.s. {len(annotation_files)})ï¼Œç¨‹åºé€€å‡º!")
else:
    print(f"ä¸¤ä¸ªæ–‡ä»¶å¤¹æ•°é‡ä¸ç›¸åŒ({len(image_files)} v.s. {len(annotation_files)})ï¼Œå¯èƒ½å­˜åœ¨çº¯è´Ÿæ ·æœ¬!")
```

ä¸Šé¢çš„è„šæœ¬å¯ä»¥æ£€æŸ¥å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶ï¼Œçœ‹æ ‡æ³¨æ–‡ä»¶æ˜¯å¦æœ‰å¯¹åº”çš„å›¾ç‰‡ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™åˆ é™¤æ ‡æ³¨æ–‡ä»¶ã€‚

## 4.2 æ•°æ®é›†ä¸­æœ‰çº¯è´Ÿæ ·æœ¬æ€ä¹ˆåŠï¼Ÿ

åœ¨å®é™…ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬éš¾å…ä¼šæœ‰ä¸€å¼ å›¾ç‰‡æ˜¯è´Ÿæ ·æœ¬çš„æƒ…å†µï¼Œæ­¤æ—¶è¿™å¼ å›¾ç‰‡æ˜¯æ²¡æœ‰ä»»ä½• Object çš„ã€‚æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ LabelImg æ¥æ ‡æ³¨å›¾ç‰‡ï¼Œä½† LabelImg ä¸ä¼šå¯¹æ²¡æœ‰ Object çš„å›¾ç‰‡ç”Ÿæˆå¯¹åº”çš„ `.xml` æ–‡ä»¶ï¼Œæ­¤æ—¶æˆ‘ä»¬è¿è¡Œä¸Šé¢ç»™çš„ `voc2yolo.py` æ–‡ä»¶å°±ä¼šæŠ¥é”™ï¼Œå› ä¸ºæˆ‘ä»¬æ–­è¨€äº† `.xml` æ˜¯å¦å­˜åœ¨ã€‚é‚£ä¹ˆæˆ‘ä»¬ç›´æ¥ `continue` å¯ä»¥å—ï¼Ÿå…¶å®æ˜¯å¯ä»¥çš„ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸€èˆ¬æ˜¯æƒ³å¾€æ•°æ®é›†ä¸­æ·»åŠ ä¸€å®šçš„çº¯è´Ÿæ ·æœ¬çš„ï¼Œç›´æ¥ `continue` å°±æ²¡æœ‰åŠæ³•æ·»åŠ çº¯è´Ÿæ ·æœ¬äº†ï¼Œé‚£æˆ‘ä»¬è¯¥æ€ä¹ˆåŠï¼Ÿ

å…¶å®æ–¹æ³•ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œé¦–å…ˆä¸ºæ‰€æœ‰çš„å›¾ç‰‡ç”Ÿæˆä¸€ä¸ª `.xml` æ–‡ä»¶ï¼Œè„šæœ¬å¦‚ä¸‹ï¼š

```python
import os
import xml.dom.minidom
from tqdm import tqdm


# ä¸ºå“ªäº›å›¾ç‰‡ç”Ÿæˆ .xml æ–‡ä»¶ï¼Ÿ
img_path = '/mnt/c/Users/Le0v1n/Desktop/æµ‹è¯•æ¡ˆä¾‹/Datasets/exp_1/JPEGImages'

# å°†ç”Ÿæˆçš„ .xml æ–‡ä»¶ä¿å­˜åˆ°å“ªä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼Ÿ
xml_path = '/mnt/c/Users/Le0v1n/Desktop/æµ‹è¯•æ¡ˆä¾‹/Datasets/exp_1/Empty_Annotations'

# è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
img_files = os.listdir(img_path)

# ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
for img_file in tqdm(img_files, desc="ç”ŸæˆXMLæ–‡ä»¶"):
    img_name = os.path.splitext(img_file)[0]

    # åˆ›å»ºä¸€ä¸ªç©ºçš„DOMæ–‡æ¡£å¯¹è±¡
    doc = xml.dom.minidom.Document()
    # åˆ›å»ºåä¸ºannotationçš„æ ¹èŠ‚ç‚¹
    annotation = doc.createElement('annotation')
    # å°†æ ¹èŠ‚ç‚¹æ·»åŠ åˆ°DOMæ–‡æ¡£å¯¹è±¡
    doc.appendChild(annotation)

    # æ·»åŠ folderå­èŠ‚ç‚¹
    folder = doc.createElement('folder')
    folder_text = doc.createTextNode('VOC2007')
    folder.appendChild(folder_text)
    annotation.appendChild(folder)

    # æ·»åŠ filenameå­èŠ‚ç‚¹
    filename = doc.createElement('filename')
    filename_text = doc.createTextNode(img_file)
    filename.appendChild(filename_text)
    annotation.appendChild(filename)

    # æ·»åŠ pathå­èŠ‚ç‚¹
    path = doc.createElement('path')
    path_text = doc.createTextNode(img_path + '/' + img_file)  # ä¿®æ­£è·¯å¾„
    path.appendChild(path_text)
    annotation.appendChild(path)

    # æ·»åŠ sourceå­èŠ‚ç‚¹
    source = doc.createElement('source')
    database = doc.createElement('database')
    database_text = doc.createTextNode('Unknown')
    source.appendChild(database)
    database.appendChild(database_text)
    annotation.appendChild(source)

    # æ·»åŠ sizeå­èŠ‚ç‚¹
    size = doc.createElement('size')
    width = doc.createElement('width')
    width_text = doc.createTextNode('1280')
    height = doc.createElement('height')
    height_text = doc.createTextNode('720')
    depth = doc.createElement('depth')
    depth_text = doc.createTextNode('3')
    size.appendChild(width)
    width.appendChild(width_text)
    size.appendChild(height)
    height.appendChild(height_text)
    size.appendChild(depth)
    depth.appendChild(depth_text)
    annotation.appendChild(size)

    # æ·»åŠ segmentedå­èŠ‚ç‚¹
    segmented = doc.createElement('segmented')
    segmented_text = doc.createTextNode('0')
    segmented.appendChild(segmented_text)
    annotation.appendChild(segmented)

    # å°†XMLå†™å…¥æ–‡ä»¶
    xml_file_path = os.path.join(xml_path, f'{img_name}.xml')
    with open(xml_file_path, 'w+', encoding='utf-8') as fp:
        doc.writexml(fp, indent='\t', addindent='\t', newl='\n', encoding='utf-8')
```

**æ³¨æ„è·¯å¾„**ï¼š
1. `img_path`: å¯¹å“ªä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡ç”Ÿæˆ .xml æ–‡ä»¶
2. `xml_path`: å°†ç”Ÿæˆçš„ .xml æ–‡ä»¶æ”¾åœ¨å“ªä¸ªæ–‡ä»¶å¤¹é‡Œ

> æœ‰äº›åŒå­¦å¯èƒ½ä¼šæ‹…å¿ƒï¼Œåœ¨ `voc2yolo.py` ä¸­ä¼šé€šè¿‡å›¾ç‰‡çš„å°ºå¯¸è¿›è¡Œåæ ‡è½¬æ¢ï¼Œä½†æ˜¯ä½ è¦è®°ä½ï¼Œé‚£æ˜¯å¯¹äºæœ‰ Object çš„å›¾ç‰‡è€Œè¨€çš„ï¼Œå¯¹äºçº¯è´Ÿæ ·æœ¬è€Œè¨€ï¼Œæ²¡æœ‰ä»»ä½• Objectï¼Œä¹Ÿå°±ä¸ä¼šè¿›è¡Œåæ ‡è½¬æ¢ï¼Œæ‰€ä»¥è¿™é‡Œéšä¾¿å†™äº†ä¸€ä¸ª 1280Ã—720 æ˜¯åˆç†çš„ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°†ä¹‹å‰æ ‡æ³¨å¥½çš„ `.xml` æ–‡ä»¶ï¼ˆæ˜¯è‡ªå·±æ ‡æ³¨çš„ï¼Œä¸æ˜¯ç”Ÿæˆçš„æ–‡ä»¶ï¼‰ï¼Œå¤åˆ¶ä¸€ä¸‹ï¼Œç„¶åç²˜è´´åˆ°ç”Ÿæˆçš„ `.xml` æ–‡ä»¶ä¸­ã€‚å½“ç³»ç»Ÿæç¤ºæœ‰é‡åæ–‡ä»¶æ—¶ï¼Œå…¨éƒ¨è¦†ç›–å³å¯ã€‚è¿™æ ·ï¼Œæ‰€æœ‰çš„å›¾ç‰‡éƒ½ä¼šæœ‰è‡ªå·±çš„ `.xml` æ–‡ä»¶äº†ã€‚


æ­¤æ—¶ï¼Œæˆ‘ä»¬å†è¿è¡Œ `voc2yolo.py` æ–‡ä»¶ï¼Œå®ƒä¼šå¯¹çº¯è´Ÿæ ·æœ¬ç”Ÿæˆä¸€ä¸ª `.txt` æ–‡ä»¶ã€‚

> <kbd>Note</kbd>ï¼šåœ¨ `voc2yolo.py` è„šæœ¬ä¸­ï¼Œæœ‰ä¸€ä¸ªåä¸º `--no_create_txt_for_pure_negative_sample` çš„å‚æ•°ã€‚å½“è¯¥å‚æ•°è¢«è§¦å‘æ—¶ï¼Œè„šæœ¬ä¸ä¼šä¸ºçº¯è´Ÿæ ·æœ¬ç”Ÿæˆ `.txt` æ–‡ä»¶ï¼ˆé»˜è®¤ä¼šç”Ÿæˆ `.txt` æ–‡ä»¶ï¼‰

# çŸ¥è¯†æ¥æº

1. [Ultralytics YOLOv5 Docs](https://docs.ultralytics.com/yolov5/tutorials)
2. [ã€CSDNã€‘PASCAL VOC 2012 æ•°æ®é›†è®²è§£ä¸åˆ¶ä½œè‡ªå·±çš„æ•°æ®é›†](https://blog.csdn.net/weixin_44878336/article/details/124540069)
3. [ã€Bilibiliã€‘PASCAL VOC 2012 æ•°æ®é›†è®²è§£ä¸åˆ¶ä½œè‡ªå·±çš„æ•°æ®é›†](https://www.bilibili.com/video/BV1kV411k7D8)
4. [trans_voc2yolo.py](https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/blob/master/pytorch_object_detection/yolov3_spp/trans_voc2yolo.py)