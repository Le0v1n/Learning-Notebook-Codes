# 5. YOLOv5 è®­ç»ƒæŠ€å·§

## 5.1 warm-up

åœ¨ YOLOv5 ä¸­ï¼Œwarm-upï¼ˆé¢„çƒ­ï¼‰æ˜¯æŒ‡åœ¨è®­ç»ƒåˆå§‹é˜¶æ®µä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œç„¶åé€æ¸å¢åŠ å­¦ä¹ ç‡ï¼Œä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°é€‚åº”æ•°æ®é›†ã€‚è¿™ä¸ªè¿‡ç¨‹æœ‰åŠ©äºé¿å…åœ¨åˆå§‹é˜¶æ®µå‡ºç°æ¢¯åº¦çˆ†ç‚¸æˆ–ä¸ç¨³å®šçš„æƒ…å†µï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›ã€‚

YOLOv5 ä¸­çš„ warm-up ä¸»è¦ä½“ç°åœ¨å­¦ä¹ ç‡çš„è°ƒæ•´ä¸Šã€‚å…·ä½“è€Œè¨€ï¼ŒYOLOv5 ä½¿ç”¨çº¿æ€§ warm-up ç­–ç•¥ï¼Œå³åœ¨åˆå§‹è®­ç»ƒé˜¶æ®µï¼Œå­¦ä¹ ç‡ä»ä¸€ä¸ªè¾ƒå°çš„åˆå§‹å€¼çº¿æ€§å¢åŠ åˆ°è®¾å®šçš„åˆå§‹å­¦ä¹ ç‡ã€‚è¿™æœ‰åŠ©äºå‡ç¼“æ¨¡å‹çš„å‚æ•°æ›´æ–°é€Ÿåº¦ï¼Œé˜²æ­¢åœ¨åˆå§‹æ—¶å‡ºç°è¿‡å¤§çš„æƒé‡æ›´æ–°ï¼Œä»è€Œæé«˜è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

åœ¨ YOLOv5 çš„å®ç°ä¸­ï¼Œwarm-up é˜¶æ®µé€šå¸¸æŒç»­ä¸€å®šçš„è¿­ä»£æ¬¡æ•°ï¼Œè¿™ä¸ªæ¬¡æ•°æ˜¯åœ¨è®­ç»ƒå¼€å§‹æ—¶è®¾å®šçš„ã€‚ä¸€æ—¦ warm-up é˜¶æ®µç»“æŸï¼Œæ¨¡å‹å°†ä»¥è®¾å®šçš„åˆå§‹å­¦ä¹ ç‡è¿›è¡Œæ­£å¸¸çš„è®­ç»ƒã€‚

Warm-up çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå¯ä»¥åœ¨æ¨¡å‹å¼€å§‹å­¦ä¹ ä»»åŠ¡æ—¶æ›´å¥½åœ°æ§åˆ¶å­¦ä¹ çš„é€Ÿåº¦ï¼Œä»è€Œæœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°é€‚åº”æ•°æ®åˆ†å¸ƒã€‚è¿™åœ¨å¤„ç†å¤æ‚çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºè¿™äº›ä»»åŠ¡é€šå¸¸å…·æœ‰å¤§é‡çš„æ ·æœ¬å’Œå¤æ‚çš„èƒŒæ™¯ã€‚

æˆ‘ä»¬çœ‹ä¸€ä¸‹ç›¸å…³çš„æºç ï¼ˆ`train.py`ï¼‰ï¼š

```python
nb = len(train_loader)  # number of batches | ä¸€ä¸ªepochæ‹¥æœ‰çš„batchæ•°é‡
nw = max(round(hyp["warmup_epochs"] * nb), 100)  # number of warmup | çƒ­èº«çš„æ€»è¿­ä»£æ¬¡æ•°

pbar = enumerate(train_loader)  # éå†train_loader

# è®°å½•æ—¥å¿—
LOGGER.info(("\n" + "%11s" * 7) % ("Epoch", "GPU_mem", "box_loss", "obj_loss", "cls_loss", "Instances", "Size"))

# å¦‚æœåœ¨ä¸»çº¿ç¨‹ä¸­ï¼Œé‚£ä¹ˆç»™enumberateåŠ ä¸Štqdmè¿›åº¦æ¡
if RANK in {-1, 0}:
    pbar = tqdm(pbar, total=nb, bar_format=TQDM_BAR_FORMAT)  # progress bar

# å¼€å§‹éå†train_loader
for i, (imgs, targets, paths, _) in pbar:  # batch 
    # imgs: ä¸€ä¸ªbatchçš„å›¾ç‰‡
    # targets: ä¸€ä¸ªbatchçš„æ ‡ç­¾
    # paths: ä¸€ä¸ªbatchçš„è·¯å¾„
    callbacks.run("on_train_batch_start")  # è®°å½•æ­¤æ—¶æ­£åœ¨å¹²ä»€ä¹ˆ

    # è®¡ç®—å½“å‰çš„è¿­ä»£æ¬¡æ•°
    ni = i + nb * epoch  # number integrated batches (since train start)
    imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0

    # Warmup
    if ni <= nw:  # å¦‚æœå½“å‰çš„è¿­ä»£æ¬¡æ•°å°äºéœ€è¦çƒ­èº«çš„è¿­ä»£æ¬¡æ•°ï¼Œåˆ™å¼€å§‹çƒ­èº«
        xi = [0, nw]  # x interp

        # accumulateå˜é‡çš„ä½œç”¨æ˜¯åŠ¨æ€åœ°æ§åˆ¶ç´¯ç§¯çš„ Batch æ•°ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå¼€å§‹æ—¶é€æ¸å¢åŠ ç´¯ç§¯çš„ Batch æ•°ï¼Œ
        # ä»è€Œå®ç°ä»è¾ƒå°çš„ç´¯ç§¯ Batch æ•°åˆ°è¾ƒå¤§çš„ç´¯ç§¯ Batch æ•°çš„å¹³æ»‘è¿‡æ¸¡
        # è¿™æœ‰åŠ©äºæ¨¡å‹åœ¨è®­ç»ƒåˆæœŸç¨³å®šåœ°å­¦ä¹ 
        accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())
        for j, x in enumerate(optimizer.param_groups):
            # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0
            x["lr"] = np.interp(ni, xi, [hyp["warmup_bias_lr"] if j == 0 else 0.0, x["initial_lr"] * lf(epoch)])
            if "momentum" in x:
                x["momentum"] = np.interp(ni, xi, [hyp["warmup_momentum"], hyp["momentum"]])
```

åœ¨ [How suspend image mixing #931](https://github.com/ultralytics/yolov5/issues/931) ä¸­æœ‰ä½œè€…å…³äº warm-up çš„è¯´æ˜ï¼š

warmup æ…¢æ…¢åœ°å°†è®­ç»ƒå‚æ•°ä»å®ƒä»¬çš„åˆå§‹ï¼ˆæ›´ç¨³å®šï¼‰å€¼è°ƒæ•´åˆ°å®ƒä»¬çš„é»˜è®¤è®­ç»ƒå€¼ã€‚ä¾‹å¦‚ï¼Œé€šå¸¸ä¼šåœ¨æœ€åˆçš„å‡ ä¸ª Epoch å†…å°†å­¦ä¹ ç‡ä» 0 è°ƒæ•´åˆ°æŸä¸ªåˆå§‹å€¼ï¼Œä»¥é¿å…æ—©æœŸè®­ç»ƒçš„ä¸ç¨³å®šã€nan ç­‰é—®é¢˜ã€‚

çƒ­èº«æ•ˆæœå¯ä»¥åœ¨ Tensorboard çš„å­¦ä¹ ç‡æ›²çº¿å›¾ä¸­è§‚å¯Ÿåˆ°ï¼Œè¿™äº›æ›²çº¿è‡ªä»æœ€è¿‘çš„æäº¤ä»¥æ¥å·²ç»è¢«è‡ªåŠ¨è·Ÿè¸ªã€‚ä¸‹é¢çš„ä¾‹å­æ˜¾ç¤ºäº†åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¤§çº¦ 30 ä¸ª Epoch çš„çƒ­èº«ï¼Œæ¯ä¸ªå‚æ•°ç»„æœ‰ä¸€ä¸ªæ›²çº¿å›¾ã€‚æœ€åä¸€ä¸ªæ›²çº¿å›¾å±•ç¤ºäº†ä¸åŒçš„çƒ­èº«ç­–ç•¥ï¼ˆå³ä¸åŒçš„è¶…å‚æ•°è®¾ç½®ï¼‰ã€‚

<div align=center>
    <img src=./imgs_markdown/2024-02-06-17-35-38.png
    width=100%>
    <center></center>
</div>

### 5.1.1 np.interp è¯­æ³•

`numpy.interp(x, xp, fp, left=None, right=None, period=None)` æ˜¯ NumPy ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºçº¿æ€§æ’å€¼ã€‚çº¿æ€§æ’å€¼æ˜¯ä¸€ç§ä¼°ç®—åœ¨ä¸¤ä¸ªå·²çŸ¥å€¼ä¹‹é—´çš„æœªçŸ¥å€¼çš„æ–¹æ³•ï¼Œå‡è®¾è¿™äº›å€¼ä¹‹é—´çš„å˜åŒ–æ˜¯çº¿æ€§çš„ã€‚

å…¶ä¸­ï¼š

- `x`: éœ€è¦è¿›è¡Œæ’å€¼çš„ä¸€ç»´æ•°ç»„ã€‚
- `xp`: å·²çŸ¥æ•°æ®ç‚¹çš„ x åæ ‡ï¼ˆä¸€ç»´æ•°ç»„ï¼‰-> x pointsã€‚
- `fp`: å·²çŸ¥æ•°æ®ç‚¹çš„ y åæ ‡ï¼ˆä¸€ç»´æ•°ç»„ï¼‰-> function pointsã€‚
- `left`: å½“ x å°äº xp çš„æœ€å°å€¼æ—¶ï¼Œè¿”å›çš„é»˜è®¤å€¼ï¼Œé»˜è®¤ä¸º fp[0]ã€‚
- `right`: å½“ x å¤§äº xp çš„æœ€å¤§å€¼æ—¶ï¼Œè¿”å›çš„é»˜è®¤å€¼ï¼Œé»˜è®¤ä¸º fp[-1]ã€‚
- `period`: å¦‚æœæä¾›äº† periodï¼Œè¡¨ç¤º xp æ˜¯å‘¨æœŸæ€§çš„ï¼Œæ­¤æ—¶æ’å€¼ä¼šè€ƒè™‘å‘¨æœŸæ€§ã€‚period æ˜¯å‘¨æœŸçš„é•¿åº¦ã€‚

**ç¤ºä¾‹**ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt

# å·²çŸ¥æ•°æ®ç‚¹
x_known = np.array([1, 2, 3, 4, 5])
y_known = np.array([3, 5, 7, 9, 11])

# å¾…æ’å€¼çš„æ•°æ®ç‚¹
x_unknown = [0.0, 1.5, 3.0, 4.5, 6.0]

# ä½¿ç”¨np.interpè¿›è¡Œæ’å€¼
y_unknown = np.interp(x_unknown, x_known, y_known)
print(f"{y_unknown = }")  # [3, 4, 7, 10, 11]

# ç»˜åˆ¶å›¾å½¢
plt.figure(figsize=(10, 6), dpi=200)
plt.plot(x_known, y_known, 'o', label='Known points', color='green')  # å·²çŸ¥æ•°æ®ç‚¹
plt.plot(x_unknown, y_unknown, 'o', label='Unknown points', color='red')  # æ’å€¼ç»“æœ
plt.xlabel('x')
plt.ylabel('y')
plt.title(r'Example for $np.interp()$')
plt.legend()
plt.grid(True)
plt.savefig('Example4np.interp.jpg')
```

çœ‹ä¸æ‡‚æ²¡å…³ç³»ï¼Œæˆ‘ä»¬ä½œå›¾çœ‹ä¸€ä¸‹ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-02-05-14-29-23.png
    width=100%>
    <center></center>
</div>

å¤–æ¨è§„åˆ™å¦‚ä¸‹ï¼š
- å¦‚æœ `x` çš„å€¼å°äº `xp` çš„æœ€å°å€¼ï¼Œåˆ™ `np.interp` è¿”å›ä¸ `xp` æœ€å°å€¼å¯¹åº”çš„ `fp` å€¼ã€‚
- å¦‚æœ `x` çš„å€¼å¤§äº `xp` çš„æœ€å¤§å€¼ï¼Œåˆ™ `np.interp` è¿”å›ä¸ `xp` æœ€å¤§å€¼å¯¹åº”çš„ `fp` å€¼ã€‚

åˆ†æå¦‚ä¸‹ï¼š

- x[0] = 0.0, å®ƒå°äº xp çš„æœ€å°å€¼1ï¼Œæ‰€ä»¥å¤–æ¨ï¼Œæ­¤æ—¶ x[0] å¯¹åº”çš„ y[0] = fp[0] -> 3
- x[1] = 1.5, å®ƒåœ¨ xp çš„ [1, 2] ä¹‹é—´ï¼Œæ‰€ä»¥å¯¹åº”çš„ y[1] åº”è¯¥ä¸º y[0] = (fp[1] + f[2]) / 2 --> (3 + 5) / 2 = 4
- x[2] = 3.0 == xp[2], æ‰€ä»¥å¯¹åº”çš„ y[2] == fp[2] --> 7
- x[3] = 4.5 âˆˆ [4, 5], y[3] == (fp[4] + fp[5]) / 2 --> (9 + 11) / 2 --> 10
- x[4] = 6.0ï¼Œå®ƒå¤§äº xp çš„æœ€å¤§å€¼ï¼Œæ‰€ä»¥å¤–æ¨ï¼Œæ­¤è‡´ x[4] å¯¹åº”çš„ y[4] == fp[5] --> 11

> âš ï¸ x å’Œ y å–çš„æ˜¯ç´¢å¼•ï¼Œè€Œ xp å’Œ fp è¿™é‡Œä¸æ˜¯å–ç´¢å¼•ï¼Œè€Œæ˜¯å–å€¼

## 5.2 Cosine Annealing Warm Restart

- è®ºæ–‡åœ°å€ï¼š[SGDR: Stochastic Gradient Descent with Warm Restarts](https://arxiv.org/abs/1608.03983)
- ç¿»è¯‘ï¼š[Cosine Annealing Warm Restartè®ºæ–‡è®²è§£](https://blog.csdn.net/weixin_44878336/article/details/125016166)

Cosine Annealing Warm Restart æ˜¯ä¸€ç§å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ï¼Œå®ƒæ˜¯åŸºäºä½™å¼¦é€€ç«å‘¨æœŸæ€§è°ƒæ•´å­¦ä¹ ç‡çš„ç®—æ³•ã€‚è¿™ç§ç­–ç•¥åœ¨å­¦ä¹ ç‡è°ƒæ•´ä¸Šå¼•å…¥äº†å‘¨æœŸæ€§çš„â€œé‡å¯â€ï¼Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿå‘¨æœŸæ€§åœ°è·³å‡ºå±€éƒ¨æœ€å°å€¼ï¼Œä»è€Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½ã€‚

å…·ä½“æ¥è¯´ï¼ŒCosine Annealing Warm Restart ç­–ç•¥åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š

1. **ä½™å¼¦é€€ç«å‘¨æœŸ**ï¼šåœ¨æ¯ä¸ªå‘¨æœŸå†…ï¼Œå­¦ä¹ ç‡æŒ‰ç…§ä½™å¼¦å‡½æ•°çš„å˜åŒ–è§„å¾‹è¿›è¡Œè°ƒæ•´ã€‚ä½™å¼¦å‡½æ•°ä»æœ€å¤§å€¼å¼€å§‹ï¼Œé€æ¸å‡å°åˆ°æœ€å°å€¼ï¼Œå› æ­¤å­¦ä¹ ç‡ä¹Ÿä¼šä»åˆå§‹å€¼å¼€å§‹ï¼Œå…ˆå‡å°åˆ°ä¸€ä¸ªä½ç‚¹ï¼Œç„¶åå†å¢åŠ å›åˆ°åˆå§‹å€¼ã€‚
2. **å‘¨æœŸæ€§é‡å¯**ï¼šåœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ï¼Œå­¦ä¹ ç‡ä¼šè¢«é‡æ–°è®¾ç½®å›åˆå§‹å€¼ï¼Œå¹¶é‡æ–°å¼€å§‹ä¸€ä¸ªæ–°çš„å‘¨æœŸã€‚è¿™ç§é‡å¯æœ‰åŠ©äºæ¨¡å‹è·³å‡ºå½“å‰çš„ä¼˜åŒ–è·¯å¾„ï¼Œæ¢ç´¢æ–°çš„å‚æ•°ç©ºé—´ã€‚
3. **å‘¨æœŸé•¿åº¦è°ƒæ•´**ï¼šéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œå‘¨æœŸé•¿åº¦ï¼ˆå³é€€ç«å‘¨æœŸï¼‰å’Œæœ€å°å­¦ä¹ ç‡å¯ä»¥é€æ¸è°ƒæ•´ã€‚é€šå¸¸ï¼Œæ¯ä¸ªå‘¨æœŸçš„é•¿åº¦ä¼šé€æ¸å‡å°ï¼Œè€Œæœ€å°å­¦ä¹ ç‡ä¼šé€æ¸å¢åŠ ï¼Œè¿™æ ·å¯ä»¥è®©æ¨¡å‹åœ¨è®­ç»ƒåæœŸæ›´åŠ ç»†è‡´åœ°æœç´¢æœ€ä¼˜è§£ã€‚
4. **å­¦ä¹ ç‡èŒƒå›´**ï¼šåœ¨æ¯ä¸ªå‘¨æœŸå†…ï¼Œå­¦ä¹ ç‡çš„å˜åŒ–èŒƒå›´æ˜¯ä»æœ€å¤§å€¼åˆ°æœ€å°å€¼ï¼Œè¿™ä¸¤ä¸ªå€¼éƒ½å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

Cosine Annealing Warm Restart ç­–ç•¥çš„ä¼˜åŠ¿åœ¨äºå®ƒé€šè¿‡å‘¨æœŸæ€§é‡å¯å’Œè°ƒæ•´å‘¨æœŸé•¿åº¦ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­æ¢ç´¢æ–°çš„å‚æ•°ç©ºé—´ï¼Œä»è€Œæœ‰å¯èƒ½æ‰¾åˆ°æ›´å¥½çš„å±€éƒ¨æœ€å°å€¼æˆ–å…¨å±€æœ€å°å€¼ã€‚è¿™ç§ç­–ç•¥ç‰¹åˆ«é€‚åˆäºé‚£äº›å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼çš„å¤æ‚æ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æœ€ç»ˆæ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

åœ¨è®ºæ–‡ [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187) ä¸­æœ‰ä»‹ç»åˆ°ä½™å¼¦é€€ç«å’Œé˜¶æ®µä¸¤ç§å­¦ä¹ ç‡åœ¨ ImageNet æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆæ¨¡å‹ä¸º ResNet-50ï¼‰ï¼š

<div align=center>
    <img src=./imgs_markdown/2024-02-06-17-42-37.png
    width=70%>
    <center></center>
</div>

> å›¾ 3ï¼šå¸¦æœ‰çƒ­èº«é˜¶æ®µçš„å­¦ä¹ ç‡è®¡åˆ’çš„å¯è§†åŒ–ã€‚é¡¶éƒ¨ï¼šBatch size=1024 ä¸‹çš„ä½™å¼¦å’Œé˜¶è·ƒè°ƒåº¦ã€‚åº•éƒ¨ï¼šä¸¤ç§è°ƒåº¦ä¸‹çš„Top-1éªŒè¯å‡†ç¡®ç‡æ›²çº¿ã€‚

---

ä½™å¼¦é€€ç«çƒ­é‡å¯çš„è°ƒç”¨å¦‚ä¸‹ï¼š

```python
import torch.optim as optim


model = ...
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ä½¿ç”¨CosineAnnealingWarmRestartsè°ƒåº¦å™¨
# T_0æ˜¯åˆå§‹å‘¨æœŸçš„å¤§å°ï¼ŒT_multæ¯ä¸ªå‘¨æœŸç»“æŸåå‘¨æœŸå¤§å°ä¹˜ä»¥çš„å€æ•°
scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)

for epoch in range(num_epochs):
    # è®­ç»ƒæ¨¡å‹çš„ä»£ç 
    train(...)
    # åœ¨æ¯ä¸ªepochåæ›´æ–°å­¦ä¹ ç‡
    scheduler.step(epoch)
```

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œ`T_0` å‚æ•°ä»£è¡¨åˆå§‹å‘¨æœŸçš„å¤§å°ï¼Œå³åœ¨ç¬¬ä¸€æ¬¡ä½™å¼¦é€€ç«å‘¨æœŸä¸­ï¼Œå­¦ä¹ ç‡å°†æŒ‰ç…§ä½™å¼¦è°ƒåº¦è¿›è¡Œè°ƒæ•´çš„ Epoch æ•°ã€‚`T_mult` å‚æ•°æŒ‡å®šäº†æ¯ä¸ªå‘¨æœŸç»“æŸåå‘¨æœŸå¤§å°å°†ä¹˜ä»¥çš„å€æ•°ã€‚`scheduler.step(epoch)` åº”è¯¥åœ¨æ¯æ¬¡æ›´æ–°å‚æ•°ä¹‹åã€æ¯ä¸ªepochç»“æŸæ—¶è°ƒç”¨ã€‚
è¯·æ ¹æ®æˆ‘ä»¬çš„å…·ä½“éœ€æ±‚è°ƒæ•´ `T_0` å’Œ `T_mult` çš„å€¼ï¼Œä»¥åŠ `num_epochs`ï¼Œå³æˆ‘ä»¬çš„è®­ç»ƒå‘¨æœŸæ€»æ•°ã€‚

## 5.3 YOLOv5-v7.0 ä½¿ç”¨çš„ Scheduler

```python
# Scheduler
if opt.cos_lr:  # å¦‚æœä½¿ç”¨cosineå­¦ä¹ ç‡
    lf = one_cycle(1, hyp["lrf"], epochs)  # cosine 1->hyp['lrf']
else:
    lf = lambda x: (1 - x / epochs) * (1.0 - hyp["lrf"]) + hyp["lrf"]  # linear
scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  # plot_lr_scheduler(optimizer, scheduler, epochs)
```

æˆ‘ä»¬ç”»å›¾çœ‹ä¸€ä¸‹äºŒè€…çš„åŒºåˆ«ï¼š

```python
import matplotlib.pyplot as plt
import math


def one_cycle(y1=0.0, y2=1.0, steps=100):
    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1


# è®¾å®šè®­ç»ƒçš„æ€»epochæ•°
epochs = 100

# YOLOv5ä¸­çš„è¶…å‚æ•°
hyp = {
    "lr0": 0.01,  # åˆå§‹å­¦ä¹ ç‡
    "lrf": 0.1  # final OneCycleLR learning rate (lr0 * lrf)
}

# åˆ›å»ºä¸€ä¸ªnumpyæ•°ç»„ï¼Œè¡¨ç¤ºepochæ•°
epoch_lst = range(epochs)

# Cosineè°ƒåº¦å™¨çš„å­¦ä¹ ç‡å˜åŒ–
lf_cos = one_cycle(1, hyp["lrf"], epochs)
lr_cos = [lf_cos(epoch) for epoch in epoch_lst]

# Linearè°ƒåº¦å™¨çš„å­¦ä¹ ç‡å˜åŒ–
lf_lin = lambda x: (1 - x / epochs) * (1.0 - hyp["lrf"]) + hyp["lrf"]
lr_lin = [lf_lin(epoch) for epoch in epoch_lst]

# ç»˜åˆ¶å­¦ä¹ ç‡å˜åŒ–æ›²çº¿
plt.figure(figsize=(10, 6), dpi=200)

plt.plot(epoch_lst, lr_cos, '-', label='Cosine Scheduler', color='skyblue')
plt.plot(epoch_lst, lr_lin, '-.', label='Linear Scheduler', color='lightpink')

plt.xlabel('Epochs')
plt.ylabel('Learning Rate')
plt.title('Comparison of Cosine and Linear Learning Rate Schedulers')

plt.legend()
plt.grid(True)
plt.savefig('Le0v1n/results/Comparison-of-Cosine-and-Linear-Learning-Rate-Schedulers.jpg')
```

<div align=center>
    <img src=./imgs_markdown/Comparison-of-Cosine-and-Linear-Learning-Rate-Schedulers.jpg
    width=100%>
    <center></center>
</div>

## 5.3 AutoAnchor

### 5.3.1 ç›®çš„

AutoAnchor æ˜¯ YOLOv5 ä¸­çš„ä¸€ä¸ªåŠŸèƒ½ï¼Œç”¨äºè‡ªåŠ¨è°ƒæ•´ Anchorï¼ˆanchor boxesï¼‰çš„å¤§å°ä»¥æ›´å¥½åœ°é€‚åº”è®­ç»ƒæ•°æ®é›†ä¸­çš„å¯¹è±¡å½¢çŠ¶ã€‚

> Anchor æ˜¯åœ¨å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­ä½¿ç”¨çš„ä¸€ç§æŠ€æœ¯ï¼Œå®ƒä»¬ä»£è¡¨äº†ä¸åŒå¤§å°å’Œå®½é«˜æ¯”çš„é¢„å®šä¹‰è¾¹ç•Œæ¡†ï¼Œç”¨äºé¢„æµ‹çœŸå®å¯¹è±¡çš„ä½ç½®å’Œå¤§å°ã€‚

åœ¨ YOLOv5 ä¸­ï¼ŒAutoAnchor çš„ä¸»è¦ç›®çš„æ˜¯ä¼˜åŒ– Anchor çš„å¤§å°ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´æé«˜æ£€æµ‹ç²¾åº¦å’Œæ•ˆç‡ã€‚è¿™ä¸ªåŠŸèƒ½åœ¨è®­ç»ƒè¿‡ç¨‹å¼€å§‹æ—¶æ‰§è¡Œï¼Œæ ¹æ®è®­ç»ƒæ•°æ®é›†ä¸­çš„è¾¹ç•Œæ¡†è®¡ç®—æœ€ä½³ Anchor é…ç½®ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒYOLOv5 å¯ä»¥è‡ªåŠ¨é€‚åº”æ–°çš„æ•°æ®é›†ï¼Œè€Œæ— éœ€æ‰‹åŠ¨è°ƒæ•´ Anchorã€‚

### 5.3.2 AutoAnchor çš„æ­¥éª¤

1. **åˆ†ææ•°æ®é›†**ï¼šåˆ†ææ•°æ®é›†ä¸­çš„è¾¹ç•Œæ¡†ï¼Œäº†è§£å¯¹è±¡çš„å¤§å°å’Œå½¢çŠ¶åˆ†å¸ƒã€‚
2. **Anchorèšç±»**ï¼šä½¿ç”¨èšç±»ç®—æ³•ï¼ˆå¦‚ K-meansï¼‰å¯¹è¾¹ç•Œæ¡†è¿›è¡Œèšç±»ï¼Œä»¥ç¡®å®šæœ€ä½³çš„ Anchor æ•°é‡å’Œå¤§å°ã€‚
3. **æ›´æ–°é…ç½®**ï¼šæ ¹æ®èšç±»ç»“æœæ›´æ–° Anchor é…ç½®ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨è¿™äº›æ–° Anchorã€‚
4. **é‡æ–°è®­ç»ƒ**ï¼šä½¿ç”¨æ–°çš„ Anchor é…ç½®é‡æ–°å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚

### 5.3.3 ä½œç”¨

AutoAnchor çš„ä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿä¸ºç‰¹å®šçš„æ•°æ®é›†å®šåˆ¶ Anchorï¼Œè¿™æœ‰åŠ©äºæé«˜æ£€æµ‹ç²¾åº¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å…·æœ‰ä¸åŒå¯¹è±¡å¤§å°å’Œå½¢çŠ¶çš„å¤šæ ·åŒ–æ•°æ®é›†æ—¶ã€‚é€šè¿‡è‡ªåŠ¨è°ƒæ•´ Anchorï¼ŒYOLOv5 å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œå‡å°‘å¯¹è¶…å‚æ•°çš„æ‰‹åŠ¨è°ƒæ•´éœ€æ±‚ï¼Œä»è€Œç®€åŒ–äº†æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ã€‚

### 5.3.4 æºç 

é¦–å…ˆéœ€è¦å…ˆè®¡ç®—å½“å‰çš„ Anchor ä¸æ•°æ®é›†çš„é€‚åº”ç¨‹åº¦ã€‚

```python
@TryExcept(f"{PREFIX}ERROR")
def check_anchors(dataset, model, thr=4.0, imgsz=640):
    # å‡½æ•°ä½œç”¨ï¼šæ£€æŸ¥anchoræ˜¯å¦é€‚åˆæ•°æ®ï¼Œå¦‚æœ‰å¿…è¦ï¼Œåˆ™é‡æ–°è®¡ç®—anchor

    # ä»æ¨¡å‹ä¸­è·å–æ£€æµ‹å±‚ï¼ˆDetect()ï¼‰
    m = model.module.model[-1] if hasattr(model, "module") else model.model[-1]
    
    # è®¡ç®—è¾“å…¥å›¾ç‰‡çš„å°ºå¯¸ç›¸å¯¹äºæœ€å¤§å°ºå¯¸çš„æ¯”ä¾‹
    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)

    # ç”Ÿæˆä¸€ä¸ªéšæœºçš„æ¯”ä¾‹å› å­ï¼Œç”¨äºæ‰©å¤§æˆ–ç¼©å°å›¾ç‰‡å°ºå¯¸
    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))

    # è®¡ç®—æ‰€æœ‰å›¾ç‰‡çš„å®½é«˜ï¼ˆwhï¼‰
    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)]))

    def metric(k):  # è®¡ç®—åº¦é‡å€¼
        # è®¡ç®—æ¯ä¸ªanchorä¸gt boxesçš„å®½é«˜æ¯”
        r = wh[:, None] / k[None]

        # è®¡ç®—æœ€å°æ¯”ç‡å’Œæœ€å¤§æ¯”ç‡
        x = torch.min(r, 1 / r).min(2)[0]

        # æ‰¾åˆ°æœ€å¤§æ¯”ç‡çš„anchor
        best = x.max(1)[0]

        # è®¡ç®—è¶…è¿‡é˜ˆå€¼ï¼ˆthrï¼‰çš„anchoræ•°é‡å æ¯”
        aat = (x > 1 / thr).float().sum(1).mean()

        # è®¡ç®—BPRï¼ˆbest possible recallï¼‰
        bpr = (best > 1 / thr).float().mean()

        return bpr, aat

    # è·å–æ¨¡å‹çš„æ­¥é•¿ï¼ˆstrideï¼‰
    stride = m.stride.to(m.anchors.device).view(-1, 1, 1)

    # è®¡ç®—å½“å‰çš„anchor
    anchors = m.anchors.clone() * stride
    
    # è®¡ç®—å½“å‰anchorä¸gt boxesçš„æ¯”å€¼ï¼Œå¹¶æ‰¾åˆ°æœ€ä½³æ¯”å€¼å’Œè¶…è¿‡é˜ˆå€¼çš„anchorå æ¯”
    bpr, aat = metric(anchors.cpu().view(-1, 2))
    s = f"\n{PREFIX}{aat:.2f} anchors/target, {bpr:.3f} Best Possible Recall (BPR). "
    
    # å¦‚æœæœ€ä½³æ¯”å€¼å¬å›ç‡å¤§äº0.98ï¼Œè¯´æ˜å½“å‰anchoré€‚åˆæ•°æ®é›†
    if bpr > 0.98:
        LOGGER.info(f"{s}Current anchors are a good fit to dataset âœ…")
    else:  # è¯´æ˜anchorä¸é€‚åˆæ•°æ®é›†ï¼Œéœ€è¦å°è¯•æ”¹è¿›
        LOGGER.info(f"{s}Anchors are a poor fit to dataset âš ï¸, attempting to improve...")

        # è®¡ç®—anchoræ•°é‡
        na = m.anchors.numel() // 2

        # ä½¿ç”¨k-meansèšç±»ç®—æ³•é‡æ–°è®¡ç®—anchor
        anchors = kmean_anchors(dataset, n=na, img_size=imgsz, thr=thr, gen=1000, verbose=False)

        # è®¡ç®—æ–°anchorçš„æœ€ä½³æ¯”å€¼å¬å›ç‡
        new_bpr = metric(anchors)[0]

        # å¦‚æœæ–°anchorçš„å¬å›ç‡æ¯”åŸæ¥çš„é«˜ï¼Œåˆ™æ›¿æ¢anchor
        if new_bpr > bpr:
            anchors = torch.tensor(anchors, device=m.anchors.device).type_as(m.anchors)
            m.anchors[:] = anchors.clone().view_as(m.anchors)

            # æ£€æŸ¥anchoré¡ºåºæ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»åœ¨åƒç´ ç©ºé—´ï¼Œä¸èƒ½åœ¨ç½‘æ ¼ç©ºé—´ï¼‰
            check_anchor_order(m)
            m.anchors /= stride
            s = f"{PREFIX}Done
```

## 5.4 Hyper-parameter Evolution è¶…å‚æ•°è¿›åŒ–

è¶…å‚æ•°è¿›åŒ–ï¼ˆHyperparameter Evolutionï¼‰æ˜¯ä¸€ç§æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯ï¼Œå®ƒæ¶‰åŠåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€åœ°è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼ˆhyperparametersï¼‰ï¼Œä»¥æ‰¾åˆ°åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šæ€§èƒ½æœ€ä½³çš„å‚æ•°è®¾ç½®ã€‚è¿™äº›è¶…å‚æ•°æ˜¯æ¨¡å‹è®¾è®¡ä¸­çš„é«˜çº§è®¾ç½®ï¼Œå®ƒä»¬æ§åˆ¶æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ï¼Œä½†ä¸ç›´æ¥ä½œä¸ºæ¨¡å‹è¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚å¸¸è§çš„è¶…å‚æ•°åŒ…æ‹¬å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€è¿­ä»£æ¬¡æ•°ã€æ­£åˆ™åŒ–å‚æ•°ã€Anchor å¤§å°ç­‰ã€‚

è¶…å‚æ•°è¿›åŒ–çš„ç›®æ ‡æ˜¯å‡å°‘è¶…å‚æ•°è°ƒæ•´çš„è¯•é”™è¿‡ç¨‹ï¼Œæé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡ã€‚ä¼ ç»Ÿçš„è¶…å‚æ•°è°ƒæ•´æ–¹æ³•é€šå¸¸éœ€è¦æ‰‹åŠ¨è°ƒæ•´è¶…å‚æ•°æˆ–ä½¿ç”¨ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰ç­‰æ–¹æ³•è¿›è¡Œå¤§é‡çš„å®éªŒæ¥æ‰¾åˆ°æœ€ä½³è®¾ç½®ã€‚è¿™äº›æ–¹æ³•æ—¢è€—æ—¶åˆå¯èƒ½æ— æ³•æ‰¾åˆ°æœ€ä¼˜è§£ã€‚

åœ¨ [ã€Šè¶…å‚æ•°æ¼”å˜ã€‹](https://docs.ultralytics.com/zh/yolov5/tutorials/hyperparameter_evolution/) è¿™ä¸€å®˜æ–¹æ–‡æ¡£ä¸­å¯¹å…¶è¿›è¡Œäº†ä»‹ç»ï¼š

è¶…å‚æ•°æ¼”åŒ–æ˜¯ä¸€ç§ä½¿ç”¨é—ä¼ ç®—æ³•ï¼ˆGAï¼‰è¿›è¡Œä¼˜åŒ–çš„è¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ã€‚

ML ä¸­çš„è¶…å‚æ•°æ§åˆ¶ç€è®­ç»ƒçš„å„ä¸ªæ–¹é¢ï¼Œè€Œä¸ºè¶…å‚æ•°å¯»æ‰¾æœ€ä½³å€¼æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚ç½‘æ ¼æœç´¢ç­‰ä¼ ç»Ÿæ–¹æ³•å¾ˆå¿«å°±ä¼šå˜å¾—éš¾ä»¥å¤„ç†ï¼ŒåŸå› åœ¨äºï¼š1ï¼‰æœç´¢ç©ºé—´ç»´åº¦é«˜ï¼›2ï¼‰ç»´åº¦ä¹‹é—´çš„ç›¸å…³æ€§æœªçŸ¥ï¼›3ï¼‰è¯„ä¼°æ¯ä¸ªç‚¹çš„é€‚é…æ€§æˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤ GA æ˜¯è¶…å‚æ•°æœç´¢çš„åˆé€‚å€™é€‰æ–¹æ³•ã€‚

GA çš„æµç¨‹å¦‚ä¸‹ï¼š

<div align=center>
    <img src=./imgs_markdown/plots-GA.jpg
    width=80%>
    <center></center>
</div>

æˆ‘ä»¬çœ‹ä¸€ä¸‹å®˜æ–¹çš„ä»‹ç»ï¼š

### 5.4.1 åˆå§‹åŒ–è¶…å‚æ•°

YOLOv5 æœ‰å¤§çº¦ 30 ä¸ªè¶…å‚æ•°ï¼Œç”¨äºä¸åŒçš„è®­ç»ƒè®¾ç½®ã€‚è¿™äº›å‚æ•°åœ¨ `*.yaml` æ–‡ä»¶ä¸­çš„ `/data/hyps` ç›®å½•ã€‚æ›´å¥½çš„åˆå§‹çŒœæµ‹å°†äº§ç”Ÿæ›´å¥½çš„æœ€ç»ˆç»“æœï¼Œå› æ­¤åœ¨æ¼”åŒ–ä¹‹å‰æ­£ç¡®åˆå§‹åŒ–è¿™äº›å€¼éå¸¸é‡è¦ã€‚å¦‚æœæœ‰ç–‘é—®ï¼Œåªéœ€ä½¿ç”¨é»˜è®¤å€¼å³å¯ï¼Œè¿™äº›å€¼å·²é’ˆå¯¹ YOLOv5 COCO ä»å¤´å¼€å§‹çš„è®­ç»ƒè¿›è¡Œäº†ä¼˜åŒ–ã€‚

```yaml
# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
# Hyperparameters for low-augmentation COCO training from scratch

lr0: 0.01 # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.01 # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937 # SGD momentum/Adam beta1
weight_decay: 0.0005 # optimizer weight decay 5e-4
warmup_epochs: 3.0 # warmup epochs (fractions ok)
warmup_momentum: 0.8 # warmup initial momentum
warmup_bias_lr: 0.1 # warmup initial bias lr
box: 0.05 # box loss gain
cls: 0.5 # cls loss gain
cls_pw: 1.0 # cls BCELoss positive_weight
obj: 1.0 # obj loss gain (scale with pixels)
obj_pw: 1.0 # obj BCELoss positive_weight
iou_t: 0.20 # IoU training threshold
anchor_t: 4.0 # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0 # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.015 # image HSV-Hue augmentation (fraction)
hsv_s: 0.7 # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4 # image HSV-Value augmentation (fraction)
degrees: 0.0 # image rotation (+/- deg)
translate: 0.1 # image translation (+/- fraction)
scale: 0.5 # image scale (+/- gain)
shear: 0.0 # image shear (+/- deg)
perspective: 0.0 # image perspective (+/- fraction), range 0-0.001
flipud: 0.0 # image flip up-down (probability)
fliplr: 0.5 # image flip left-right (probability)
mosaic: 1.0 # image mosaic (probability)
mixup: 0.0 # image mixup (probability)
copy_paste: 0.0 # segment copy-paste (probability)
```

### 5.4.2 å®šä¹‰é€‚åº”åº¦ï¼ˆfitnessï¼‰

é€‚åº”åº¦æ˜¯æˆ‘ä»¬è¯•å›¾æœ€å¤§åŒ–çš„å€¼ã€‚åœ¨ YOLOv5 ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªé»˜è®¤çš„é€‚åº”åº¦å‡½æ•°ï¼Œå®ƒæ˜¯ä»¥ä¸‹æŒ‡æ ‡çš„åŠ æƒç»„åˆï¼š`mAP@0.5` è´¡çŒ®äº† 10% çš„æƒé‡ï¼Œè€Œ `mAP@0.5:0.95` è´¡çŒ®äº†å‰©ä½™çš„ 90%ï¼Œå…¶ä¸­ä¸åŒ…æ‹¬ Precision `P` å’Œ Recall `R`ã€‚æˆ‘ä»¬å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¿™äº›æŒ‡æ ‡ï¼Œæˆ–è€…ä½¿ç”¨ `utils/metrics.py` ä¸­çš„é»˜è®¤é€‚åº”åº¦å®šä¹‰ï¼ˆå»ºè®®ä½¿ç”¨ï¼‰ã€‚

```python
def fitness(x):
    # Model fitness as a weighted combination of metrics
    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]
    return (x[:, :4] * w).sum(1)
```

ç®€å•æ¥è¯´ï¼š

$$
\mathrm{fitness} = 0.1 \times \mathrm{mAP^{0.5}} + 0.9 \times \mathrm{mAP^{0.5:0.95}}
$$

### 5.4.3 è¿›åŒ–ï¼ˆEvolveï¼‰

è¿›åŒ–æ˜¯åŸºäºæˆ‘ä»¬å¯»æ±‚æ”¹è¿›çš„åŸºç¡€æƒ…æ™¯è¿›è¡Œçš„ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒåŸºç¡€æƒ…æ™¯æ˜¯åœ¨ COCO128 ä¸Šå¯¹é¢„è®­ç»ƒçš„ YOLOv5s è¿›è¡Œ 10 ä¸ªå‘¨æœŸçš„å¾®è°ƒã€‚åŸºç¡€æƒ…æ™¯çš„è®­ç»ƒå‘½ä»¤æ˜¯ï¼š

```bash
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache
```

ä¸ºäº†é’ˆå¯¹è¿™ä¸ªæƒ…æ™¯è¿›åŒ–ç‰¹å®šçš„è¶…å‚æ•°ï¼Œä»æˆ‘ä»¬åœ¨ 5.4.1 ä¸­å®šä¹‰çš„åˆå§‹å€¼å¼€å§‹ï¼Œå¹¶æœ€å¤§åŒ–æˆ‘ä»¬åœ¨ 5.4.2 ä¸­å®šä¹‰çš„é€‚åº”åº¦ï¼Œè¯·åœ¨å‘½ä»¤è¡Œä¸­æ·»åŠ  `--evolve` å‚æ•°ï¼š

```bash
# Single-GPU
python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --evolve

# Multi-GPU
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30-second delay (optional)
  echo 'Starting GPU '$i'...' &&
  nohup python train.py --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache --device $i --evolve > evolve_gpu_$i.log &
done

# Multi-GPU bash-while (not recommended)
for i in 0 1 2 3 4 5 6 7; do
  sleep $(expr 30 \* $i) &&  # 30-second delay (optional)
  echo 'Starting GPU '$i'...' &&
  "$(while true; do nohup python train.py... --device $i --evolve 1 > evolve_gpu_$i.log; done)" &
done
```

> ğŸ’¡ nohup å‘½ä»¤ï¼š`nohup` æ˜¯ä¸€ä¸ªåœ¨ Unix-like ç³»ç»Ÿä¸­å¸¸ç”¨çš„å‘½ä»¤ï¼Œç”¨äºåœ¨ç”¨æˆ·é€€å‡ºç™»å½•ä¼šè¯åç»§ç»­è¿è¡Œå‘½ä»¤ã€‚è¿™ä¸ªåå­—æ˜¯ "no hang up" çš„ç¼©å†™ï¼Œæ„å‘³ç€å³ä½¿ä¼šè¯æŒ‚èµ·ï¼ˆå³ç”¨æˆ·é€€å‡ºç™»å½•ï¼‰ï¼Œå‘½ä»¤ä¹Ÿä¼šç»§ç»­æ‰§è¡Œã€‚

é»˜è®¤çš„è¶…å‚æ•°è¿›åŒ–è®¾ç½®å°†è¿è¡ŒåŸºç¡€æƒ…æ™¯ 300 æ¬¡ï¼Œå³è¿›è¡Œ 300 ä»£è¿›åŒ–ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ `--evolve` å‚æ•°ä¿®æ”¹ä»£æ•°ï¼Œä¾‹å¦‚ `python train. py --evolve 1000`ã€‚

ä¸»è¦çš„é—ä¼ è¿ç®—ç¬¦æ˜¯äº¤å‰ï¼ˆcrossoverï¼‰å’Œå˜å¼‚ï¼ˆmutationï¼‰ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œå˜å¼‚è¢«ä½¿ç”¨ï¼Œå˜å¼‚æ¦‚ç‡ä¸º 80%ï¼Œæ–¹å·®ä¸º 0.04ï¼ŒåŸºäºæ‰€æœ‰ä¹‹å‰ä»£ä¸­æœ€ä½³çˆ¶æ¯ç»„åˆåˆ›å»ºæ–°çš„åä»£ã€‚ç»“æœè¢«è®°å½•åˆ° `runs/evolve/exp/evolve.csv`ï¼Œå¹¶ä¸”æ¯ä¸€ä»£ä¸­é€‚åº”åº¦æœ€é«˜çš„åä»£éƒ½è¢«ä¿å­˜ä¸º `runs/evolve/hyp_evolved.yaml`ï¼š

```yaml
# YOLOv5 Hyperparameter Evolution Results
# Best generation: 287
# Last generation: 300
#    metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss
#              0.54634,              0.55625,              0.58201,              0.33665,             0.056451,             0.042892,             0.013441

lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 0.05  # box loss gain
cls: 0.5  # cls loss gain
cls_pw: 1.0  # cls BCELoss positive_weight
obj: 1.0  # obj loss gain (scale with pixels)
obj_pw: 1.0  # obj BCELoss positive_weight
iou_t: 0.20  # IoU training threshold
anchor_t: 4.0  # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.1  # image translation (+/- fraction)
scale: 0.5  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 1.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)
```

æˆ‘ä»¬å»ºè®®è‡³å°‘è¿›è¡Œ 300 ä»£çš„è¿›åŒ–ä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚âš ï¸ è¯·æ³¨æ„ï¼Œè¿›åŒ–é€šå¸¸æ—¢æ˜‚è´µåˆè€—æ—¶ï¼Œå› ä¸ºåŸºç¡€æƒ…æ™¯éœ€è¦è®­ç»ƒæ•°ç™¾æ¬¡ï¼Œå¯èƒ½éœ€è¦æ•°ç™¾æˆ–æ•°åƒå°æ—¶çš„ GPU æ—¶é—´ã€‚

### 5.4.4 å¯è§†åŒ–ï¼ˆVisualizeï¼‰

`evolve.csv` åœ¨è¿›åŒ–å®Œæˆä¹‹åï¼Œç”± `utils.plots.plot_evolve()` ç»˜åˆ¶ä¸º `evolve.png`ï¼Œæ¯ä¸ªè¶…å‚æ•°éƒ½æœ‰ä¸€ä¸ªå­å›¾ï¼Œæ˜¾ç¤ºé€‚åº”åº¦ï¼ˆyè½´ï¼‰ä¸è¶…å‚æ•°å€¼ï¼ˆxè½´ï¼‰çš„å…³ç³»ã€‚é»„è‰²è¡¨ç¤ºæ›´é«˜çš„æµ“åº¦ã€‚å‚ç›´åˆ†å¸ƒè¡¨æ˜ä¸€ä¸ªå‚æ•°å·²è¢«ç¦ç”¨ä¸”ä¸ä¼šå˜å¼‚ã€‚è¿™å¯ä»¥åœ¨ `train.py` ä¸­çš„å…ƒå­—å…¸ä¸­é€‰æ‹©ï¼Œå¯¹äºå›ºå®šå‚æ•°å¹¶é˜²æ­¢å®ƒä»¬è¿›åŒ–çš„åœºæ™¯éå¸¸æœ‰ç”¨ã€‚

<div align=center>
    <img src=./imgs_markdown/2024-02-07-14-31-43.png
    width=100%>
    <center></center>
</div>

### 5.4.5 æºç 

```python
# Hyperparameter evolution metadata (including this hyperparameter True-False, lower_limit, upper_limit)
# è¶…å‚æ•°è¿›åŒ–metadataï¼ˆåŒ…æ‹¬æ­¤è¶…å‚æ•°æ˜¯å¦å‚ä¸è¿›åŒ–ï¼Œä¸‹é™ï¼Œä¸Šé™ï¼‰
meta = {
    "lr0": (False, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)
    "lrf": (False, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)
    "momentum": (False, 0.6, 0.98),  # SGD momentum/Adam beta1
    "weight_decay": (False, 0.0, 0.001),  # optimizer weight decay
    "warmup_epochs": (False, 0.0, 5.0),  # warmup epochs (fractions ok)
    "warmup_momentum": (False, 0.0, 0.95),  # warmup initial momentum
    "warmup_bias_lr": (False, 0.0, 0.2),  # warmup initial bias lr
    "box": (False, 0.02, 0.2),  # box loss gain
    "cls": (False, 0.2, 4.0),  # cls loss gain
    "cls_pw": (False, 0.5, 2.0),  # cls BCELoss positive_weight
    "obj": (False, 0.2, 4.0),  # obj loss gain (scale with pixels)
    "obj_pw": (False, 0.5, 2.0),  # obj BCELoss positive_weight
    "iou_t": (False, 0.1, 0.7),  # IoU training threshold
    "anchor_t": (False, 2.0, 8.0),  # anchor-multiple threshold
    "anchors": (False, 2.0, 10.0),  # anchors per output grid (0 to ignore)
    "fl_gamma": (False, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)
    "hsv_h": (True, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)
    "hsv_s": (True, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)
    "hsv_v": (True, 0.0, 0.9),  # image HSV-Value augmentation (fraction)
    "degrees": (True, 0.0, 45.0),  # image rotation (+/- deg)
    "translate": (True, 0.0, 0.9),  # image translation (+/- fraction)
    "scale": (True, 0.0, 0.9),  # image scale (+/- gain)
    "shear": (True, 0.0, 10.0),  # image shear (+/- deg)
    "perspective": (True, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001
    "flipud": (True, 0.0, 1.0),  # image flip up-down (probability)
    "fliplr": (True, 0.0, 1.0),  # image flip left-right (probability)
    "mosaic": (True, 0.0, 1.0),  # image mixup (probability)
    "mixup": (True, 0.0, 1.0),  # image mixup (probability)
    "copy_paste": (True, 0.0, 1.0),
}  # segment copy-paste (probability)

# GA configs
# é—ä¼ ç®—æ³•çš„é…ç½®
pop_size = 50  # # ç§ç¾¤å¤§å°

# å˜å¼‚ç‡çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
mutation_rate_min = 0.01
mutation_rate_max = 0.5

# äº¤å‰ç‡çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
crossover_rate_min = 0.5
crossover_rate_max = 1

# ç²¾è‹±å¤§å°ï¼ˆä¿ç•™çš„æœ€å¥½ä¸ªä½“æ•°é‡ï¼‰çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
min_elite_size = 2
max_elite_size = 5

# é”¦æ ‡èµ›å¤§å°ï¼ˆç”¨äºé€‰æ‹©çˆ¶ä»£çš„é€‰æ‹©æ± å¤§å°ï¼‰çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
tournament_size_min = 2
tournament_size_max = 10

with open(opt.hyp, errors="ignore") as f:
    hyp = yaml.safe_load(f)  # load hyps dict

    # å¦‚æœåœ¨.yamlæ–‡ä»¶ä¸­æ²¡æœ‰ anchors è¿™ä¸ªè¶…å‚æ•°ï¼Œé‚£ä¹ˆæˆ‘ä»¬åŠ ä¸Š
    if "anchors" not in hyp:  # anchors commented in hyp.yaml
        hyp["anchors"] = 3

# ä¸ä½¿ç”¨AutoAnchors
if opt.noautoanchor:
    del hyp["anchors"], meta["anchors"]  # ä»GAç§ç¾¤ä¸­åˆ å»

# ä¿®æ”¹éƒ¨åˆ†å‚æ•°å€¼
opt.noval, opt.nosave, save_dir = True, True, Path(opt.save_dir)  # only val/save final epoch

# æ‹¼æ¥ä¿å­˜è·¯å¾„
evolve_yaml, evolve_csv = save_dir / "hyp_evolve.yaml", save_dir / "evolve.csv"

# Delete the items in meta dictionary whose first value is False
# åˆ é™¤å…ƒå­—å…¸ä¸­å…¶ç¬¬ä¸€ä¸ªå€¼ä¸º False çš„é¡¹ --> ä¸å‚ä¸è¿›åŒ–çš„å‚æ•°éƒ½åˆ æ‰
del_ = [item for item, value_ in meta.items() if value_[0] is False]

# åœ¨åˆ é™¤ä¹‹å‰å¤‡ä»½ä¸€ä¸‹
hyp_GA = hyp.copy()  # Make a copy of hyp dictionary

# å¼€å§‹åˆ é™¤ä¸å‚ä¸è¿›åŒ–çš„è¶…å‚æ•°
for item in del_:
    del meta[item]  # Remove the item from meta dictionary
    del hyp_GA[item]  # Remove the item from hyp_GA dictionary

# Set lower_limit and upper_limit arrays to hold the search space boundaries
# è®¾ç½® lower_limit å’Œ upper_limit æ•°ç»„ä»¥ä¿æŒæœç´¢ç©ºé—´çš„è¾¹ç•Œ
lower_limit = np.array([meta[k][1] for k in hyp_GA.keys()])
upper_limit = np.array([meta[k][2] for k in hyp_GA.keys()])

# Create gene_ranges list to hold the range of values for each gene in the population
# åˆ›å»º gene_ranges åˆ—è¡¨ä»¥æŒæœ‰ç§ç¾¤ä¸­æ¯ä¸ªåŸºå› å€¼çš„èŒƒå›´
gene_ranges = [(lower_limit[i], upper_limit[i]) for i in range(len(upper_limit))]

# Initialize the population with initial_values or random values
# åˆå§‹åŒ–ç§ç¾¤ï¼Œä½¿ç”¨åˆå§‹å€¼æˆ–éšæœºå€¼
initial_values = []

# If resuming evolution from a previous checkpoint
# æ ¹æ®ä¹‹å‰çš„ ckpt ç»§ç»­è¿›åŒ–
if opt.resume_evolve is not None:
    assert os.path.isfile(ROOT / opt.resume_evolve), "evolve population path is wrong!"
    with open(ROOT / opt.resume_evolve, errors="ignore") as f:
        evolve_population = yaml.safe_load(f)
        for value in evolve_population.values():
            value = np.array([value[k] for k in hyp_GA.keys()])
            initial_values.append(list(value))

# If not resuming from a previous checkpoint, generate initial values from .yaml files in opt.evolve_population
# å¦‚æœä¸æ˜¯ä»ä¹‹å‰çš„ckptæ¢å¤ï¼Œåˆ™ä» opt.evolve_population ä¸­çš„ .yaml æ–‡ä»¶ç”Ÿæˆåˆå§‹å€¼
else:
    yaml_files = [f for f in os.listdir(opt.evolve_population) if f.endswith(".yaml")]
    for file_name in yaml_files:
        with open(os.path.join(opt.evolve_population, file_name)) as yaml_file:
            value = yaml.safe_load(yaml_file)
            value = np.array([value[k] for k in hyp_GA.keys()])
            initial_values.append(list(value))

# Generate random values within the search space for the rest of the population
# ä¸ºç§ç¾¤ä¸­å‰©ä½™çš„éƒ¨åˆ†åœ¨æœç´¢ç©ºé—´å†…ç”Ÿæˆéšæœºå€¼
if initial_values is None:
    population = [generate_individual(gene_ranges, len(hyp_GA)) for _ in range(pop_size)]
elif pop_size > 1:
    population = [generate_individual(gene_ranges, len(hyp_GA)) for _ in range(pop_size - len(initial_values))]
    for initial_value in initial_values:
        population = [initial_value] + population

# Run the genetic algorithm for a fixed number of generations
# å¯¹å›ºå®šçš„ä¸€ä»£æ•°è¿è¡Œé—ä¼ ç®—æ³•
list_keys = list(hyp_GA.keys())
for generation in range(opt.evolve):
    if generation >= 1:
        save_dict = {}
        for i in range(len(population)):
            little_dict = {list_keys[j]: float(population[i][j]) for j in range(len(population[i]))}
            save_dict[f"gen{str(generation)}number{str(i)}"] = little_dict

        with open(save_dir / "evolve_population.yaml", "w") as outfile:
            yaml.dump(save_dict, outfile, default_flow_style=False)

    # Adaptive elite size
    # è‡ªé€‚åº”ç²¾è‹±çš„å¤§å°
    elite_size = min_elite_size + int((max_elite_size - min_elite_size) * (generation / opt.evolve))

    # Evaluate the fitness of each individual in the population
    # è¯„ä¼°ç§ç¾¤ä¸­æ¯ä¸ªä¸ªä½“çš„é€‚åº”åº¦
    fitness_scores = []
    for individual in population:
        for key, value in zip(hyp_GA.keys(), individual):
            hyp_GA[key] = value
        hyp.update(hyp_GA)
        results = train(hyp.copy(), opt, device, callbacks)
        callbacks = Callbacks()
        # Write mutation results
        # å†™å…¥å˜å¼‚ç»“æœ
        keys = (
            "metrics/precision",
            "metrics/recall",
            "metrics/mAP_0.5",
            "metrics/mAP_0.5:0.95",
            "val/box_loss",
            "val/obj_loss",
            "val/cls_loss",
        )
        print_mutation(keys, results, hyp.copy(), save_dir, opt.bucket)
        fitness_scores.append(results[2])

    # Select the fittest individuals for reproduction using adaptive tournament selection
    # ä½¿ç”¨â€œè‡ªé€‚åº”é”¦æ ‡èµ›é€‰æ‹©â€é€‰æ‹©é€‚åº”åº¦æœ€é«˜çš„è¿›è¡Œç¹æ®–
    selected_indices = []
    for _ in range(pop_size - elite_size):
        # Adaptive tournament size
        # è‡ªé€‚åº”
        tournament_size = max(
            max(2, tournament_size_min),
            int(min(tournament_size_max, pop_size) - (generation / (opt.evolve / 10))),
        )
        # Perform tournament selection to choose the best individual
        # æ‰§è¡Œé”¦æ ‡èµ›é€‰æ‹©ä»è€ŒæŒ‘é€‰å‡ºæœ€ä½³çš„ä¸ªä½“
        tournament_indices = random.sample(range(pop_size), tournament_size)
        tournament_fitness = [fitness_scores[j] for j in tournament_indices]
        winner_index = tournament_indices[tournament_fitness.index(max(tournament_fitness))]
        selected_indices.append(winner_index)

    # Add the elite individuals to the selected indices
    # å°†ç²¾è‹±ä¸ªä½“æ·»åŠ åˆ°é€‰å®šçš„ç´¢å¼•ä¸­
    elite_indices = [i for i in range(pop_size) if fitness_scores[i] in sorted(fitness_scores)[-elite_size:]]
    selected_indices.extend(elite_indices)

    # Create the next generation through crossover and mutation
    # é€šè¿‡äº¤å‰å’Œå˜å¼‚åˆ›é€ ä¸‹ä¸€ä»£
    next_generation = []
    for _ in range(pop_size):
        parent1_index = selected_indices[random.randint(0, pop_size - 1)]
        parent2_index = selected_indices[random.randint(0, pop_size - 1)]

        # Adaptive crossover rate
        # è‡ªé€‚åº”äº¤å‰ï¼ˆäº¤é…ï¼‰æ¯”ä¾‹
        crossover_rate = max(
            crossover_rate_min, min(crossover_rate_max, crossover_rate_max - (generation / opt.evolve))
        )
        if random.uniform(0, 1) < crossover_rate:
            crossover_point = random.randint(1, len(hyp_GA) - 1)
            child = population[parent1_index][:crossover_point] + population[parent2_index][crossover_point:]
        else:
            child = population[parent1_index]

        # Adaptive mutation rate
        # è‡ªé€‚åº”å˜å¼‚æ¯”ä¾‹
        mutation_rate = max(
            mutation_rate_min, min(mutation_rate_max, mutation_rate_max - (generation / opt.evolve))
        )
        for j in range(len(hyp_GA)):
            if random.uniform(0, 1) < mutation_rate:
                child[j] += random.uniform(-0.1, 0.1)
                child[j] = min(max(child[j], gene_ranges[j][0]), gene_ranges[j][1])
        next_generation.append(child)

    # Replace the old population with the new generation
    # ç”¨æ–°ä¸€ä»£æ›¿æ¢æ—§ç§ç¾¤
    population = next_generation

# Print the best solution found
# æ‰“å°æ‰¾åˆ°çš„æœ€ä½³è§£å†³æ–¹æ¡ˆ
best_index = fitness_scores.index(max(fitness_scores))
best_individual = population[best_index]
print("Best solution found:", best_individual)

# Plot results
# ç»˜åˆ¶ç»“æœ
plot_evolve(evolve_csv)
LOGGER.info(
    f'Hyperparameter evolution finished {opt.evolve} generations\n'
    f"Results saved to {colorstr('bold', save_dir)}\n"
    f'Usage example: $ python train.py --hyp {evolve_yaml}'
)
```

## 5.5 Automatic mixed precision (AMP) training

### 5.5.1 å®šä¹‰

è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAutomatic Mixed Precision, AMPï¼‰è®­ç»ƒæ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ è®­ç»ƒæŠ€æœ¯ï¼Œå®ƒå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€åœ°é€‰æ‹©ä½¿ç”¨æµ®ç‚¹æ•°çš„ç²¾åº¦ã€‚

è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œæ ¹æ®è®¡ç®—çš„éœ€æ±‚å’Œæˆæœ¬ï¼Œè‡ªåŠ¨åœ°åœ¨å•ç²¾åº¦ï¼ˆFP32ï¼‰å’ŒåŠç²¾åº¦ï¼ˆFP16ï¼‰ä¹‹é—´åˆ‡æ¢ã€‚å…·ä½“æ¥è¯´ï¼ŒAMP è®­ç»ƒä¼šè¯†åˆ«é‚£äº›å¯¹ç²¾åº¦è¦æ±‚ä¸é«˜çš„è®¡ç®—ï¼ˆä¾‹å¦‚ï¼Œæƒé‡çŸ©é˜µçš„ä¹˜æ³•ï¼‰ï¼Œå¹¶å°†è¿™äº›è®¡ç®—è½¬æ¢ä¸ºåŠç²¾åº¦ï¼ˆFP16ï¼‰è®¡ç®—ï¼Œä»¥å‡å°‘æ¢¯åº¦è®¡ç®—ä¸­çš„æ•°å€¼è¯¯å·®ã€‚è€Œå¯¹äºé‚£äº›å¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„è®¡ç®—ï¼ˆä¾‹å¦‚ï¼Œæ¿€æ´»å‡½æ•°çš„è®¡ç®—ï¼‰ï¼ŒAMP è®­ç»ƒä»ç„¶ä½¿ç”¨å•ç²¾åº¦ï¼ˆFP32ï¼‰è®¡ç®—ï¼Œä»¥ä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§å’Œå“åº”æ€§ã€‚

> - float32: å•ç²¾åº¦æµ®ç‚¹æ•°
> - float16: åŠç²¾åº¦æµ®ç‚¹æ•°
> - float64: åŒç²¾åº¦æµ®ç‚¹æ•°

### 5.5.2 AMP è®­ç»ƒçš„ä¼˜ç‚¹

1. **æé«˜è®­ç»ƒé€Ÿåº¦**ï¼šä½¿ç”¨åŒç²¾åº¦è¿›è¡ŒæŸäº›è®¡ç®—å¯ä»¥å‡å°‘æµ®ç‚¹è¿ç®—çš„æ¬¡æ•°ï¼Œä»è€Œæé«˜è®­ç»ƒé€Ÿåº¦ã€‚
2. **å‡å°‘å†…å­˜ä½¿ç”¨**ï¼šåŒç²¾åº¦é€šå¸¸éœ€è¦æ¯”å•ç²¾åº¦æ›´å¤šçš„å†…å­˜ï¼Œä½†åªåœ¨å¿…è¦æ—¶ä½¿ç”¨åŒç²¾åº¦ï¼Œå¯ä»¥å‡å°‘æ€»ä½“å†…å­˜ä½¿ç”¨ã€‚
3. **æé«˜æ•°å€¼ç¨³å®šæ€§**ï¼šåœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œä½¿ç”¨åŒç²¾åº¦å¯ä»¥å‡å°‘æ¢¯åº¦æ›´æ–°çš„æ•°å€¼è¯¯å·®ï¼Œæé«˜æ¨¡å‹çš„è®­ç»ƒç¨³å®šæ€§ã€‚

### 5.5.3 `torch.FloatTensor` å’Œ `torch.HalfTensor`

åœ¨ PyTorch ä¸­ï¼Œ`torch.FloatTensor` å’Œ `torch.HalfTensor` æ˜¯ä¸¤ç§ä¸åŒç²¾åº¦çš„æµ®ç‚¹å¼ é‡ç±»å‹ï¼Œå®ƒä»¬åˆ†åˆ«å¯¹åº”äºå•ç²¾åº¦ï¼ˆFP32ï¼‰å’ŒåŠç²¾åº¦ï¼ˆFP16ï¼‰æµ®ç‚¹æ•°ã€‚

- **torch.FloatTensor**ï¼šè¿™æ˜¯ PyTorch ä¸­çš„å•ç²¾åº¦æµ®ç‚¹å¼ é‡ã€‚å®ƒä½¿ç”¨ 32 ä½ï¼ˆ4 å­—èŠ‚ï¼‰æ¥å­˜å‚¨æ¯ä¸ªæµ®ç‚¹æ•°ï¼Œæä¾›äº†è¾ƒé«˜çš„æ•°å€¼ç²¾åº¦å’Œè¾ƒå¤§çš„æ•°å€¼èŒƒå›´ã€‚è¿™æ˜¯å¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­é»˜è®¤ä½¿ç”¨çš„æµ®ç‚¹ç±»å‹ã€‚
- **torch.HalfTensor**ï¼šè¿™æ˜¯ PyTorch ä¸­çš„åŠç²¾åº¦æµ®ç‚¹å¼ é‡ã€‚å®ƒä½¿ç”¨ 16 ä½ï¼ˆ2 å­—èŠ‚ï¼‰æ¥å­˜å‚¨æ¯ä¸ªæµ®ç‚¹æ•°ï¼Œæ•°å€¼èŒƒå›´å’Œç²¾åº¦éƒ½æ¯”å•ç²¾åº¦æµ®ç‚¹æ•°ä½ã€‚ç„¶è€Œï¼Œç”±äºåŠç²¾åº¦æµ®ç‚¹æ•°å ç”¨çš„å†…å­˜è¾ƒå°‘ï¼Œå› æ­¤åœ¨æŸäº›æƒ…å†µä¸‹ï¼ˆå¦‚å†…å­˜å—é™çš„ç¯å¢ƒæˆ–éœ€è¦å¤§å¹…æé«˜è®¡ç®—é€Ÿåº¦æ—¶ï¼‰ä¼šä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ã€‚

### 5.5.4 ä½œè€…ç­”ç–‘

åœ¨ [Automatic mixed precision (AMP) training is now natively supported and a stable feature. #557](https://github.com/ultralytics/yolov5/issues/557) æœ‰æåˆ° AMPã€‚

<div align=center>
    <img src=./imgs_markdown/2024-02-07-15-05-30.png
    width=100%>
    <center></center>
</div>

ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼ŒğŸ’¡ YOLOv5 é»˜è®¤å¼€å¯ AMP è®­ç»ƒï¼Œå¹¶ä¸”ä¿å­˜çš„æ¨¡å‹ä¹Ÿæ˜¯ FP16 è€Œéä¼ ç»Ÿçš„ FP32ã€‚

### 5.5.5 å¦‚ä½•åœ¨ PyTorch ä¸­ä½¿ç”¨ AMPï¼Ÿ

> ğŸ’¡ æˆ‘ä¹‹å‰å†™è¿‡ç›¸å…³åšå®¢ï¼š[PyTorchæ··åˆç²¾åº¦åŸç†åŠå¦‚ä½•å¼€å¯è¯¥æ–¹æ³•](https://blog.csdn.net/weixin_44878336/article/details/125433023)

```python
from torch.cuda.amp import Scaler, autocast
```

> âš ï¸ æ³¨æ„ï¼š
> 1. Scaler å¹¶ä¸æ˜¯ AMPï¼Œautocast ä¹Ÿä¸æ˜¯ AMPï¼Œåªæœ‰ AMP + Scaler æ‰æ˜¯ AMP
>
> 2. AMP å¹¶ä¸ç‰¹æŒ‡åŠç²¾åº¦ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šä»»æ„ç²¾åº¦ï¼

#### 5.5.5.1 autocast

- ã€”å®˜æ–¹æ–‡æ¡£ã€•[torch.cuda.amp.autocast](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.autocast)

ä½¿ç”¨ `torch.cuda.amp` æ¨¡å—ä¸­çš„ `autocast` ç±»ã€‚å½“è¿›å…¥ `autocast` ä¸Šä¸‹æ–‡åï¼Œæ”¯æŒ AMP çš„ CUDA ç®—å­ä¼šæŠŠ Tensor çš„ `dtype` è½¬æ¢ä¸º FP16ï¼Œä»è€Œåœ¨ä¸æŸå¤±è®­ç»ƒç²¾åº¦çš„æƒ…å†µä¸‹åŠ å¿«è¿ç®—ã€‚åˆšè¿›å…¥ `autocast` çš„ä¸Šä¸‹æ–‡æ—¶ï¼ŒTensor å¯ä»¥æ˜¯ä»»ä½•ç±»å‹ï¼Œä¸éœ€è¦åœ¨ `model` æˆ– `input` ä¸Šæ‰‹å·¥è°ƒç”¨ `.half()`ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨åšï¼Œè¿™å°±æ˜¯ AMP ä¸­çš„ Automaticã€‚

å¦å¤–éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`autocast` ä¸Šä¸‹æ–‡åº”è¯¥åªåŒ…å«ç½‘ç»œçš„å‰å‘æ¨ç†è¿‡ç¨‹ï¼ˆåŒ…æ‹¬ loss çš„è®¡ç®—ï¼‰ï¼Œâš ï¸ ä¸è¦åŒ…å«åå‘ä¼ æ’­ï¼Œå› ä¸º BP çš„ç®—å­ä¼šä½¿ç”¨å’Œå‰å‘ç®—å­ç›¸åŒçš„ç±»å‹ã€‚

---

æˆ‘ä»¬çœ‹ä¸€ä¸‹æºç ï¼š

```python
class torch.autocast(device_type, 
                     dtype=None, 
                     enabled=True, 
                     cache_enabled=None)
```

**å‚æ•°**ï¼š

- `device_type`ï¼ˆstrï¼Œå¿…éœ€ï¼‰ - è¦ä½¿ç”¨çš„è®¾å¤‡ç±»å‹ã€‚å¯èƒ½çš„å€¼æœ‰ï¼š'cuda'ï¼Œ'cpu'ï¼Œ'xpu' å’Œ 'hpu'ã€‚ç±»å‹ä¸ `torch.device` çš„ `type` å±æ€§ç›¸åŒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `Tensor.device.type` è·å–å¼ é‡çš„è®¾å¤‡ç±»å‹ã€‚
- `enabled`ï¼ˆboolï¼Œå¯é€‰ï¼‰ - åŒºåŸŸå†…æ˜¯å¦åº”å¯ç”¨ autocastã€‚é»˜è®¤å€¼ï¼šTrue
- `dtype`ï¼ˆtorch_dtypeï¼Œå¯é€‰ï¼‰ - æ˜¯å¦ä½¿ç”¨ `torch.float16` æˆ– `torch.bfloat16`ã€‚
- `cache_enabled`ï¼ˆboolï¼Œå¯é€‰ï¼‰ - æ˜¯å¦åº”å¯ç”¨ autocast å†…éƒ¨çš„æƒé‡ç¼“å­˜ã€‚é»˜è®¤å€¼ï¼šTrue

> âš ï¸ autocast åªæ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä¼šæŠŠåœ¨å®ƒèŒƒå›´å†…çš„ Tensor çš„æ•°æ®èŒƒå›´éƒ½ç»Ÿä¸€ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¿®æ”¹ `dtype` å‚æ•°æ¥å®ç°ä¸åŒç²¾åº¦çš„è®¡ç®—ï¼Œæ¯”å¦‚ `dtype=torch.float32, int8, ...`


`autocast` çš„å®ä¾‹å¯ç”¨ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨æˆ–è£…é¥°å™¨ï¼Œå…è®¸è„šæœ¬çš„æŸäº›åŒºåŸŸä»¥æ··åˆç²¾åº¦è¿è¡Œã€‚

åœ¨è¿™äº›åŒºåŸŸä¸­ï¼Œæ“ä½œä»¥ `autocast` é€‰æ‹©çš„ä¸æ“ä½œç‰¹å®šçš„ `dtype` è¿è¡Œï¼Œä»¥æé«˜æ€§èƒ½åŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚

åœ¨è¿›å…¥å¯ç”¨ `autocast` çš„åŒºåŸŸæ—¶ï¼Œå¼ é‡å¯ä»¥æ˜¯ä»»ä½•ç±»å‹ã€‚åœ¨ä½¿ç”¨ autocasting æ—¶ï¼Œä¸åº”åœ¨æ¨¡å‹æˆ–è¾“å…¥ä¸Šè°ƒç”¨ `half()` æˆ– `bfloat16()`ã€‚

`autocast` åº”è¯¥ä»…åŒ…è£…ç½‘ç»œçš„å‰å‘æ¨ç†ï¼ŒåŒ…æ‹¬æŸå¤±è®¡ç®—ã€‚âš ï¸ ä¸å»ºè®®åœ¨ autocast ä¸‹æ‰§è¡Œåå‘ä¼ é€’ã€‚åå‘æ“ä½œåœ¨ä¸ autocast ç”¨äºç›¸åº”å‰å‘æ¨ç†çš„ç›¸åŒç±»å‹ä¸­è¿è¡Œã€‚

---

**CUDA è®¾å¤‡çš„ç¤ºä¾‹**ï¼š

```python
# Creates model and optimizer in default precision
model = Net().cuda()
optimizer = optim.SGD(model.parameters(), ...)

for input, target in data:
    optimizer.zero_grad()

    # Enables autocasting for the forward pass (model + loss)
    # å¯ç”¨å‰å‘æ¨ç†ï¼ˆæ¨¡å‹ + æŸå¤±ï¼‰çš„ autocastã€‚
    with torch.autocast(device_type="cuda"):
        output = model(input)
        loss = loss_fn(output, target)

    # Exits the context manager before backward()
    # åœ¨è°ƒç”¨backward()ä¹‹å‰é€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
    loss.backward()
    optimizer.step()
```

`autocast` ä¹Ÿå¯ä»¥ä½œä¸ºè£…é¥°å™¨ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥åº”ç”¨åœ¨æ¨¡å‹çš„ `forward` æ–¹æ³•ä¸Šï¼š

```python
class AutocastModel(nn.Module):
    ...
    @torch.autocast(device_type="cuda")
    def forward(self, input):
        ...
```

åœ¨å¯ç”¨äº† `autocast` çš„åŒºåŸŸä¸­äº§ç”Ÿçš„æµ®ç‚¹å¼ é‡å¯èƒ½æ˜¯ `float16`ï¼ˆé»˜è®¤å°±æ˜¯ FP16ï¼‰ã€‚åœ¨è¿”å›åˆ°ç¦ç”¨ `autocast` çš„åŒºåŸŸåï¼Œå°†å…¶ä¸ä¸åŒ `dtype` çš„æµ®ç‚¹å¼ é‡ä¸€èµ·ä½¿ç”¨å¯èƒ½å¯¼è‡´ç±»å‹ä¸åŒ¹é…é”™è¯¯ã€‚å¦‚æœå‡ºç°æ­¤æƒ…å†µï¼Œè¯·å°†åœ¨ `autocast` åŒºåŸŸä¸­ç”Ÿæˆçš„å¼ é‡è½¬å›ä¸º `float32`ï¼ˆæˆ–å…¶ä»–æ‰€éœ€çš„ `dtype`ï¼‰ã€‚å¦‚æœ `autocast` åŒºåŸŸçš„å¼ é‡å·²ç»æ˜¯ `float32`ï¼Œåˆ™è½¬æ¢æ˜¯ä¸€ä¸ªæ— æ“ä½œï¼Œå¹¶ä¸”ä¸ä¼šäº§ç”Ÿé¢å¤–å¼€é”€ã€‚

---

**CUDA ç¤ºä¾‹**ï¼š

```python
# Creates some tensors in default dtype (here assumed to be float32)
a_float32 = torch.rand((8, 8), device="cuda")
b_float32 = torch.rand((8, 8), device="cuda")
c_float32 = torch.rand((8, 8), device="cuda")
d_float32 = torch.rand((8, 8), device="cuda")

with torch.autocast(device_type="cuda"):
    # torch.mm is on autocast's list of ops that should run in float16.
    # torch.mm åœ¨ autocast çš„æ“ä½œåˆ—è¡¨ä¸­ï¼Œåº”è¯¥åœ¨ float16 ä¸­è¿è¡Œ
    # Inputs are float32, but the op runs in float16 and produces float16 output.
    # è¾“å…¥æ˜¯ float32ï¼Œä½†æ“ä½œåœ¨ float16 ä¸­è¿è¡Œï¼Œå¹¶ç”Ÿæˆ float16 çš„è¾“å‡º
    # No manual casts are required.
    # æ— éœ€æ‰‹åŠ¨è¿›è¡Œç±»å‹è½¬æ¢ã€‚
    e_float16 = torch.mm(a_float32, b_float32)

    # Also handles mixed input types
    # è¿˜å¤„ç†æ··åˆè¾“å…¥ç±»å‹
    f_float16 = torch.mm(d_float32, e_float16)

# After exiting autocast, calls f_float16.float() to use with d_float32
# åœ¨é€€å‡º autocast åï¼Œè°ƒç”¨ f_float16.float() ä»¥ä¸ d_float32 ä¸€èµ·ä½¿ç”¨
g_float32 = torch.mm(d_float32, f_float16.float())  # é€šè¿‡ .float() å°† FP16 è½¬æ¢ä¸ºäº† FP32
```

---

**CPU è®­ç»ƒç¤ºä¾‹**ï¼š

```python
# Creates model and optimizer in default precision
model = Net()
optimizer = optim.SGD(model.parameters(), ...)

for epoch in epochs:
    for input, target in data:
        optimizer.zero_grad()

        # Runs the forward pass with autocasting.
        with torch.autocast(device_type="cpu", dtype=torch.bfloat16):
            output = model(input)
            loss = loss_fn(output, target)

        loss.backward()
        optimizer.step()
```

#### 5.5.5.2 GradScaler

- ã€”å®˜æ–¹æ–‡æ¡£ã€•[torch.cuda.amp.GradScaler](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler)

ä½¿ç”¨ `torch.cuda.amp.GradScaler`ï¼Œéœ€è¦åœ¨è®­ç»ƒæœ€å¼€å§‹ä¹‹å‰å®ä¾‹åŒ–ä¸€ä¸ª `GradScaler` å¯¹è±¡ã€‚é€šè¿‡æ”¾å¤§ Loss çš„å€¼ï¼Œä»è€Œé˜²æ­¢æ¢¯åº¦çš„ underflowï¼ˆâš ï¸ è¿™åªæ˜¯ BP çš„æ—¶å€™ä¼ é€’æ¢¯åº¦ä¿¡æ¯ä½¿ç”¨ï¼ŒçœŸæ­£æ›´æ–°æƒé‡çš„æ—¶å€™è¿˜æ˜¯è¦æŠŠæ”¾å¤§çš„æ¢¯åº¦å† unscale å›å»ï¼‰

---

æˆ‘ä»¬çœ‹ä¸€ä¸‹å®ƒçš„æºç ï¼š

```python
class torch.cuda.amp.GradScaler(init_scale=65536.0, 
                                growth_factor=2.0, 
                                backoff_factor=0.5, 
                                growth_interval=2000, 
                                enabled=True)
```

**å‚æ•°**ï¼š

- `init_scale`ï¼ˆfloatï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º 2.0**16ï¼‰ - åˆå§‹ç¼©æ”¾å› å­ã€‚
- `growth_factor`ï¼ˆfloatï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º 2.0ï¼‰ - å¦‚æœåœ¨ `growth_interval` è¿ç»­çš„è¿­ä»£ä¸­æ²¡æœ‰å‡ºç° inf/NaN æ¢¯åº¦ï¼Œåˆ™åœ¨ `update()` æœŸé—´å°†ç¼©æ”¾ä¹˜ä»¥æ­¤å› å­ â€”â€” **ç›®çš„æ˜¯å°½æœ€å¤§å¯èƒ½å°†ç¼©æ”¾å› å­å˜å¤§**ã€‚
- `backoff_factor`ï¼ˆfloatï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º 0.5ï¼‰ - å¦‚æœåœ¨è¿­ä»£ä¸­å‡ºç° inf/NaN æ¢¯åº¦ï¼Œåˆ™åœ¨ `update()` æœŸé—´å°†ç¼©æ”¾ä¹˜ä»¥æ­¤å› å­ â€”â€” å‡å°ç¼©æ”¾å› å­é¿å…æ¨¡å‹æ— æ³•è®­ç»ƒã€‚
- `growth_interval`ï¼ˆintï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º 2000ï¼‰ - å¿…é¡»åœ¨æ²¡æœ‰ inf/NaN æ¢¯åº¦çš„è¿ç»­è¿­ä»£ä¸­å‘ç”Ÿçš„æ¬¡æ•°ï¼Œä»¥ä¾¿é€šè¿‡ `growth_factor` å°†ç¼©æ”¾ä¹˜ä»¥æ­¤å› å­ â€”â€” åœ¨ `growth_interval` æ¬¡è¿­ä»£ä¸­éƒ½æ²¡æœ‰å‡ºç° inf/NaN ç°è±¡ï¼Œå°±è¦æ”¾å¤§ç¼©æ”¾å› å­äº†ã€‚
- `enabled`ï¼ˆboolï¼Œå¯é€‰ï¼‰ - å¦‚æœä¸º Falseï¼Œåˆ™ç¦ç”¨æ¢¯åº¦ç¼©æ”¾ã€‚`step()` ç®€å•åœ°è°ƒç”¨åº•å±‚çš„ `optimizer.step()`ï¼Œè€Œå…¶ä»–æ–¹æ³•åˆ™æˆä¸ºæ— æ“ä½œã€‚é»˜è®¤å€¼ï¼šTrue â€”â€” æé«˜å…¼å®¹æ€§ç”¨çš„

**æ–¹æ³•**ï¼š

- `scaler.scale(loss)` å°†ç»™å®šçš„æŸå¤±ä¹˜ä»¥ç¼©æ”¾å™¨å½“å‰çš„ç¼©æ”¾å› å­ã€‚
- `scaler.step(optimizer)` å®‰å…¨åœ°å–æ¶ˆç¼©æ”¾æ¢¯åº¦å¹¶è°ƒç”¨ `optimizer.step()`ã€‚
- `scaler.update()` æ›´æ–°ç¼©æ”¾å™¨çš„ç¼©æ”¾å› å­ã€‚

âš ï¸ ç¼©æ”¾å› å­é€šå¸¸ä¼šå¯¼è‡´åœ¨å‰å‡ æ¬¡è¿­ä»£ä¸­æ¢¯åº¦ä¸­å‡ºç° infs/NaNsï¼Œå› ä¸ºå…¶å€¼è¿›è¡Œæ ¡å‡†ã€‚å¯¹äºè¿™äº›è¿­ä»£ï¼Œ`scaler.step` å°†è·³è¿‡åº•å±‚çš„ `optimizer.step()`ã€‚ä¹‹åï¼Œè·³è¿‡æ­¥éª¤åº”è¯¥å¾ˆå°‘å‘ç”Ÿï¼ˆæ¯å‡ ç™¾æˆ–å‡ åƒæ¬¡è¿­ä»£ä¸€æ¬¡ï¼‰ã€‚

#### 5.5.5.3 ç¤ºä¾‹

##### 1. å…¸å‹çš„æ··åˆç²¾åº¦è®­ç»ƒ

```python
# Creates model and optimizer in default precision
model = Net().cuda()
optimizer = optim.SGD(model.parameters(), ...)

# åœ¨è®­ç»ƒå¼€å§‹æ—¶åˆ›å»ºä¸€ä¸ª GradScaler å®ä¾‹
scaler = GradScaler()

for epoch in epochs:
    for input, target in data:
        optimizer.zero_grad()  # æ¸…ç©ºå†å²æ¢¯åº¦

        # ä½¿ç”¨ autocast è¿è¡Œå‰å‘æ¨ç†
        with autocast(device_type='cuda', dtype=torch.float16):
            output = model(input)
            loss = loss_fn(output, target)

        # ç¼©æ”¾æŸå¤±ã€‚å¯¹ç¼©æ”¾åçš„æŸå¤±è°ƒç”¨ backward() ä»¥åˆ›å»ºç¼©æ”¾åçš„æ¢¯åº¦ã€‚
        # âš ï¸ åœ¨ autocast ä¸‹æ‰§è¡Œåå‘ä¼ é€’æ˜¯ä¸æ¨èçš„
        # åœ¨ autocast é€‰æ‹©çš„ç›¸åº”å‰å‘æ¨ç†çš„ dtype ä¸­è¿è¡Œåå‘æ“ä½œ
        scaler.scale(loss).backward()

        # scaler.step() é¦–å…ˆå–æ¶ˆä¼˜åŒ–å™¨çš„åˆ†é…å‚æ•°çš„æ¢¯åº¦çš„ç¼©æ”¾ï¼ˆä»F32å˜ä¸ºF16ï¼‰
        # å¦‚æœè¿™äº›æ¢¯åº¦ä¸åŒ…å«æ— ç©·å¤§æˆ– NaNï¼Œç„¶åè°ƒç”¨ optimizer.step()
        # å¦åˆ™ï¼Œè·³è¿‡ optimizer.step()
        scaler.step(optimizer)

        # æ›´æ–°ä¸‹ä¸€æ¬¡è¿­ä»£çš„ç¼©æ”¾å› å­
        scaler.update()
```

##### 2. æ¢¯åº¦ç´¯ç§¯

æ¢¯åº¦ç´¯ç§¯ä¼šå°†ä¸€ä¸ªæœ‰æ•ˆ Batch å¤§å°ï¼ˆ`batch_per_iter * iters_to_accumulate` * `num_procs`ï¼‰å†…çš„æ¢¯åº¦ç›¸åŠ ã€‚ç¼©æ”¾åº”è¯¥æ ¹æ®æœ‰æ•ˆ Batch è¿›è¡Œæ ¡å‡†ï¼Œè¿™æ„å‘³ç€åœ¨æœ‰æ•ˆ Batch ç²’åº¦ä¸Šè¿›è¡Œ inf/NaN æ£€æŸ¥ã€å¦‚æœå‘ç° inf/NaN æ¢¯åº¦åˆ™è·³è¿‡æ­¥éª¤ï¼Œä»¥åŠåœ¨æœ‰æ•ˆ Batch ä¸Šæ›´æ–°ç¼©æ”¾å› å­ã€‚è€Œåœ¨ç»™å®šæœ‰æ•ˆ Batch ç´¯ç§¯æ¢¯åº¦æœŸé—´ï¼Œæ¢¯åº¦åº”è¯¥ä¿æŒç¼©æ”¾ï¼Œç¼©æ”¾å› å­åº”è¯¥ä¿æŒä¸å˜ã€‚å¦‚æœåœ¨ç´¯ç§¯å®Œæˆä¹‹å‰æ¢¯åº¦è¢«å–æ¶ˆç¼©æ”¾ï¼ˆæˆ–ç¼©æ”¾å› å­å‘ç”Ÿå˜åŒ–ï¼‰ï¼Œé‚£ä¹ˆä¸‹ä¸€æ¬¡åå‘ä¼ é€’å°†ä¼šå°†ç¼©æ”¾æ¢¯åº¦æ·»åŠ åˆ°æœªç¼©æ”¾æ¢¯åº¦ä¸­ï¼ˆæˆ–ç”¨ä¸åŒå› å­ç¼©æ”¾çš„æ¢¯åº¦ï¼‰ï¼Œä¹‹åå°±æ— æ³•æ¢å¤ç´¯ç§¯çš„æœªç¼©æ”¾æ¢¯åº¦ï¼Œæ­¥éª¤å¿…é¡»åº”ç”¨ã€‚

å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å–æ¶ˆç¼©æ”¾æ¢¯åº¦ï¼ˆä¾‹å¦‚ï¼Œå…è®¸å‰ªåˆ‡æœªç¼©æ”¾æ¢¯åº¦ï¼‰ï¼Œè¯·åœ¨æ‰§è¡Œæ­¥éª¤ä¹‹å‰ï¼Œåœ¨å³å°†åˆ°æ¥çš„æ­¥éª¤çš„æ‰€æœ‰ï¼ˆç¼©æ”¾çš„ï¼‰æ¢¯åº¦è¢«ç´¯ç§¯åè°ƒç”¨ `unscale_`ã€‚å¹¶ä¸”**åªæœ‰åœ¨ä¸ºä¸€ä¸ªå®Œæ•´çš„æœ‰æ•ˆ Batch è°ƒç”¨äº†æ­¥éª¤çš„è¿­ä»£ç»“æŸæ—¶**æ‰è°ƒç”¨ `update`ï¼š

```python
scaler = GradScaler()

for epoch in epochs:
    for i, (input, target) in enumerate(data):
        with autocast(device_type='cuda', dtype=torch.float16):
            output = model(input)
            loss = loss_fn(output, target)
            loss = loss / iters_to_accumulate

        # ç´¯ç§¯ç¼©æ”¾çš„æ¢¯åº¦
        scaler.scale(loss).backward()

        if (i + 1) % iters_to_accumulate == 0:
            # åœ¨è¿™é‡Œå¯ä»¥ä½¿ç”¨ unscale_ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œä¾‹å¦‚ï¼Œå…è®¸å‰ªåˆ‡æœªç¼©æ”¾çš„æ¢¯åº¦
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶éœ€è¦æ”¾åœ¨æœ€åäº†ï¼Œä¸ç„¶æ¢¯åº¦æ²¡æ³•ç´¯ç§¯çš„
```

##### 3. å¤„ç†å¤šä¸ªæ¨¡å‹ã€æŸå¤±å’Œä¼˜åŒ–å™¨

å¦‚æœæˆ‘ä»¬çš„ç½‘ç»œæœ‰å¤šä¸ªæŸå¤±ï¼Œæˆ‘ä»¬å¿…é¡»å¯¹æ¯ä¸ªæŸå¤±åˆ†åˆ«è°ƒç”¨ `scaler.scale`ã€‚å¦‚æœæˆ‘ä»¬çš„ç½‘ç»œæœ‰å¤šä¸ªä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†åˆ«å¯¹æ¯ä¸ªä¼˜åŒ–å™¨è°ƒç”¨ `scaler.unscale_`ï¼Œå¹¶ä¸”å¿…é¡»å¯¹æ¯ä¸ªä¼˜åŒ–å™¨åˆ†åˆ«è°ƒç”¨ `scaler.step`ã€‚

ç„¶è€Œï¼Œâš ï¸ `scaler.update` åªåº”åœ¨æ­¤è¿­ä»£ä¸­ä½¿ç”¨çš„æ‰€æœ‰ä¼˜åŒ–å™¨éƒ½å·²æ‰§è¡Œæ­¥éª¤ä¹‹åè°ƒç”¨ä¸€æ¬¡ï¼š

```python
scaler = torch.cuda.amp.GradScaler()

for epoch in epochs:
    for input, target in data:
        optimizer0.zero_grad()
        optimizer1.zero_grad()
        with autocast(device_type='cuda', dtype=torch.float16):
            output0 = model0(input)  # ç¬¬ä¸€ä¸ªæ¨¡å‹
            output1 = model1(input)  # ç¬¬äºŒä¸ªæ¨¡å‹
            loss0 = loss_fn(2 * output0 + 3 * output1, target)  # æ··åˆæŸå¤±1
            loss1 = loss_fn(3 * output0 - 5 * output1, target)  # æ··åˆæŸå¤±2

        # è¿™é‡Œçš„ retain_graph ä¸ amp æ— å…³ï¼Œå®ƒå­˜åœ¨æ˜¯å› ä¸ºåœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œ
        # ä¸¤ä¸ª backward() è°ƒç”¨å…±äº«äº†ä¸€äº›å›¾çš„éƒ¨åˆ†
        scaler.scale(loss0).backward(retain_graph=True)
        scaler.scale(loss1).backward()

        # æˆ‘ä»¬å¯ä»¥é€‰æ‹©å“ªäº›ä¼˜åŒ–å™¨æ¥æ”¶æ˜¾å¼å–æ¶ˆç¼©æ”¾ï¼Œ
        # ä»¥ä¾¿æ£€æŸ¥æˆ–ä¿®æ”¹å®ƒä»¬æ‹¥æœ‰çš„å‚æ•°çš„æ¢¯åº¦ã€‚
        scaler.unscale_(optimizer0)

        scaler.step(optimizer0)
        scaler.step(optimizer1)

        scaler.update()
```

> âš ï¸ æ¯ä¸ªä¼˜åŒ–å™¨éƒ½ä¼šæ£€æŸ¥å…¶æ¢¯åº¦ä¸­æ˜¯å¦åŒ…å« inf/NaNï¼Œå¹¶ç‹¬ç«‹å†³å®šæ˜¯å¦è·³è¿‡è¯¥æ­¥éª¤ã€‚è¿™å¯èƒ½å¯¼è‡´ä¸€ä¸ªä¼˜åŒ–å™¨è·³è¿‡è¯¥æ­¥éª¤ï¼Œè€Œå¦ä¸€ä¸ªä¸è·³è¿‡ã€‚ç”±äºæ­¥éª¤è·³è¿‡å¾ˆå°‘å‘ç”Ÿï¼ˆæ¯å‡ ç™¾æ¬¡è¿­ä»£ä¸€æ¬¡ï¼‰ï¼Œè¿™ä¸åº”å½±å“æ”¶æ•›æ€§ã€‚

##### 4. DataParallel (DP) in a single process

å³ä½¿ `torch.nn.DataParallel` ç”Ÿæˆçº¿ç¨‹æ¥åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šè¿è¡Œå‰å‘æ¨ç†ï¼Œautocast çŠ¶æ€ä¹Ÿä¼šåœ¨æ¯ä¸ªçº¿ç¨‹ä¸­ä¼ æ’­ï¼Œä»¥ä¸‹æ“ä½œå°†èƒ½å¤Ÿæ­£å¸¸å·¥ä½œï¼š

```python
model = MyModel()
dp_model = nn.DataParallel(model)

# åœ¨ä¸»çº¿ç¨‹ä¸­è®¾ç½® autocast
with autocast(device_type='cuda', dtype=torch.float16):
    # dp_model å†…éƒ¨çš„çº¿ç¨‹å°†ä½¿ç”¨ autocastã€‚
    output = dp_model(input)
    # loss_fn ä¹Ÿä½¿ç”¨ autocast
    loss = loss_fn(output)
```

##### 5. DistributedDataParallel (DDP), å•å¡å•çº¿ç¨‹

`torch.nn.parallel.DistributedDataParallel` çš„æ–‡æ¡£å»ºè®®æ¯ä¸ªè¿›ç¨‹ä½¿ç”¨ä¸€ä¸ª GPU ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`DistributedDataParallel` ä¸ä¼šåœ¨å†…éƒ¨ç”Ÿæˆçº¿ç¨‹ï¼Œå› æ­¤å¯¹ autocast å’Œ GradScaler çš„ä½¿ç”¨ä¸å—å½±å“ã€‚

##### 6. DistributedDataParallel (DDP), å¤šå¡å¤šçº¿ç¨‹

åœ¨è¿™é‡Œï¼Œ`torch.nn.parallel.DistributedDataParallel` å¯èƒ½ä¼šç”Ÿæˆä¸€ä¸ªè¾…åŠ©çº¿ç¨‹æ¥åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šè¿è¡Œå‰å‘æ¨ç†ï¼Œç±»ä¼¼äº `torch.nn.DataParallel`ã€‚

è§£å†³æ–¹æ³•æ˜¯ç›¸åŒçš„ï¼šåœ¨æ¨¡å‹çš„å‰å‘æ–¹æ³•ä¸­åº”ç”¨ autocastï¼Œä»¥ç¡®ä¿å®ƒåœ¨è¾…åŠ©çº¿ç¨‹ä¸­å¯ç”¨ã€‚

## 5.6 æ–­ç‚¹ç»­è®­

æ–­ç‚¹ç»­è®­ï¼ˆResume Trainingï¼‰æ˜¯æœºå™¨å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªåŠŸèƒ½ï¼Œå®ƒå…è®¸æ¨¡å‹è®­ç»ƒåœ¨ä¹‹å‰åœæ­¢çš„åœ°æ–¹ç»§ç»­è¿›è¡Œã€‚è¿™å¯¹äºå¤„ç†å¤§å‹æ•°æ®é›†æˆ–éœ€è¦é•¿æ—¶é—´è®­ç»ƒçš„æ¨¡å‹å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šç”±äºå„ç§åŸå› ï¼ˆå¦‚ç¡¬ä»¶æ•…éšœã€ç”µåŠ›ä¸­æ–­ç­‰ï¼‰å¯¼è‡´è®­ç»ƒè¿‡ç¨‹æ„å¤–åœæ­¢ã€‚

åœ¨ YOLOv5 ä¸­å®ç°æ–­ç‚¹ç»­è®­é€šå¸¸æ¶‰åŠä»¥ä¸‹æ­¥éª¤ï¼š

1. **ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šå®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè¿™äº›æ£€æŸ¥ç‚¹åŒ…å«äº†æ¨¡å‹å‚æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€ä»¥åŠå½“å‰çš„è®­ç»ƒè½®æ¬¡ç­‰ä¿¡æ¯ã€‚
2. **ä¸­æ–­è®­ç»ƒ**ï¼šå¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°äº†ä¸­æ–­ï¼Œç³»ç»Ÿä¼šåœæ­¢æ›´æ–°è¿™äº›æ£€æŸ¥ç‚¹ã€‚
3. **æ¢å¤è®­ç»ƒ**ï¼šè¦æ¢å¤è®­ç»ƒï¼Œç”¨æˆ·éœ€è¦æŒ‡å®šä¸Šæ¬¡ä¿å­˜çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ã€‚YOLOv5 è®­ç»ƒè„šæœ¬é€šå¸¸ä¼šæœ‰ä¸€ä¸ª `--resume` å‚æ•°ï¼Œé€šè¿‡è®¾ç½®è¿™ä¸ªå‚æ•°ï¼Œå¯ä»¥ä»æœ€è¿‘çš„æ£€æŸ¥ç‚¹å¼€å§‹ç»§ç»­è®­ç»ƒã€‚
4. **è®¾ç½®**ï¼šåœ¨æ¢å¤è®­ç»ƒä¹‹å‰ï¼Œç¡®ä¿è®­ç»ƒçš„è®¾ç½®ï¼ˆå¦‚å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€æ•°æ®é›†ç­‰ï¼‰ä¸ä¹‹å‰è®­ç»ƒçš„è®¾ç½®ä¿æŒä¸€è‡´ï¼Œä»¥ç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„è¿ç»­æ€§å’Œç¨³å®šæ€§ã€‚
5. **ç»§ç»­è®­ç»ƒ**ï¼šå¯åŠ¨è®­ç»ƒè„šæœ¬ï¼Œç¨‹åºä¼šåŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå¹¶ä»åœæ­¢çš„åœ°æ–¹å¼€å§‹ç»§ç»­è®­ç»ƒæ¨¡å‹ã€‚

æ–­ç‚¹ç»­è®­ä¸ä»…èƒ½å¤Ÿå¸®åŠ©èŠ‚çœæ—¶é—´ï¼Œé¿å…ä»å¤´å¼€å§‹è®­ç»ƒï¼Œè¿˜èƒ½å¤Ÿç¡®ä¿æ¨¡å‹è®­ç»ƒçš„è¿è´¯æ€§å’Œæœ€ç»ˆæ•ˆæœã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„åŠŸèƒ½ï¼Œå¯ä»¥æé«˜æ¨¡å‹è®­ç»ƒçš„æ•ˆç‡ã€‚

æˆ‘ä»¬çœ‹ä¸€ä¸‹ `--resume` åœ¨æºç ä¸­çš„ä½¿ç”¨ï¼š

```python
parser.add_argument("--resume", nargs="?", const=True, default=False, help="resume most recent training")

...

def main(opt, callbacks=Callbacks()):
    # Checks
    if RANK in {-1, 0}:  # åˆ¤æ–­æ˜¯å¦åœ¨ä¸»çº¿ç¨‹ä¸­
        print_args(vars(opt))  # æ‰“å°æ‰€æœ‰å‚æ•°
        check_git_status()  # æ£€æŸ¥gitçš„çŠ¶æ€
        check_requirements(ROOT / "requirements.txt")  # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ»¡è¶³ï¼ˆå¦‚æœä¸æ»¡è¶³åˆ™è‡ªåŠ¨å®‰è£…ï¼‰

    # Resume (from specified or most recent last.pt) | æ–­ç‚¹ç»­è®­
    if opt.resume and not check_comet_resume(opt) and not opt.evolve:
        # å…ˆåˆ¤æ–­ opt.resume æ˜¯ä¸æ˜¯ä¸€ä¸ªstrï¼Œå¦‚æœæ˜¯ï¼Œè¯´æ˜æˆ‘ä»¬æŒ‡å®šäº†å…·ä½“çš„last.pt
        last = Path(check_file(opt.resume) if isinstance(opt.resume, str) else get_latest_run())

        # è¯»å–æƒé‡æ–‡ä»¶çš„ä¸Šçº§ä¸Šçº§æ–‡ä»¶å¤¹ä¸‹çš„opt.yamlæ–‡ä»¶
        opt_yaml = last.parent.parent / "opt.yaml"  # train options yaml

        # å°†å¯åŠ¨è®­ç»ƒæ—¶çš„optä¿å­˜ä¸€ä¸‹
        opt_data = opt.data  # original dataset

        if opt_yaml.is_file():  # å¦‚æœæƒé‡æ–‡ä»¶çš„ä¸Šçº§ä¸Šçº§æ–‡ä»¶å¤¹ä¸‹çš„opt.yamlæ–‡ä»¶å­˜åœ¨
            with open(opt_yaml, errors="ignore") as f:
                d = yaml.safe_load(f)  # åŠ è½½æ‰€æœ‰çš„é…ç½®
        else:  # å¦‚æœä¸å­˜åœ¨åˆ™è¯»å–æƒé‡ä¸­çš„opt
            d = torch.load(last, map_location="cpu")["opt"]

        # å°†åŸæ¥çš„optä½¿ç”¨è¯»å–åˆ°çš„optè¿›è¡Œè¦†ç›–
        opt = argparse.Namespace(**d)  # replace
        
        # ä¿®æ”¹optä¸­çš„ä¸‰ä¸ªå‚æ•°
        opt.cfg, opt.weights, opt.resume = "", str(last), True  # reinstate
```

å› ä¸º `--resume` æ˜¯ `nargs="?"`ï¼Œæ‰€ä»¥å®ƒå¯ä»¥æœ‰ 0 ä¸ªå‚æ•°æˆ–è€… 1 ä¸ªå‚æ•°ï¼Œå³æˆ‘ä»¬å¯ä»¥ç»™å®ƒä¼ å‚ä¹Ÿå¯ä»¥ä¸ç»™å®ƒä¼ å‚ï¼Œé‚£ä¹ˆå®ƒæœ‰å¦‚ä¸‹ä¸¤ç§ç”¨æ³•ï¼š

```bash
# ç”¨æ³•1: ç›´æ¥ä½¿ç”¨ last.pt è¿›è¡Œæ–­ç‚¹ç»­è®­
python train.py --resume

# ç”¨æ³•2: ä½¿ç”¨æŒ‡å®šçš„æƒé‡è¿›è¡Œæ–­ç‚¹ç»­è®­
python train.py --resume runs/exp/weights/example_weights.pt
```

## 5.7 Multi-GPU Trainingï¼Œå¤š GPU è®­ç»ƒ

PyTorch ä¸ºæ•°æ®å¹¶è¡Œè®­ç»ƒæä¾›äº†å‡ ç§é€‰é¡¹ã€‚å¯¹äºä»ç®€å•åˆ°å¤æ‚ã€ä»åŸå‹åˆ°ç”Ÿäº§é€æ¸å¢é•¿çš„åº”ç”¨ç¨‹åºï¼Œå¸¸è§çš„å¼€å‘è·¯å¾„å°†æ˜¯ï¼š

1. ã€”**ä¸ä½¿ç”¨ DDP**ã€•å¦‚æœæ•°æ®å’Œæ¨¡å‹å¯ä»¥é€‚åº”ä¸€ä¸ª GPUï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦ä¸æ˜¯é—®é¢˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å•è®¾å¤‡è®­ç»ƒå°±è¡Œï¼Œä¸ç”¨ DDPã€‚
2. ã€”**å•æœºå¤šå¡ - ä¸æ¨è**ã€•ä½¿ç”¨å•æœºå¤š GPU çš„ DataParallelï¼Œä»¥æœ€å°çš„ä»£ç æ›´æ”¹åˆ©ç”¨å•å°æœºå™¨ä¸Šçš„å¤šä¸ª GPU æ¥åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚
3. ã€”**å•æœºå¤šå¡ - æ¨è**ã€•å¦‚æœæˆ‘ä»¬æƒ³è¿›ä¸€æ­¥åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œå¹¶æ„¿æ„ç¼–å†™æ›´å¤šä»£ç ï¼Œé‚£ä¹ˆå°±ä½¿ç”¨å•æœºå¤š GPU çš„ DDPã€‚
4. ã€”**å¤šæœºå¤šå¡**ã€•å¦‚æœåº”ç”¨ç¨‹åºéœ€è¦è·¨æœºå™¨æ‰©å±•ï¼Œè¯·ä½¿ç”¨å¤šæœºå™¨çš„ DistributedDataParallel å’Œå¯åŠ¨è„šæœ¬ã€‚
5. ã€”**è®­ç»ƒå¤§æ¨¡å‹**ã€•å½“æ•°æ®å’Œæ¨¡å‹æ— æ³•é€‚åº”ä¸€ä¸ª GPU æ—¶ï¼Œåœ¨å•æœºæˆ–å¤šæœºä¸Šä½¿ç”¨å¤š GPU çš„ FullyShardedDataParallel (FSDP) è¿›è¡Œè®­ç»ƒã€‚
6. ã€”**å¼¹æ€§è®­ç»ƒ**ã€•å¦‚æœé¢„æœŸä¼šå‡ºç°é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå†…å­˜ä¸è¶³ï¼‰æˆ–è€…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èµ„æºå¯ä»¥åŠ¨æ€åŠ å…¥å’Œç¦»å¼€ï¼Œè¯·ä½¿ç”¨ torch.distributed.elastic å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒã€‚

> ğŸ’¡ DP è®­ç»ƒä¹Ÿé€‚ç”¨äºè‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰

> ğŸ’¡ ä¹‹å‰å†™è¿‡ä¸€ç¯‡å…³äºå¤š GPU è®­ç»ƒçš„åšå®¢ï¼š[PyTorchä½¿ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒåŠå…¶åŸç†å’Œæ³¨æ„äº‹é¡¹](https://blog.csdn.net/weixin_44878336/article/details/125412625)

### 5.7.1 DP (Data Parallelï¼Œæ•°æ®å¹¶è¡Œ)

```python
class torch.nn.DataParallel(module, 
                            device_ids=None, 
                            output_device=None, 
                            dim=0)
```

å¯ä»¥çœ‹åˆ°ï¼ŒDP å¯ä»¥åœ¨ module çº§åˆ«å®ç°æ•°æ®å¹¶è¡Œã€‚å…·ä½“æ¥è¯´ï¼Œè¿™ä¸ªå®¹å™¨ï¼ˆDPï¼‰é€šè¿‡åœ¨ Batch ç»´åº¦ä¸Šåˆ†å—ï¼Œå°†è¾“å…¥åˆ†å‰²åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Šï¼Œä»è€Œå®ç°ç»™å®š module çš„å¹¶è¡Œåº”ç”¨ï¼ˆå…¶ä»–å¯¹è±¡å°†æ¯ä¸ªè®¾å¤‡å¤åˆ¶ä¸€æ¬¡ï¼‰ã€‚

- åœ¨å‰å‘ä¼ æ’­ä¸­ï¼Œ module åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå¤åˆ¶ï¼Œå¹¶ä¸”æ¯ä¸ªå‰¯æœ¬å¤„ç†è¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚
- åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªå‰¯æœ¬çš„æ¢¯åº¦è¢«æ±‡æ€»åˆ°åŸå§‹ module ä¸­ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼šBatch åº”è¯¥å¤§äºä½¿ç”¨çš„ GPU æ•°é‡ã€‚

> âš ï¸ åœ¨ PyTorch å®˜æ–¹æ–‡æ¡£ä¸­ä¹Ÿè¡¨æ˜ï¼šå»ºè®®ä½¿ç”¨ DistributedDataParallel è€Œä¸æ˜¯è¿™ä¸ªç±»ï¼ˆDPï¼‰æ¥è¿›è¡Œå¤š GPU è®­ç»ƒï¼Œ**å³ä½¿åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹**ã€‚

> DataParallel åŒ…ä½¿å•æœºå¤š GPU å¹¶è¡Œå˜å¾—éå¸¸å®¹æ˜“ï¼Œå‡ ä¹ä¸éœ€è¦ç¼–å†™ä»»ä½•ä»£ç ã€‚å®ƒåªéœ€è¦å¯¹åº”ç”¨ç¨‹åºä»£ç è¿›è¡Œä¸€æ¬¡è¡Œæ›´æ”¹ã€‚å°½ç®¡ DataParallel éå¸¸æ˜“äºä½¿ç”¨ï¼Œä½†é€šå¸¸å®ƒçš„æ€§èƒ½å¹¶ä¸æ˜¯æœ€å¥½çš„ï¼Œå› ä¸ºå®ƒåœ¨æ¯ä¸ªå‰å‘ä¼ æ’­ä¸­éƒ½å¤åˆ¶äº†æ¨¡å‹ï¼Œå¹¶ä¸”å®ƒçš„å•è¿›ç¨‹å¤šçº¿ç¨‹å¹¶è¡Œè‡ªç„¶ä¼šå—åˆ° GIL äº‰ç”¨çš„å›°æ‰°ã€‚ä¸ºäº†è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œè¯·è€ƒè™‘ä½¿ç”¨ DistributedDataParallelã€‚


### 5.7.2 DDPï¼ˆDistributed Data Parallelï¼Œåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼‰

#### 5.7.2.1 DDP ä»‹ç»

Distributed Data Parallel (DDP) æ˜¯ PyTorch ä¸­ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒçš„é«˜çº§åŸè¯­ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ª GPUã€‚DDP å¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨å¤§é‡æ•°æ®å’Œå¤æ‚æ¨¡å‹æ—¶ã€‚

DDP èƒŒåçš„ä¸»è¦æ€æƒ³æ˜¯å°†æ¨¡å‹å¤åˆ¶åˆ°æ¯ä¸ªèŠ‚ç‚¹ï¼Œå¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šç‹¬ç«‹åœ°å¤„ç†ä¸€éƒ¨åˆ†æ•°æ®ã€‚åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„æ¨¡å‹å‰¯æœ¬ä¼šè®¡ç®—æ¢¯åº¦ï¼Œç„¶åè¿™äº›æ¢¯åº¦ä¼šåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¹‹é—´è¿›è¡Œå¹³å‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒDDP å¯ä»¥ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„æ¨¡å‹å‚æ•°ä¿æŒåŒæ­¥ã€‚

DDP ç›¸å¯¹äºå…¶ä»–å¹¶è¡Œæ–¹æ³•ï¼ˆå¦‚ DataParallelï¼‰çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå…¶é«˜æ•ˆçš„é€šä¿¡æœºåˆ¶ã€‚DDP ä½¿ç”¨ Ring Allreduce ç®—æ³•æ¥å‡å°‘æ¢¯åº¦åŒæ­¥æ—¶çš„é€šä¿¡ç“¶é¢ˆï¼Œè¿™ä½¿å¾— DDP ç‰¹åˆ«é€‚åˆäºå¤§å‹æ¨¡å‹å’Œå¤§è§„æ¨¡è®­ç»ƒå·¥ä½œã€‚

#### 5.7.2.2 DDP çš„ç±»å®šä¹‰

```python
class torch.nn.parallel.DistributedDataParallel(
        module,  # è¦å¹¶è¡ŒåŒ–çš„æ¨¡å—
        device_ids=None,  # device_idså¿…é¡»ç”¨list
        output_device=None,
        dim=0, broadcast_buffers=True,
        process_group=None,
        bucket_cap_mb=25,
        find_unused_parameters=False,
        check_reduction=False,  # æ­¤å‚æ•°å·²å¼ƒç”¨
        gradient_as_bucket_view=False,
        static_graph=False,
        delay_all_reduce_named_params=None,
        param_to_hook_all_reduce=None,
        mixed_precision=None,
        device_mesh=Non
)
```

#### 5.7.2.3 ä½¿ç”¨ DDP çš„æ­¥éª¤

1. åˆå§‹åŒ–ä¸€ä¸ªè¿›ç¨‹ç»„ï¼Œè¯¥è¿›ç¨‹ç»„å®šä¹‰äº†å‚ä¸è®­ç»ƒçš„æ‰€æœ‰èŠ‚ç‚¹å’Œå®ƒä»¬ä¹‹é—´çš„é€šä¿¡æ–¹å¼ã€‚
2. å°†æ¨¡å‹å°è£…åœ¨ `DistributedDataParallel` ä¸­ï¼Œè¿™æ ·æ¨¡å‹å°±å¯ä»¥åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šå¹¶è¡Œè®­ç»ƒã€‚
3. ä½¿ç”¨åˆ†å¸ƒå¼ `Sampler` ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹åªå¤„ç†æ•´ä¸ªæ•°æ®é›†çš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œé¿å…æ•°æ®é‡å¤ã€‚
4. åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œè®­ç»ƒå¾ªç¯ï¼ŒDDP ä¼šè‡ªåŠ¨å¤„ç†æ¢¯åº¦åŒæ­¥å’Œæ¨¡å‹æ›´æ–°ã€‚

DDP è¿˜æä¾›äº†ä¸€äº›å…¶ä»–åŠŸèƒ½ï¼Œå¦‚è‡ªåŠ¨æ•…éšœæ¢å¤å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œè¿™äº›åŠŸèƒ½å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„å¤§è§„æ¨¡è®­ç»ƒä»»åŠ¡éå¸¸æœ‰ç”¨ã€‚

æ€»çš„æ¥è¯´ï¼ŒDDP æ˜¯ PyTorch ä¸­ç”¨äºå®ç°é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒçš„å¼ºå¤§å·¥å…·ï¼Œå®ƒé€šè¿‡åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šå¹¶è¡ŒåŒ–æ¨¡å‹å’Œæ•°æ®ï¼Œä½¿å¾—è®­ç»ƒå¤§å‹æ¨¡å‹å˜å¾—æ›´åŠ å¯è¡Œå’Œé«˜æ•ˆã€‚

#### 5.7.2.4 DDP çš„ä¼˜ç‚¹ï¼ˆç›¸æ¯”äº DPï¼‰

ä¸ DataParallel ç›¸æ¯”ï¼ŒDistributedDataParallel éœ€è¦å¤šä¸€ä¸ªæ­¥éª¤æ¥è®¾ç½®ï¼Œå³è°ƒç”¨ init_process_groupã€‚DDP ä½¿ç”¨<font color='red'>å¤šè¿›ç¨‹å¹¶è¡Œ</font>ï¼Œå› æ­¤åœ¨æ¨¡å‹å‰¯æœ¬ä¹‹é—´æ²¡æœ‰ GIL äº‰ç”¨ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨ DDP æ„å»ºæ—¶è¿›è¡Œå¹¿æ’­ï¼Œè€Œä¸æ˜¯åœ¨æ¯æ¬¡å‰å‘ä¼ æ’­æ—¶ï¼Œè¿™ä¹Ÿæœ‰åŠ©äºåŠ é€Ÿè®­ç»ƒã€‚DDP é…å¤‡äº†å¤šç§æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ã€‚

> ğŸ’¡ å¤šçº¿ç¨‹ä¼šæœ‰ GIL çš„é—®é¢˜ï¼Œè€Œå¤šè¿›ç¨‹æ²¡æœ‰è¿™ç§é—®é¢˜ã€‚

#### 5.7.2.5 é€šä¿¡åè®®ä»‹ç»

åœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œé€šä¿¡åè®®ä¸»è¦æŒ‡çš„æ˜¯åç«¯é€šä¿¡åº“ï¼Œå®ƒç”¨äºåœ¨ä¸åŒè¿›ç¨‹ä¹‹é—´ä¼ è¾“æ•°æ®å’Œæ¢¯åº¦ã€‚æˆªè‡³æˆ‘æ‰€çŸ¥çš„ä¿¡æ¯ï¼ŒDDP ä¸»è¦æ”¯æŒä»¥ä¸‹å‡ ç§é€šä¿¡åè®®ï¼š

1. **GLOO**
   - ã€”**ç‰¹ç‚¹**ã€•ï¼šGLOO æ˜¯ PyTorch å†…ç½®çš„é€šä¿¡åº“ï¼Œæ”¯æŒ CPU å’Œ GPU ä¹‹é—´çš„é€šä¿¡ã€‚å®ƒé€‚ç”¨äºå•ä¸ªèŠ‚ç‚¹ä¸Šçš„å¤š GPU è®­ç»ƒã€‚
   - ã€”**ä¼˜ç‚¹**ã€•ï¼šæ˜“äºä½¿ç”¨ï¼Œå®ç°ç®€å•ï¼Œé€‚åˆå¼€å‘å’Œæµ‹è¯•ã€‚
   - ã€”**ç¼ºç‚¹**ã€•ï¼šæ€§èƒ½ç›¸å¯¹è¾ƒä½ï¼Œ<font color='red'><b>ä¸é€‚åˆå¤§è§„æ¨¡çš„åˆ†å¸ƒå¼è®­ç»ƒ</b></font>ã€‚
2. **NCCL**
   - ã€”**ç‰¹ç‚¹**ã€•ï¼šNCCL æ˜¯ NVIDIA Collective Communications Library çš„ç¼©å†™ï¼Œä¸“é—¨ä¸º NVIDIA GPU è®¾è®¡çš„é€šä¿¡åº“ã€‚å®ƒæ”¯æŒ GPU ä¹‹é—´çš„é€šä¿¡ï¼Œå¹¶ä¸”æ€§èƒ½ä¼˜ç§€ã€‚
   - ã€”**ä¼˜ç‚¹**ã€•ï¼š<font color='red'><b>é€‚ç”¨äºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œç‰¹åˆ«æ˜¯åœ¨æ‹¥æœ‰å¤§é‡ GPU çš„åœºæ™¯ä¸­ï¼Œèƒ½å¤Ÿæä¾›é«˜æ•ˆçš„é€šä¿¡æ€§èƒ½</b></font>ã€‚
   - ã€”**ç¼ºç‚¹**ã€•ï¼šä»…æ”¯æŒ NVIDIA GPUï¼Œéœ€è¦åœ¨ NVIDIA ç¡¬ä»¶ä¸Šè¿è¡Œã€‚
3. **MPI**
   - ã€”**ç‰¹ç‚¹**ã€•ï¼šMPI æ˜¯ Message Passing Interface çš„ç¼©å†™ï¼Œæ˜¯ä¸€ä¸ªè·¨è¯­è¨€çš„é€šä¿¡åè®®ï¼Œå¹¿æ³›ç”¨äºé«˜æ€§èƒ½è®¡ç®—ã€‚å®ƒæ”¯æŒåœ¨å¤šèŠ‚ç‚¹ä¹‹é—´è¿›è¡Œé€šä¿¡ã€‚
   - ã€”**ä¼˜ç‚¹**ã€•ï¼šéå¸¸æˆç†Ÿï¼Œæ”¯æŒå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸­ã€‚
   - ã€”**ç¼ºç‚¹**ã€•ï¼šéœ€è¦å¤–éƒ¨ä¾èµ–ï¼Œé…ç½®å’Œä½¿ç”¨ç›¸å¯¹å¤æ‚ï¼Œå¯¹å¼€å‘è€…çš„è¦æ±‚è¾ƒé«˜ã€‚
4. **MPI_NCCL**
   - ã€”**ç‰¹ç‚¹**ã€•ï¼šç»“åˆäº† MPI å’Œ NCCL çš„ä¼˜ç‚¹ï¼Œå¯ä»¥åœ¨å¤šèŠ‚ç‚¹ä¹‹é—´è¿›è¡Œ GPU é€šä¿¡ã€‚
   - ã€”**ä¼˜ç‚¹**ã€•ï¼šç»“åˆäº† MPI çš„åˆ†å¸ƒå¼é€šä¿¡èƒ½åŠ›å’Œ NCCL åœ¨ GPU ä¹‹é—´çš„é€šä¿¡æ€§èƒ½ã€‚
   - ã€”**ç¼ºç‚¹**ã€•ï¼šå®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦åŒæ—¶é…ç½® MPI å’Œ NCCLã€‚
5. **TCP**
   - ã€”**ç‰¹ç‚¹**ã€•ï¼šTCP æ˜¯ä¼ è¾“æ§åˆ¶åè®®ï¼Œæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç½‘ç»œé€šä¿¡åè®®ã€‚åœ¨ DDP ä¸­ï¼Œå®ƒé€šå¸¸ç”¨äºåœ¨èŠ‚ç‚¹ä¹‹é—´ä¼ è¾“æ•°æ®ã€‚
   - ã€”**ä¼˜ç‚¹**ã€•ï¼šæ˜“äºå®ç°ï¼Œå…¼å®¹æ€§å¥½ï¼Œé€‚ç”¨äºå¤šç§ç½‘ç»œç¯å¢ƒã€‚
   - ã€”**ç¼ºç‚¹**ã€•ï¼šæ€§èƒ½ç›¸å¯¹è¾ƒä½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒä¸­å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

---

åœ¨é€‰æ‹©é€šä¿¡åè®®æ—¶ï¼Œéœ€è¦æ ¹æ®å…·ä½“çš„è®­ç»ƒç¯å¢ƒã€ç¡¬ä»¶é…ç½®å’Œæ€§èƒ½éœ€æ±‚æ¥å†³å®šã€‚ä¾‹å¦‚ï¼š
- ã€”**å•æœºå¤šå¡**ã€•<font color='purple'><b></b>å¦‚æœæ˜¯åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šæœ‰å¤šä¸ª GPUï¼ŒGLOO æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©</font>ã€‚
- ã€”**å¤šæœºå¤šå¡**ã€•<font color='blue'><b>å¦‚æœè®­ç»ƒéœ€è¦æ‰©å±•åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼ŒNCCL å’Œ MPI å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©</b></font>ã€‚

#### 5.7.2.6 DDP ç¤ºä¾‹-1

è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ `torch.nn.parallel.DistributedDataParallel` ç¤ºä¾‹å¼€å§‹ã€‚è¿™ä¸ªç¤ºä¾‹ä½¿ç”¨äº†ä¸€ä¸ª `torch.nn.Linear` ä½œä¸ºæœ¬åœ°æ¨¡å‹ï¼Œç”¨ DDP åŒ…è£…å®ƒï¼Œç„¶ååœ¨ DDP æ¨¡å‹ä¸Šè¿è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ã€ä¸€æ¬¡åå‘ä¼ æ’­å’Œä¸€ä¸ªä¼˜åŒ–å™¨æ­¥éª¤ã€‚ä¹‹åï¼Œæœ¬åœ°æ¨¡å‹çš„å‚æ•°å°†è¢«æ›´æ–°ï¼Œæ‰€æœ‰ä¸åŒè¿›ç¨‹ä¸Šçš„æ‰€æœ‰æ¨¡å‹åº”è¯¥å®Œå…¨ç›¸åŒã€‚

```python
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
import torch.nn as nn
import torch.optim as optim
import os
from torch.nn.parallel import DistributedDataParallel as DDP


def example(rank, world_size):
    # create default process group | åˆ›å»ºé»˜è®¤çš„è¿›ç¨‹ç»„
    dist.init_process_group("gloo",  # å•æœºå¤šå¡æ¨èçš„åè®®
                            rank=rank,  # è¡¨æ˜ç›®å‰æ˜¯å“ªä¸ªè¿›ç¨‹
                            world_size=world_size  # è¿›ç¨‹æ•°é‡
                            )

    # create local model  | åˆ›å»ºæœ¬åœ°æ¨¡å‹
    model = nn.Linear(10, 10).to(rank)

    # construct DDP model | æ„é€ DDPæ¨¡å‹
    ddp_model = DDP(model, device_ids=[rank])  # device_idså¿…é¡»ç”¨list

    # define loss function and optimizer | å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    # forward pass  | å‰å‘ä¼ æ’­
    outputs = ddp_model(torch.randn(20, 10).to(rank))
    labels = torch.randn(20, 10).to(rank)

    # backward pass | åå‘ä¼ æ’­
    loss_fn(outputs, labels).backward()

    # update parameters | æ›´æ–°å‚æ•°
    optimizer.step()


def main():
    world_size = 2  # è¿›ç¨‹æ•°é‡
    # ä½¿ç”¨PyTorchçš„å¤šè¿›ç¨‹æ–¹æ³•å¯åŠ¨å¤šè¿›ç¨‹
    mp.spawn(
        example,  # è¿›ç¨‹æ‰§è¡Œçš„å‡½æ•°
        args=(world_size,),  # è¿›ç¨‹æ‰§è¡Œå‡½æ•°çš„å‚æ•°ï¼ˆä¸éœ€è¦ä¼ é€’ rank å‚æ•°ï¼Œmp.spawnå‡½æ•°ä¼šè‡ªåŠ¨ä¼ å…¥rankå‚æ•°çš„ï¼‰
        nprocs=world_size,  # è¿›ç¨‹çš„æ•°é‡
        join=True  # è¿›ç¨‹ç­‰å¾…ï¼ˆçˆ¶è¿›ç¨‹æ˜¯å¦åº”è¯¥ç­‰å¾…å­è¿›ç¨‹å®Œæˆæ‰§è¡Œåå†æ‰§è¡Œï¼‰
        )


if __name__=="__main__":
    # Environment variables which need to be set when using c10d's default "env" initialization mode.
    # åœ¨ä½¿ç”¨ c10d çš„é»˜è®¤ "env" åˆå§‹åŒ–æ¨¡å¼æ—¶éœ€è¦è®¾ç½®çš„ç¯å¢ƒå˜é‡
    os.environ["MASTER_ADDR"] = "localhost"  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„IPä¸ºæœ¬åœ°ä¸»æœº
    os.environ["MASTER_PORT"] = "29500"  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„ç›‘å¬ç«¯å£
    main()
```

> âš ï¸ åœ¨ `mp.spawn()` å‡½æ•°ä¸­ï¼Œ`args=` å‚æ•°ä¸­ä¸éœ€è¦ä¼ é€’ `rank` å‚æ•°ï¼Œ`mp.spawn` å‡½æ•°ä¼šè‡ªåŠ¨ä¼ å…¥rankå‚æ•°çš„

---

<kbd><b>Question</b></kbd>ï¼šåœ¨ PyTorch çš„ DistributedDataParallel ä¸­ï¼Œworld_size æ˜¯ä»€ä¹ˆï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œ`world_size` æ˜¯ä¸€ä¸ªå‚æ•°ï¼Œå®ƒè¡¨ç¤ºå‚ä¸åˆ†å¸ƒå¼è®­ç»ƒçš„**æ€»è¿›ç¨‹æ•°**ï¼Œå³æ•´ä¸ªè®­ç»ƒé›†ç¾¤ä¸­çš„ GPU æ•°é‡ã€‚`world_size` ç”¨äºå®šä¹‰åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„å¹¶è¡Œçº§åˆ«ï¼Œå®ƒå‘Šè¯‰ DDP æœ‰å¤šå°‘ä¸ªè¿›ç¨‹ï¼ˆæˆ– GPUï¼‰æ­£åœ¨å‚ä¸è®­ç»ƒã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨ä¸€ä¸ªæ‹¥æœ‰ 8 ä¸ª GPU çš„å•ä¸ªèŠ‚ç‚¹ä¸Šè®­ç»ƒï¼Œé‚£ä¹ˆ `world_size` å°±æ˜¯ 8ã€‚å¦‚æœä½ æœ‰ä¸¤ä¸ªæ¯ä¸ªèŠ‚ç‚¹æœ‰ 4 ä¸ª GPU çš„èŠ‚ç‚¹ï¼Œé‚£ä¹ˆ `world_size` å°±æ˜¯ 8ã€‚

> âš ï¸ åœ¨ DDP ä¸­æ­£ç¡®è®¾ç½® `world_size` éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒä¼šå½±å“æ•°æ®çš„åˆ†ç‰‡æ–¹å¼ã€æ¢¯åº¦çš„åŒæ­¥æ–¹å¼ä»¥åŠè®­ç»ƒçš„æ•´ä½“æµç¨‹ã€‚å¦‚æœ `world_size` è®¾ç½®ä¸æ­£ç¡®ï¼Œå¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§é—®é¢˜ï¼Œå¦‚æ•°æ®ä¸å‡åŒ€ã€æ¢¯åº¦åŒæ­¥å¤±è´¥ç­‰ã€‚

---

<kbd><b>Question</b></kbd>ï¼šèŠ‚ç‚¹åˆæ˜¯ä»€ä¹ˆï¼Ÿ<a id="explanation-node"></a>

<kbd><b>Answer</b></kbd>ï¼šåœ¨ PyTorch çš„åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œ<font color='red'>èŠ‚ç‚¹å¯ä»¥æ˜¯ä¸€ä¸ªç‰©ç†æœåŠ¡å™¨ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªè™šæ‹Ÿæœº</font>ï¼Œåªè¦å®ƒèƒ½å¤Ÿè¿è¡Œ Python ç¨‹åºå¹¶èƒ½å¤Ÿä¸ç½‘ç»œä¸­çš„å…¶ä»–èŠ‚ç‚¹é€šä¿¡ã€‚

åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯èƒ½ä¼šæœ‰ä¸€ä¸ªæˆ–å¤šä¸ª GPUï¼Œå¹¶ä¸”æ¯ä¸ªèŠ‚ç‚¹å¯èƒ½ä¼šè¿è¡Œä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹ã€‚æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„è¿›ç¨‹å¯èƒ½ä¼šåŠ è½½æ¨¡å‹çš„ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶å¤„ç†æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ã€‚è¿™æ ·ï¼Œæ•´ä¸ªæ•°æ®é›†å°±è¢«åˆ†å¸ƒåœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œæ¯ä¸ªèŠ‚ç‚¹å¤„ç†æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ï¼Œä»è€Œå®ç°æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡Œï¼Œä»¥æé«˜è®­ç»ƒæ•ˆç‡å’Œå¤„ç†èƒ½åŠ›ã€‚

åœ¨å•æœºå¤š GPU è®­ç»ƒåœºæ™¯ä¸­ï¼ŒèŠ‚ç‚¹é€šå¸¸æŒ‡çš„æ˜¯å•ä¸ªç‰©ç†æœåŠ¡å™¨æˆ–å·¥ä½œç«™ï¼Œå®ƒåŒ…å«å¤šä¸ª GPUï¼Œå¹¶ä¸”è¿™äº› GPU å¯ä»¥é€šè¿‡é«˜é€Ÿå†…éƒ¨ç½‘ç»œè¿æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå¤§çš„è®¡ç®—èµ„æºæ± ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹å†…çš„ GPU ä¹‹é—´å¯ä»¥è¿›è¡Œé«˜æ•ˆçš„é€šä¿¡å’Œæ•°æ®ä¼ è¾“ã€‚

---

<kbd><b>Question</b></kbd>ï¼šè¿›ç¨‹ä¸ºä»€ä¹ˆå« worldï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨åˆ†å¸ƒå¼è®¡ç®—å’Œå¹¶è¡Œè®­ç»ƒçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæœ¯è¯­ "world" ç”¨äºè¡¨ç¤ºå‚ä¸å¹¶è¡Œæˆ–åˆ†å¸ƒå¼ä»»åŠ¡çš„å…¨éƒ¨è¿›ç¨‹é›†åˆã€‚è¿™ç§ç”¨æ³•åœ¨å„ç§å¹¶è¡Œå’Œåˆ†å¸ƒå¼ç³»ç»Ÿçš„è®¾è®¡ä¸­éƒ½å¾ˆå¸¸è§ï¼Œä¸ä»…ä»…é™äº PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ã€‚

ä½¿ç”¨ "world" æ¥æè¿°æ•´ä¸ªè¿›ç¨‹é›†åˆçš„æ¦‚å¿µæºäºè¿™æ ·çš„æ€æƒ³ï¼šåœ¨å¹¶è¡Œæˆ–åˆ†å¸ƒå¼è®¡ç®—ä¸­ï¼Œæ‰€æœ‰çš„è®¡ç®—èµ„æºï¼ˆè¿›ç¨‹ã€èŠ‚ç‚¹ã€è®¾å¤‡ç­‰ï¼‰éƒ½è¢«è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œå®ƒä»¬å…±åŒåä½œæ¥å®Œæˆä¸€ä¸ªä»»åŠ¡ã€‚è¿™ä¸ªæ•´ä½“å°±åƒæ˜¯ä¸€ä¸ªâ€œä¸–ç•Œâ€ï¼Œå…¶ä¸­çš„æ¯ä¸ªéƒ¨åˆ†ï¼ˆè¿›ç¨‹ï¼‰éƒ½æ˜¯è¿™ä¸ªâ€œä¸–ç•Œâ€çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒä»¬ä¹‹é—´éœ€è¦ååŒå·¥ä½œï¼Œä»¥ç¡®ä¿æ•´ä¸ªä»»åŠ¡çš„é¡ºåˆ©è¿›è¡Œã€‚

åœ¨ PyTorch çš„ DDP ä¸­ï¼Œ`world_size` å‚æ•°å°±æ˜¯ç”¨æ¥è¡¨ç¤ºè¿™ä¸ªâ€œä¸–ç•Œâ€ä¸­çš„è¿›ç¨‹æ•°é‡ï¼Œå³å‚ä¸è®­ç»ƒçš„ GPU æ•°é‡ã€‚è¿™ä¸ªæ¦‚å¿µå¸®åŠ©å¼€å‘è€…ç†è§£ä»–ä»¬æ­£åœ¨ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼çš„è®­ç»ƒç¯å¢ƒï¼Œå…¶ä¸­çš„æ‰€æœ‰è®¡ç®—èµ„æºéƒ½æ˜¯ç›¸äº’å…³è”çš„ï¼Œå¹¶ä¸”éœ€è¦ååŒå·¥ä½œä»¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚

æ‰€ä»¥ï¼Œå½“ä½ çœ‹åˆ° `world_size` è¿™ä¸ªè¯æ—¶ï¼Œå®ƒé€šå¸¸æŒ‡çš„æ˜¯å‚ä¸åˆ†å¸ƒå¼è®­ç»ƒçš„æ‰€æœ‰ GPU æˆ–è¿›ç¨‹çš„æ€»æ•°ã€‚

---

<kbd><b>Question</b></kbd>ï¼šèŠ‚ç‚¹å’Œè¿›ç¨‹ä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨åˆ†å¸ƒå¼è®¡ç®—å’Œå¹¶è¡Œè®­ç»ƒçš„ä¸Šä¸‹æ–‡ä¸­ï¼ŒèŠ‚ç‚¹å’Œè¿›ç¨‹ä¹‹é—´çš„å…³ç³»å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š

1. **èŠ‚ç‚¹ï¼ˆNodeï¼‰**ï¼š
   - èŠ‚ç‚¹æ˜¯ç‰©ç†æˆ–è™šæ‹Ÿçš„è®¡ç®—è®¾å¤‡ï¼Œå®ƒå¯ä»¥æ˜¯ä¸€ä¸ªæœåŠ¡å™¨ã€å·¥ä½œç«™æˆ–ä»»ä½•å…·æœ‰ç‹¬ç«‹å¤„ç†èƒ½åŠ›å’Œç½‘ç»œè¿æ¥çš„è®¾å¤‡ã€‚
   - åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼ŒèŠ‚ç‚¹æ˜¯å¹¶è¡Œæˆ–åˆ†å¸ƒå¼è®¡ç®—çš„åŸºæœ¬å•ä½ã€‚ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå¤„ç†å™¨ï¼ˆå¦‚ CPU æˆ– GPUï¼‰ï¼Œå¹¶ä¸”**å¯ä»¥è¿è¡Œä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹**ã€‚
2. **è¿›ç¨‹ï¼ˆProcessï¼‰**ï¼š
   - è¿›ç¨‹æ˜¯è®¡ç®—æœºä¸­ç¨‹åºæ‰§è¡Œçš„åŸºæœ¬å•ä½ã€‚å®ƒæ˜¯ç¨‹åºåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªå®ä¾‹ï¼Œæ‹¥æœ‰ç‹¬ç«‹çš„å†…å­˜ç©ºé—´å’Œæ‰§è¡Œçº¿ç¨‹ã€‚
   - **åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯ä»¥å¯åŠ¨ä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹**ã€‚**è¿™äº›è¿›ç¨‹å¯ä»¥è¿è¡Œæ¨¡å‹çš„å‰¯æœ¬ï¼Œå¹¶å¤„ç†æ•°æ®é›†çš„ä¸€éƒ¨åˆ†**ã€‚
   - è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡å’Œåä½œæ˜¯å®ç°åˆ†å¸ƒå¼è®¡ç®—å’Œå¹¶è¡Œå¤„ç†çš„å…³é”®ã€‚

æ€»ç»“æ¥è¯´ï¼ŒèŠ‚ç‚¹æ˜¯ç‰©ç†æˆ–è™šæ‹Ÿçš„è®¡ç®—è®¾å¤‡ï¼Œè€Œè¿›ç¨‹æ˜¯è¿™äº›èŠ‚ç‚¹ä¸Šè¿è¡Œçš„ç¨‹åºå®ä¾‹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼ŒèŠ‚ç‚¹ä¸Šå¯ä»¥å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼Œè¿™äº›è¿›ç¨‹å…±åŒå·¥ä½œæ¥å¤„ç†æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹ï¼Œæ¯ä¸ªè¿›ç¨‹è´Ÿè´£æ¨¡å‹çš„ä¸€éƒ¨åˆ†æˆ–å¤„ç†æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ã€‚èŠ‚ç‚¹å’Œè¿›ç¨‹ä¹‹é—´çš„å…³ç³»æ˜¯å¹¶è¡Œå’Œåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡çš„åŸºç¡€ã€‚

---

<kbd><b>Question</b></kbd>ï¼šrank æ˜¯ä»€ä¹ˆï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œ`rank` æ˜¯æŒ‡æ¯ä¸ªè¿›ç¨‹åœ¨åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯ä»¥å¯åŠ¨å¤šä¸ªè¿›ç¨‹ï¼Œè¿™äº›è¿›ç¨‹å¯èƒ½è´Ÿè´£ä¸åŒçš„ä»»åŠ¡ï¼Œå¦‚æ•°æ®åŠ è½½ã€æ¨¡å‹è®­ç»ƒã€å‚æ•°åŒæ­¥ç­‰ã€‚<font color='red'>æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„ `rank`ï¼Œç”¨äºåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿›è¡Œè¯†åˆ«å’Œé€šä¿¡</font>ã€‚

åœ¨ DDP ä¸­ï¼Œ`rank` çš„å€¼é€šå¸¸ä» 0 å¼€å§‹åˆ†é…ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹é€šå¸¸ä¼šè¢«åˆ†é…ä¸€ä¸ª `rank`ï¼Œè€Œè¯¥èŠ‚ç‚¹çš„å·¥ä½œè¿›ç¨‹ä¼šè¢«åˆ†é…å…¶ä»–çš„ `rank`ã€‚ğŸ’¡ åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ‰€æœ‰èŠ‚ç‚¹çš„ `rank` ä¸ªæ•°åŠ èµ·æ¥å°±æ˜¯ `world_size`ã€‚

> ğŸ’¡ å½“éœ€è¦åŒæ­¥æ¨¡å‹å‚æ•°æ—¶ï¼Œåªæœ‰ `rank=0` çš„è¿›ç¨‹ä¼šæ”¶é›†å…¶ä»–æ‰€æœ‰è¿›ç¨‹çš„å‚æ•°ï¼Œç„¶åå¹¿æ’­ç»™å…¶ä»–æ‰€æœ‰è¿›ç¨‹ã€‚
> 
> ğŸ’¡ å¦‚æœæˆ‘ä»¬éœ€è¦è®°å½•æ—¥å¿—ã€print ä¸€äº›ä¸œè¥¿çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿæ˜¯ä¼šç”¨ `rank=0` çš„ä¸»çº¿ç¨‹æ¥è¿›è¡Œçš„ï¼Œä¸ç„¶å¤šçº¿ç¨‹åŒæ—¶è¿›è¡Œçš„è¯ä¼šå¯¼è‡´å¾ˆå¤šçš„é‡å¤ï¼


ä¸‹é¢æˆ‘ä»¬ç”»ä¸€å¼ å›¾æ¥å±•ç¤ºï¼š

<div align=center>
    <img src=./imgs_markdown/plots-åˆ†å¸ƒå¼è®­ç»ƒçš„å…³ç³»å›¾.jpg
    width=80%>
    <center></center>
</div>

---

<kbd><b>Question</b></kbd>ï¼š`os.environ["MASTER_ADDR"] = "localhost"` å’Œ `os.environ["MASTER_PORT"] = "29500"` çš„ä½œç”¨ï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨ PyTorch çš„åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œ`MASTER_ADDR` å’Œ `MASTER_PORT` ç¯å¢ƒå˜é‡ç”¨äºæŒ‡å®šä¸»èŠ‚ç‚¹çš„åœ°å€å’Œç«¯å£ã€‚è¿™äº›å˜é‡åœ¨åˆ†å¸ƒå¼è®­ç»ƒçš„ä¸åŒåç«¯é€šä¿¡åº“ä¸­éƒ½æœ‰ä½¿ç”¨ï¼ŒåŒ…æ‹¬ `gloo`ã€`nccl` å’Œ `mpi`ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™ä¸¤ä¸ªç¯å¢ƒå˜é‡çš„ä½œç”¨å¦‚ä¸‹ï¼š

1. `MASTER_ADDR`ï¼šè¿™ä¸ªç¯å¢ƒå˜é‡æŒ‡å®šäº†ä¸»èŠ‚ç‚¹çš„ IP åœ°å€æˆ–ä¸»æœºåã€‚åœ¨å•æœºå¤šå¡è®­ç»ƒæˆ–å¤šèŠ‚ç‚¹è®­ç»ƒä¸­ï¼Œä¸»èŠ‚ç‚¹æ˜¯è´Ÿè´£åè°ƒè®­ç»ƒè¿‡ç¨‹çš„è¿›ç¨‹ã€‚å®ƒé€šå¸¸ä¼šæ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„æ¢¯åº¦ï¼Œå¹¶åœ¨æ‰€æœ‰è¿›ç¨‹ä¹‹é—´åŒæ­¥æ¨¡å‹å‚æ•°ã€‚

2. `MASTER_PORT`ï¼šè¿™ä¸ªç¯å¢ƒå˜é‡æŒ‡å®šäº†ä¸»èŠ‚ç‚¹ç›‘å¬çš„ç«¯å£ã€‚æ¯ä¸ªåˆ†å¸ƒå¼è®­ç»ƒçš„å®ä¾‹éƒ½éœ€è¦ä¸€ä¸ªå”¯ä¸€çš„ç«¯å£æ¥æ¥æ”¶æ¥è‡ªå…¶ä»–è¿›ç¨‹çš„è¿æ¥è¯·æ±‚ã€‚

åœ¨æˆ‘ä»¬æä¾›çš„ä»£ç ä¸­ï¼š

- `os.environ["MASTER_ADDR"] = "localhost"` è®¾ç½®ä¸»èŠ‚ç‚¹çš„åœ°å€ä¸ºæœ¬åœ°ä¸»æœºï¼Œå³å½“å‰è¿è¡Œä»£ç çš„æœºå™¨ã€‚
- `os.environ["MASTER_PORT"] = "29500"` è®¾ç½®ä¸»èŠ‚ç‚¹ç›‘å¬çš„ç«¯å£ä¸º 29500ã€‚

è¿™äº›è®¾ç½®ç¡®ä¿äº†åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„è¿›ç¨‹èƒ½å¤Ÿæ­£ç¡®åœ°è¿æ¥åˆ°ä¸»èŠ‚ç‚¹ï¼Œä»¥ä¾¿è¿›è¡Œæ•°æ®å’Œæ¢¯åº¦çš„åŒæ­¥ã€‚<font color='red'><b>å¦‚æœè¿™äº›ç¯å¢ƒå˜é‡è®¾ç½®ä¸æ­£ç¡®ï¼Œåˆ†å¸ƒå¼è®­ç»ƒçš„è¿›ç¨‹å¯èƒ½æ— æ³•ç›¸äº’é€šä¿¡ï¼Œå¯¼è‡´è®­ç»ƒå¤±è´¥</b></font>ã€‚

---

<kbd><b>Question</b></kbd>ï¼šä¸»èŠ‚ç‚¹æ˜¯ç¬¬ä¸€ä¸ªå¼€å¯çš„èŠ‚ç‚¹å—ï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šä¸ï¼Œä¸»èŠ‚ç‚¹å¹¶ä¸ä¸€å®šæ˜¯ç¬¬ä¸€ä¸ªå¼€å¯çš„èŠ‚ç‚¹ã€‚åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œä¸»èŠ‚ç‚¹æ˜¯è´Ÿè´£åè°ƒè®­ç»ƒè¿‡ç¨‹çš„è¿›ç¨‹ï¼Œå®ƒé€šå¸¸è¢«åˆ†é…ä¸€ä¸ªç‰¹å®šçš„ `rank`ï¼Œé€šå¸¸æ˜¯ `rank 0`ã€‚ä¸»èŠ‚ç‚¹çš„è§’è‰²æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„æ¢¯åº¦ï¼Œå¹¶åœ¨æ‰€æœ‰è¿›ç¨‹ä¹‹é—´åŒæ­¥æ¨¡å‹å‚æ•°ã€‚

ä¸»èŠ‚ç‚¹çš„é€‰æ‹©é€šå¸¸æ˜¯ç”±è®­ç»ƒä»£ç ä¸­çš„é€»è¾‘å†³å®šçš„ï¼Œè€Œä¸æ˜¯ç”±å¯åŠ¨é¡ºåºå†³å®šçš„ã€‚åœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ˜¾å¼åœ°æŒ‡å®šå“ªä¸ªè¿›ç¨‹åº”è¯¥ä½œä¸ºä¸»èŠ‚ç‚¹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `dist.init_process_group` å‡½æ•°å¹¶è®¾ç½® `rank=0` æ¥æŒ‡å®šä¸»èŠ‚ç‚¹ã€‚

> âš ï¸ <font color='red'><b>åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ä¸»è¿›ç¨‹éƒ½å¯ä»¥æ˜¯ä¸»èŠ‚ç‚¹ï¼Œåªè¦å®ƒä»¬åœ¨å¯åŠ¨æ—¶è¢«æ­£ç¡®åœ°åˆ†é…äº† `rank 0`ã€‚è¿™æ„å‘³ç€ï¼Œæ— è®ºå“ªä¸ªèŠ‚ç‚¹é¦–å…ˆå¯åŠ¨ï¼Œåªè¦å®ƒçš„ä¸»è¿›ç¨‹è¢«è®¾ç½®ä¸º `rank 0`ï¼Œå®ƒå°±å¯ä»¥æˆä¸ºä¸»èŠ‚ç‚¹</b></font>ã€‚

æ€»ç»“æ¥è¯´ï¼Œä¸»èŠ‚ç‚¹æ˜¯åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„ä¸€ä¸ªå…³é”®è¿›ç¨‹ï¼Œä½†å®ƒçš„é€‰æ‹©å¹¶ä¸ä¾èµ–äºå®ƒåœ¨ç½‘ç»œä¸­çš„å¯åŠ¨é¡ºåºï¼Œè€Œæ˜¯ä¾èµ–äºè®­ç»ƒä»£ç ä¸­çš„è®¾ç½®å’Œé€»è¾‘ã€‚

---

<kbd><b>Question</b></kbd>ï¼šä¸»èŠ‚ç‚¹ï¼ˆMaster Nodeï¼‰çš„ä¸»è¦ä»»åŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼šåœ¨åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­ï¼Œ`rank 0` çš„è¿›ç¨‹è¢«æŒ‡å®šä¸ºä¸»èŠ‚ç‚¹ï¼ˆMaster Nodeï¼‰ã€‚ä¸»èŠ‚ç‚¹è´Ÿè´£ä»¥ä¸‹ä»»åŠ¡ï¼š

1. **åˆå§‹åŒ–**ï¼šåœ¨è®­ç»ƒå¼€å§‹ä¹‹å‰ï¼Œä¸»èŠ‚ç‚¹è´Ÿè´£åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œä¾‹å¦‚è®¾ç½®ç½‘ç»œé€šä¿¡å’Œè¿›ç¨‹ç»„ã€‚
2. **åè°ƒ**ï¼šä¸»èŠ‚ç‚¹è´Ÿè´£åè°ƒåˆ†å¸ƒå¼è®­ç»ƒçš„å„ä¸ªè¿›ç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®çš„åˆ’åˆ†ã€æ¢¯åº¦çš„æ”¶é›†å’Œå‚æ•°çš„åŒæ­¥ã€‚
3. **ç›‘æ§**ï¼šä¸»èŠ‚ç‚¹å¯ä»¥ç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œå¹¶åœ¨è®­ç»ƒå®Œæˆåæ”¶é›†å’Œä¿å­˜æ¨¡å‹ã€‚
4. **é€šä¿¡**ï¼šä¸»èŠ‚ç‚¹æ˜¯æ‰€æœ‰è¿›ç¨‹é€šä¿¡çš„ä¸­å¿ƒç‚¹ï¼Œè´Ÿè´£æ¥æ”¶æ¥è‡ªå…¶ä»–è¿›ç¨‹çš„æ•°æ®å’Œæ¢¯åº¦ï¼Œå¹¶å°†å…¶åˆ†å‘ç»™æ‰€æœ‰è¿›ç¨‹ã€‚

åœ¨å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šé€šå¸¸ä¼šæœ‰ä¸€ä¸ªä¸»è¿›ç¨‹ï¼Œå®ƒè¢«è®¾ç½®ä¸º `rank 0`ã€‚è¿™æ„å‘³ç€ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥æœ‰ä¸€ä¸ªä¸»èŠ‚ç‚¹ï¼Œè´Ÿè´£ç®¡ç†è¯¥èŠ‚ç‚¹ä¸Šçš„è®­ç»ƒä»»åŠ¡ã€‚

æ€»ä¹‹ï¼Œ`rank 0` æ˜¯ä¸€ä¸ªç‰¹å®šçš„è¿›ç¨‹æ ‡è¯†ç¬¦ï¼Œå®ƒåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­æ‰®æ¼”ç€å…³é”®çš„è§’è‰²ï¼Œè´Ÿè´£åè°ƒå’Œç®¡ç†å·¥ä½œã€‚

#### 5.7.2.7 å†…éƒ¨è®¾è®¡

æœ¬èŠ‚é€šè¿‡æ·±å…¥æ¢è®¨æ¯ä¸€æ­¥éª¤çš„ç»†èŠ‚ï¼Œæ­ç¤ºäº† `torch.nn.parallel.DistributedDataParallel` çš„å·¥ä½œåŸç†ã€‚

ã€”**å‰ææ¡ä»¶**ã€•DDP ä¾èµ–äº c10d ProcessGroup è¿›è¡Œé€šä¿¡ã€‚å› æ­¤ï¼Œåº”ç”¨ç¨‹åºå¿…é¡»åœ¨æ„å»º DDP ä¹‹å‰åˆ›å»º ProcessGroup å®ä¾‹ã€‚

> `c10d` æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªåº“ï¼Œå®ƒæä¾›äº†é›†ä½“é€šä¿¡ï¼ˆcollective communicationï¼‰çš„å®ç°ï¼Œè¿™æ˜¯åˆ†å¸ƒå¼è®­ç»ƒä¸­ç”¨äºè¿›ç¨‹é—´é€šä¿¡çš„ä¸€ç§æœºåˆ¶ã€‚`c10d` æ”¯æŒä¸åŒç±»å‹çš„è¿›ç¨‹ç»„ï¼ˆProcessGroupï¼‰ï¼Œè¿™äº›è¿›ç¨‹ç»„å®šä¹‰äº†è¿›ç¨‹ä¹‹é—´çš„é€šä¿¡æ–¹å¼ã€‚
> 
> `ProcessGroup` æ˜¯ `c10d` ä¸­çš„ä¸€ä¸ªæ¦‚å¿µï¼Œå®ƒä»£è¡¨äº†ä¸€ç»„é€šè¿‡æŸç§é€šä¿¡åè®®è¿æ¥åœ¨ä¸€èµ·çš„è¿›ç¨‹ã€‚è¿™äº›è¿›ç¨‹å¯ä»¥æ˜¯åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šçš„å¤šä¸ªè¿›ç¨‹ï¼Œä¹Ÿå¯ä»¥æ˜¯è·¨å¤šä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹ã€‚`ProcessGroup` è´Ÿè´£ç®¡ç†è¿›ç¨‹ä¹‹é—´çš„æ•°æ®ä¼ è¾“å’ŒåŒæ­¥ã€‚
> 
> åœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œ`ProcessGroup` ç”¨äºå®ç°å¤š GPU ä¹‹é—´çš„æ•°æ®å¹¶è¡Œè®­ç»ƒã€‚DDP ä½¿ç”¨ `ProcessGroup` æ¥å®šä¹‰å’Œç»´æŠ¤åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­çš„è¿›ç¨‹ç»„ï¼ŒåŒ…æ‹¬æ•°æ®åˆ’åˆ†ã€æ¢¯åº¦æ”¶é›†å’Œå‚æ•°åŒæ­¥ç­‰æ“ä½œã€‚
> 
> æ€»ç»“æ¥è¯´ï¼Œ`c10d ProcessGroup` æ˜¯ PyTorch ä¸­ç”¨äºå®šä¹‰å’Œå®ç°åˆ†å¸ƒå¼è®­ç»ƒä¸­è¿›ç¨‹é—´é€šä¿¡çš„ä¸€ä¸ªæŠ½è±¡æ¦‚å¿µï¼Œå®ƒæ˜¯ DDP å’Œ PyTorch åˆ†å¸ƒå¼è®­ç»ƒä¸­å…¶ä»–ç»„ä»¶çš„åŸºç¡€ã€‚

---

ã€”**æ„å»º**ã€•DDP æ„é€ å‡½æ•°ï¼ˆconstructorï¼‰æ¥å—å¯¹æœ¬åœ°æ¨¡å—çš„å¼•ç”¨ï¼Œå¹¶å°† `rank=0` è¿›ç¨‹çš„ `state_dict()` å¹¿æ’­åˆ°ç»„ä¸­çš„æ‰€æœ‰å…¶ä»–è¿›ç¨‹ï¼Œä»¥ç¡®ä¿æ‰€æœ‰æ¨¡å‹å‰¯æœ¬ä»å®Œå…¨ç›¸åŒçš„çŠ¶æ€å¼€å§‹ã€‚ç„¶åï¼Œæ¯ä¸ª DDP è¿›ç¨‹åˆ›å»ºä¸€ä¸ªæœ¬åœ° Reducerï¼Œåè€…å°†åœ¨åå‘ä¼ æ’­æœŸé—´è´Ÿè´£æ¢¯åº¦çš„åŒæ­¥ã€‚

> åœ¨ PyTorch çš„ `DistributedDataParallel`ï¼ˆDDPï¼‰ä¸­ï¼Œ`Reducer` æ˜¯ä¸€ä¸ªå†…éƒ¨ç»„ä»¶ï¼Œç”¨äºåœ¨åˆ†å¸ƒå¼è®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†æ¢¯åº¦çš„åŒæ­¥ã€‚`Reducer` çš„ä¸»è¦èŒè´£æ˜¯æ”¶é›†æ¥è‡ªä¸åŒè¿›ç¨‹çš„æ¢¯åº¦ï¼Œç„¶åå¯¹è¿™äº›æ¢¯åº¦è¿›è¡Œèšåˆï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡ allreduce æ“ä½œï¼‰ï¼Œä»¥ç¡®ä¿æ‰€æœ‰è¿›ç¨‹ä¸Šçš„æ¨¡å‹å‚æ•°ä¿æŒåŒæ­¥ã€‚
> 
> `Reducer` çš„å…³é”®ç‰¹ç‚¹å’ŒåŠŸèƒ½åŒ…æ‹¬ï¼š
> 1. **æ¢¯åº¦èšåˆ**ï¼š`Reducer` è´Ÿè´£å°†æ¥è‡ªå„ä¸ªè¿›ç¨‹çš„æ¢¯åº¦èšåˆä¸ºä¸€ä¸ªå…±äº«çš„æ¢¯åº¦ï¼Œè¿™é€šå¸¸é€šè¿‡ allreduce æ“ä½œå®ç°ã€‚
> 2. **åˆ†æ¡¶**ï¼šä¸ºäº†æé«˜é€šä¿¡æ•ˆç‡ï¼Œ`Reducer` å°†å‚æ•°æ¢¯åº¦åˆ†æ¡¶ï¼ˆbucketingï¼‰ã€‚è¿™æ„å‘³ç€æ¢¯åº¦æ ¹æ®å®ƒä»¬çš„æ€§è´¨è¢«ç»„ç»‡åˆ°ä¸åŒçš„æ¡¶ä¸­ï¼Œæ¯ä¸ªæ¡¶ä¸­çš„æ¢¯åº¦åœ¨åŒä¸€æ—¶é—´å†…è¢«èšåˆã€‚
> 3. **å¼‚æ­¥é€šä¿¡**ï¼š`Reducer` æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œ<font color='red'><b>è¿™æ„å‘³ç€åœ¨ç­‰å¾…ä¸€ä¸ªæ¡¶çš„æ¢¯åº¦èšåˆå®Œæˆçš„åŒæ—¶ï¼Œå¯ä»¥å¼€å§‹å¤„ç†ä¸‹ä¸€ä¸ªæ¡¶çš„æ¢¯åº¦</b></font>ã€‚
> 4. **è‡ªåŠ¨æ±‚å¯¼é’©å­**ï¼š`Reducer` åœ¨æ„å»ºæ—¶æ³¨å†Œè‡ªåŠ¨æ±‚å¯¼ï¼ˆautogradï¼‰é’©å­ï¼Œè¿™äº›é’©å­åœ¨åå‘ä¼ æ’­æœŸé—´è¢«è§¦å‘ï¼Œå½“æ¢¯åº¦å‡†å¤‡å¥½æ—¶ï¼Œå®ƒä»¬ä¼šé€šçŸ¥ `Reducer`ã€‚
> 5. **å‰å‘ä¼ æ’­åˆ†æ**ï¼šå¦‚æœ `find_unused_parameters` è®¾ç½®ä¸º `True`ï¼Œ`Reducer` ä¼šåœ¨å‰å‘ä¼ æ’­æœŸé—´åˆ†ææ¨¡å‹è¾“å‡ºï¼Œä»¥ç¡®å®šå“ªäº›å‚æ•°å‚ä¸äº†åå‘ä¼ æ’­ã€‚
> 
> åœ¨ DDP çš„è®­ç»ƒå¾ªç¯ä¸­ï¼Œ`Reducer` åœ¨åå‘ä¼ æ’­æœŸé—´èµ·å…³é”®ä½œç”¨ï¼Œå®ƒç¡®ä¿äº†æ‰€æœ‰è¿›ç¨‹ä¸Šçš„æ¨¡å‹å‚æ•°åœ¨æ¯æ¬¡è¿­ä»£åéƒ½æ˜¯åŒæ­¥çš„ã€‚è¿™ç§åŒæ­¥æ˜¯é€šè¿‡åœ¨æ‰€æœ‰è¿›ç¨‹ä¹‹é—´å…±äº«æ¢¯åº¦æ¥å®ç°çš„ï¼Œä»è€Œç¡®ä¿äº†æ¨¡å‹çš„å¿«é€Ÿæ”¶æ•›å’Œè®­ç»ƒæ•ˆç‡ã€‚

ä¸ºäº†æé«˜é€šä¿¡æ•ˆç‡ï¼Œ`Reducer` å°†å‚æ•°æ¢¯åº¦ç»„ç»‡æˆæ¡¶ä¸­ï¼Œå¹¶ä¸€æ¬¡å‡å°‘ä¸€ä¸ªæ¡¶ã€‚å¯ä»¥é€šè¿‡åœ¨ DDP æ„é€ å‡½æ•°ä¸­è®¾ç½® `bucket_cap_mb` å‚æ•°æ¥é…ç½®æ¡¶å¤§å°ã€‚å‚æ•°æ¢¯åº¦åˆ°æ¡¶çš„æ˜ å°„æ˜¯åœ¨æ„å»ºæ—¶ç¡®å®šçš„ï¼ŒåŸºäºæ¡¶å¤§å°é™åˆ¶å’Œå‚æ•°å¤§å°ã€‚æ¨¡å‹å‚æ•°æŒ‰ç…§å¤§è‡´ä¸Šä¸ç»™å®šæ¨¡å‹çš„ `Model.parameters()` ç›¸åçš„é¡ºåºåˆ†é…åˆ°æ¡¶ä¸­ã€‚ä½¿ç”¨ç›¸åé¡ºåºçš„åŸå› æ˜¯ DDP æœŸæœ›åœ¨åå‘ä¼ æ’­æœŸé—´æ¢¯åº¦æŒ‰ç…§å¤§çº¦é‚£ä¸ªé¡ºåºå‡†å¤‡å¥½ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹ã€‚

<div align=center>
    <img src=./imgs_markdown/2024-02-18-13-50-04.png
    width=90%>
    <center></center>
</div>

æ³¨æ„ï¼Œ`grad0` å’Œ `grad1` åœ¨ `bucket1` ä¸­ï¼Œå¦å¤–ä¸¤ä¸ªæ¢¯åº¦åœ¨ `bucket0` ä¸­ã€‚å½“ç„¶ï¼Œè¿™ä¸ªå‡è®¾å¯èƒ½å¹¶ä¸æ€»æ˜¯æ­£ç¡®çš„ï¼Œå½“å‘ç”Ÿè¿™ç§æƒ…å†µæ—¶ï¼Œå®ƒå¯èƒ½ä¼šé™ä½ DDP åå‘é€Ÿåº¦ï¼Œå› ä¸º `Reducer` ä¸èƒ½åœ¨æœ€æ—©å¯èƒ½çš„æ—¶é—´å¯åŠ¨é€šä¿¡ã€‚

é™¤äº†åˆ†æ¡¶ä¹‹å¤–ï¼Œ`Reducer` åœ¨æ„å»ºæ—¶è¿˜æ³¨å†Œ `autograd` é’©å­ï¼Œæ¯ä¸ªå‚æ•°ä¸€ä¸ªã€‚è¿™äº›é’©å­å°†åœ¨åå‘ä¼ æ’­æœŸé—´æ¢¯åº¦å‡†å¤‡å¥½æ—¶è§¦å‘ã€‚

---

ã€”**å‰å‘ä¼ æ’­**ã€•DDP æ¥å—è¾“å…¥å¹¶ä¼ é€’ç»™æœ¬åœ°æ¨¡å‹ï¼Œç„¶ååˆ†ææœ¬åœ°æ¨¡å‹çš„è¾“å‡ºï¼Œå¦‚æœ `find_unused_parameters` è®¾ç½®ä¸º `True`ã€‚è¿™ç§æ¨¡å¼å…è®¸åœ¨æ¨¡å‹çš„å­å›¾ä¸Šè¿è¡Œåå‘ä¼ æ’­ï¼Œå¹¶ä¸” DDP é€šè¿‡éå†è‡ªåŠ¨å¾®åˆ†ï¼ˆautogradï¼‰å›¾ä»æ¨¡å‹è¾“å‡º**æ‰¾å‡ºå“ªäº›å‚æ•°å‚ä¸äº†åå‘ä¼ æ’­**ï¼Œå¹¶æ ‡è®°æ‰€æœ‰æœªä½¿ç”¨çš„å‚æ•°ä¸º ã€ready for reductionã€‘ã€‚åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼ŒReducer åªä¼šç­‰å¾…æœªå‡†å¤‡å¥½çš„å‚æ•°ï¼Œä½†ä»ä¼šå¯¹æ‰€æœ‰æ¡¶è¿›è¡Œæ±‚å’Œã€‚å°†å‚æ•°æ¢¯åº¦æ ‡è®°ä¸ºå‡†å¤‡å¥½ç›®å‰å¹¶ä¸å¸®åŠ© DDP è·³è¿‡æ¡¶ï¼Œä½†å®ƒå°†é˜²æ­¢ DDP åœ¨åå‘ä¼ æ’­æœŸé—´æ°¸è¿œç­‰å¾…ç¼ºå¤±çš„æ¢¯åº¦ã€‚

> âš ï¸ è¯·æ³¨æ„ï¼Œéå†è‡ªåŠ¨å¾®åˆ†å›¾ä¼šå¼•å…¥é¢å¤–çš„å¼€é”€ï¼Œå› æ­¤åº”åœ¨å¿…è¦æ—¶å°† `find_unused_parameters` è®¾ç½®ä¸º `True`ï¼Œå¦åˆ™è®¾ç½®ä¸º `False`ã€‚

---

ã€”**åå‘ä¼ æ’­**ã€•`.backward()` å‡½æ•°ç›´æ¥åœ¨æŸå¤± Tensor ä¸Šè¢«è°ƒç”¨ï¼Œè¿™è¶…å‡ºäº† DDP çš„æ§åˆ¶èŒƒå›´ï¼ŒDDP ä½¿ç”¨åœ¨æ„å»ºæ—¶æ³¨å†Œçš„ autograd é’©å­æ¥è§¦å‘æ¢¯åº¦åŒæ­¥ã€‚å½“ä¸€ä¸ªæ¢¯åº¦å‡†å¤‡å¥½æ—¶ï¼Œå…¶å¯¹åº”çš„ DDP é’©å­åœ¨è¯¥æ¢¯åº¦ç´¯ç§¯å™¨ä¸Šè§¦å‘ï¼ŒDDP ç„¶åå°†è¯¥å‚æ•°æ¢¯åº¦æ ‡è®°ä¸º ã€ready for reductionã€‘ã€‚

å½“ä¸€ä¸ªæ¡¶ä¸­çš„æ‰€æœ‰æ¢¯åº¦éƒ½å‡†å¤‡å¥½æ—¶ï¼ŒReducer å¯åŠ¨å¯¹è¯¥æ¡¶çš„å¼‚æ­¥ allreduceï¼Œä»¥è®¡ç®—æ‰€æœ‰è¿›ç¨‹ä¸Šæ¢¯åº¦çš„å¹³å‡å€¼ã€‚

å½“æ‰€æœ‰æ¡¶éƒ½å‡†å¤‡å¥½æ—¶ï¼ŒReducer å°†ç­‰å¾…æ‰€æœ‰ allreduce æ“ä½œå®Œæˆã€‚å®Œæˆæ­¤æ“ä½œåï¼Œå¹³å‡æ¢¯åº¦è¢«å†™å…¥æ‰€æœ‰å‚æ•°çš„ `param.grad` å­—æ®µã€‚å› æ­¤ï¼Œåœ¨åå‘ä¼ æ’­ä¹‹åï¼Œä¸åŒ DDP è¿›ç¨‹ä¸Šå¯¹åº”å‚æ•°çš„ grad å­—æ®µåº”è¯¥ç›¸åŒã€‚

---

ã€”**ä¼˜åŒ–å™¨æ­¥éª¤**ã€•ä»ä¼˜åŒ–å™¨çš„è§’åº¦æ¥çœ‹ï¼Œå®ƒæ­£åœ¨ä¼˜åŒ–ä¸€ä¸ªæœ¬åœ°æ¨¡å‹ã€‚DDP è¿›ç¨‹ä¸Šçš„æ‰€æœ‰æ¨¡å‹å‰¯æœ¬å¯ä»¥ä¿æŒåŒæ­¥ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä»ç›¸åŒçš„çŠ¶æ€å¼€å§‹ï¼Œå¹¶ä¸”åœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½æœ‰ç›¸åŒçš„å¹³å‡æ¢¯åº¦ã€‚

> âš ï¸ DDP è¦æ±‚æ‰€æœ‰è¿›ç¨‹ä¸­éƒ½æœ‰ Reducer å®ä¾‹ï¼Œä»¥ä¾¿ä»¥å®Œå…¨ç›¸åŒçš„é¡ºåºè°ƒç”¨ allreduceï¼Œè¿™æ˜¯é€šè¿‡å§‹ç»ˆæŒ‰æ¡¶ç´¢å¼•é¡ºåºè€Œä¸æ˜¯å®é™…çš„æ¡¶å‡†å¤‡é¡ºåºè¿è¡Œ allreduce æ¥å®ç°çš„ã€‚è¿›ç¨‹ä¹‹é—´ allreduce é¡ºåºçš„ä¸åŒ¹é…å¯èƒ½å¯¼è‡´é”™è¯¯çš„ç»“æœæˆ– DDP åå‘ä¼ æ’­æŒ‚èµ·ã€‚

#### 5.7.2.8 DDP ä¸ DP çš„å¯¹æ¯”

åœ¨æˆ‘ä»¬æ·±å…¥äº†è§£ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆææ¸…æ¥šä¸ºä»€ä¹ˆå°½ç®¡å¢åŠ äº†å¤æ‚æ€§ï¼Œæˆ‘ä»¬ä»ç„¶ä¼šè€ƒè™‘ä½¿ç”¨ DDP è€Œä¸æ˜¯ DPï¼š

é¦–å…ˆï¼ŒDP æ˜¯å•è¿›ç¨‹ã€<font color='red'><b>å¤šçº¿ç¨‹</b></font>çš„ï¼Œå¹¶ä¸”åªèƒ½åœ¨å•æœºä¸Šå·¥ä½œï¼Œè€Œ DDP æ˜¯<font color='red'><b>å¤šè¿›ç¨‹</b></font>çš„ï¼Œå¹¶ä¸”æ—¢æ”¯æŒå•æœºä¹Ÿæ”¯æŒå¤šæœºè®­ç»ƒã€‚<u>å³ä½¿åœ¨å•æœºä¸Šï¼ŒDP é€šå¸¸ä¹Ÿæ¯” DDP æ…¢</u>ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºçº¿ç¨‹é—´çš„ GIL äº‰ç”¨ã€æ¯è¿­ä»£å¤åˆ¶çš„æ¨¡å‹ï¼Œä»¥åŠè¾“å…¥åˆ†æ•£å’Œè¾“å‡ºèšé›†å¼•å…¥çš„é¢å¤–å¼€é”€ã€‚

å›æƒ³ä¸€ä¸‹å‰é¢çš„æ•™ç¨‹ï¼Œå¦‚æœæˆ‘ä»¬çš„æ¨¡å‹å¤ªå¤§ï¼Œæ— æ³•é€‚åº”å•ä¸ª GPUï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨æ¨¡å‹å¹¶è¡Œå°†å…¶æ‹†åˆ†åˆ°å¤šä¸ª GPU ä¸Šã€‚DDP æ”¯æŒæ¨¡å‹å¹¶è¡Œï¼Œä½† DP ç›®å‰ä¸æ”¯æŒã€‚å½“ DDP ä¸æ¨¡å‹å¹¶è¡Œç»“åˆä½¿ç”¨æ—¶ï¼Œæ¯ä¸ª DDP è¿›ç¨‹å°†ä½¿ç”¨æ¨¡å‹å¹¶è¡Œï¼Œæ‰€æœ‰è¿›ç¨‹é›†ä½“å°†ä½¿ç”¨æ•°æ®å¹¶è¡Œã€‚

|æ–¹å¼|æ•°æ®å¹¶è¡Œ|æ¨¡å‹å¹¶è¡Œ|
|:-:|:-:|:-:|
|DP|âœ”ï¸|âŒ|
|DDP|âœ”ï¸|âœ”ï¸|

#### 5.7.2.9 DDP ç¤ºä¾‹-2

```python
import os
import sys
import tempfile
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp

from torch.nn.parallel import DistributedDataParallel as DDP


def setup(rank, world_size):
    # rank: è¿›ç¨‹ç´¢å¼•
    # world_size: è¿›ç¨‹æ€»é‡

    os.environ['MASTER_ADDR'] = 'localhost'  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„IPä¸ºæœ¬åœ°ä¸»æœº
    os.environ['MASTER_PORT'] = '12355'  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„ç›‘å¬ç«¯å£

    # initialize the process group | åˆå§‹åŒ–è¿›ç¨‹ç»„
    dist.init_process_group(backend="gloo", 
                            rank=rank, 
                            world_size=world_size)

def cleanup():
    dist.destroy_process_group()  # å…³é—­è¿›ç¨‹ç»„
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼šåœ¨ Windows å¹³å°ä¸Šï¼Œ`torch.distributed` åŒ…ä»…æ”¯æŒ `Gloo` `åç«¯ã€FileStore` å’Œ `TcpStoreã€‚`
å¯¹äº `FileStore`ï¼Œè¯·åœ¨ `init_process_group` ä¸­çš„ `init_method` å‚æ•°ä¸­è®¾ç½®ä¸º`æœ¬åœ°æ–‡ä»¶è·¯å¾„`ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
init_method = "file:///f:/libtmp/some_file"
dist.init_process_group(
   "gloo",
   rank=rank,
   init_method=init_method,
   world_size=world_size)
```

å¯¹äº TcpStoreï¼Œåœ¨ Windows ä¸Šçš„è®¾ç½®æ–¹å¼ä¸ Linux ç›¸åŒã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ¨¡å‹ï¼ˆToyModelï¼‰ï¼Œç”¨ DDP åŒ…è£…å®ƒï¼Œå¹¶å‘å…¶æä¾›ä¸€äº›æ¨¡æ‹Ÿè¾“å…¥æ•°æ®ã€‚

> âš ï¸ è¯·æ³¨æ„ï¼Œç”±äº DDP åœ¨æ„é€ å‡½æ•°ä¸­ä» rank 0 è¿›ç¨‹å‘æ‰€æœ‰å…¶ä»– DDP è¿›ç¨‹å¹¿æ’­æ¨¡å‹çŠ¶æ€ï¼Œå› æ­¤æˆ‘ä»¬ä¸éœ€è¦æ‹…å¿ƒä¸åŒçš„ DDP è¿›ç¨‹ä»ä¸åŒçš„åˆå§‹æ¨¡å‹å‚æ•°å€¼å¼€å§‹ã€‚

```python
class ToyModel(nn.Module):
    def __init__(self):
        super(ToyModel, self).__init__()
        self.net1 = nn.Linear(10, 10)
        self.relu = nn.ReLU()
        self.net2 = nn.Linear(10, 5)

    def forward(self, x):
        return self.net2(self.relu(self.net1(x)))


def demo_basic(rank, world_size):
    print(f"Running basic DDP example on rank {rank}.")
    setup(rank, world_size)

    # create model and move it to GPU with id rank
    # åˆ›å»ºæ¨¡å‹å¹¶ä½¿ç”¨DDPå°†å…¶é€åˆ°å¯¹åº”çš„GPUä¸­
    model = ToyModel().to(rank)
    ddp_model = DDP(model, device_ids=[rank])  # device_idså¿…é¡»ç”¨list
    print(f"[{rank}] æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...")

    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    optimizer.zero_grad()  # æ¸…ç©ºå†å²æ¢¯åº¦ä¿¡æ¯
    outputs = ddp_model(torch.randn(20, 10))  # å‰å‘æ¨ç†
    labels = torch.randn(20, 5).to(rank)  # åˆ›å»ºGT
    loss_fn(outputs, labels).backward()  # è®¡ç®—æŸå¤±
    optimizer.step()  # æ›´æ–°å‚æ•°
    print(f"[{rank}] æ¨¡å‹è¿è¡Œå®Œæ¯•")

    cleanup()  # å…³é—­è¿›ç¨‹ç»„
    print(f"[{rank}] å…³é—­è¿›ç¨‹ç»„!")


def run_demo(demo_fn, world_size):
    mp.spawn(demo_fn,
             args=(world_size,),
             nprocs=world_size,
             join=True)
    
    
if __name__ == "__main__":
    run_demo(demo_fn=demo_basic, world_size=4)
```

ç»“æœå¦‚ä¸‹ï¼š

```
Running basic DDP example on rank 0.
Running basic DDP example on rank 2.
Running basic DDP example on rank 3.
Running basic DDP example on rank 1.
[2] æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...
[0] æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...
[3] æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...
[1] æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...
[3] æ¨¡å‹è¿è¡Œå®Œæ¯•
[1] æ¨¡å‹è¿è¡Œå®Œæ¯•
[3] å…³é—­è¿›ç¨‹ç»„!
[1] å…³é—­è¿›ç¨‹ç»„!
[2] æ¨¡å‹è¿è¡Œå®Œæ¯•
[2] å…³é—­è¿›ç¨‹ç»„!
[0] æ¨¡å‹è¿è¡Œå®Œæ¯•
[0] å…³é—­è¿›ç¨‹ç»„!
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿›ç¨‹çš„å¼€å§‹å’Œç»“æŸå¹¶ä¸æ˜¯ç»Ÿä¸€çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬æ˜¯ `rank=0` è¿™ä¸ªä¸»èŠ‚ç‚¹è¿›è¡Œ print æ“ä½œï¼Œå³ï¼š

```python
def demo_basic(rank, world_size):
    # print(f"Running basic DDP example on rank {rank}.")
    setup(rank, world_size)

    # create model and move it to GPU with id rank
    # åˆ›å»ºæ¨¡å‹å¹¶ä½¿ç”¨DDPå°†å…¶é€åˆ°å¯¹åº”çš„GPUä¸­
    model = ToyModel().to(rank)
    ddp_model = DDP(model, device_ids=[rank])  # device_idså¿…é¡»ç”¨list
    print(f"æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...") if rank == 0 else ...

    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    optimizer.zero_grad()  # æ¸…ç©ºå†å²æ¢¯åº¦ä¿¡æ¯
    outputs = ddp_model(torch.randn(20, 10))  # å‰å‘æ¨ç†
    labels = torch.randn(20, 5).to(rank)  # åˆ›å»ºGT
    loss_fn(outputs, labels).backward()  # è®¡ç®—æŸå¤±
    optimizer.step()  # æ›´æ–°å‚æ•°
    print(f"æ¨¡å‹è¿è¡Œå®Œæ¯•") if rank == 0 else ...

    cleanup()  # å…³é—­è¿›ç¨‹ç»„
    print(f"å…³é—­è¿›ç¨‹ç»„!") if rank == 0 else ...


def run_demo(demo_fn, world_size):
    mp.spawn(demo_fn,
             args=(world_size,),
             nprocs=world_size,
             join=True)
    
    
if __name__ == "__main__":
    run_demo(demo_fn=demo_basic, world_size=4)
```

```
æ¨¡å‹å·²åˆ›å»ºå¹¶ä½¿ç”¨ DDP è¿›è¡Œäº†åŒ…è£…...
æ¨¡å‹è¿è¡Œå®Œæ¯•
å…³é—­è¿›ç¨‹ç»„!
```

> âš ï¸ åœ¨DDPä¸­ï¼Œæ„é€ å‡½æ•°ã€å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­éƒ½æ˜¯åˆ†å¸ƒå¼åŒæ­¥ç‚¹ã€‚ä¸åŒè¿›ç¨‹åº”è¯¥å¯åŠ¨ç›¸åŒæ•°é‡çš„åŒæ­¥ï¼Œå¹¶ä»¥ç›¸åŒçš„é¡ºåºåˆ°è¾¾è¿™äº›åŒæ­¥ç‚¹ï¼Œå¹¶ä¸”**å¤§è‡´**åŒæ—¶è¿›å…¥æ¯ä¸ªåŒæ­¥ç‚¹ã€‚å¦åˆ™ï¼Œå¿«é€Ÿè¿›ç¨‹å¯èƒ½ä¼šæå‰åˆ°è¾¾å¹¶åœ¨ç­‰å¾…æ‰é˜Ÿè€…æ—¶è¶…æ—¶ã€‚å› æ­¤ï¼Œç”¨æˆ·è´Ÿè´£å¹³è¡¡è·¨è¿›ç¨‹çš„å·¥ä½œè´Ÿè½½åˆ†å¸ƒã€‚æœ‰æ—¶ï¼Œç”±äºç½‘ç»œå»¶è¿Ÿã€èµ„æºäº‰ç”¨æˆ–ä¸å¯é¢„æµ‹çš„å·¥ä½œè´Ÿè½½å³°å€¼ç­‰åŸå› ï¼Œå¤„ç†é€Ÿåº¦åå·®æ˜¯ä¸å¯é¿å…çš„ã€‚ä¸ºäº†åœ¨è¿™äº›æƒ…å†µä¸‹é¿å…è¶…æ—¶ï¼Œè¯·ç¡®ä¿åœ¨è°ƒç”¨ `init_process_group` æ—¶ä¼ é€’ä¸€ä¸ªè¶³å¤Ÿå¤§çš„è¶…æ—¶å€¼ã€‚

```python
class dist.init_process_group(backend=None, 
                              init_method=None, 
                              timeout=None,  # è¶…æ—¶å€¼
                              world_size=-1, 
                              rank=-1, 
                              store=None, 
                              group_name='', 
                              pg_options=None)
```

`timeout`ï¼šé’ˆå¯¹è¿›ç¨‹ç»„æ‰§è¡Œçš„æ“ä½œçš„è¶…æ—¶æ—¶é—´ã€‚NCCL çš„åç«¯é»˜è®¤å€¼ä¸º 10 åˆ†é’Ÿï¼Œå…¶ä»–åç«¯é»˜è®¤å€¼ä¸º 30 åˆ†é’Ÿã€‚è¿™æ˜¯é›†ä½“æ“ä½œå°†åœ¨ä¹‹åè¢«å¼‚æ­¥ä¸­æ­¢ï¼Œå¹¶ä¸”è¿›ç¨‹å°†å´©æºƒçš„æŒç»­æ—¶é—´ã€‚è¿™æ ·åšæ˜¯å› ä¸º CUDA æ‰§è¡Œæ˜¯å¼‚æ­¥çš„ï¼Œä¸€æ—¦å¼‚æ­¥ NCCL æ“ä½œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œç”¨æˆ·ä»£ç å°†ä¸å†å®‰å…¨ï¼Œå› ä¸ºå¤±è´¥çš„å¼‚æ­¥ NCCL æ“ä½œå¯èƒ½å¯¼è‡´åç»­çš„ CUDA æ“ä½œåœ¨æŸåçš„æ•°æ®ä¸Šè¿è¡Œã€‚å½“è®¾ç½® `TORCH_NCCL_BLOCKING_WAIT` æ—¶ï¼Œè¿›ç¨‹å°†é˜»å¡å¹¶ç­‰å¾…è¿™ä¸ªè¶…æ—¶æ—¶é—´ã€‚

#### 5.7.2.10 Save and Load Checkpointsï¼Œä¿å­˜å’ŒåŠ è½½æ£€æŸ¥ç‚¹

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šä½¿ç”¨ `torch.save` å’Œ `torch.load` æ¥æ£€æŸ¥ç‚¹æ¨¡å—ï¼Œå¹¶ä»æ£€æŸ¥ç‚¹æ¢å¤ã€‚å½“ä½¿ç”¨ DDP æ—¶ï¼Œ<font color='red'>ä¸€ç§ä¼˜åŒ–æ–¹æ³•æ˜¯åœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­ä¿å­˜æ¨¡å‹ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°æ‰€æœ‰è¿›ç¨‹ä¸­ï¼Œä»è€Œå‡å°‘å†™æ“ä½œçš„å¼€é”€</font>ã€‚è¿™æ˜¯æ­£ç¡®çš„ï¼Œ**å› ä¸ºæ‰€æœ‰è¿›ç¨‹éƒ½ä»ç›¸åŒçš„å‚æ•°å¼€å§‹ï¼Œå¹¶ä¸”åœ¨åå‘ä¼ æ’­ä¸­åŒæ­¥æ¢¯åº¦ï¼Œå› æ­¤ä¼˜åŒ–å™¨åº”è¯¥ç»§ç»­å°†å‚æ•°è®¾ç½®ä¸ºç›¸åŒçš„å€¼**ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨è¿™ç§ä¼˜åŒ–ï¼Œè¯·ç¡®ä¿åœ¨ä¿å­˜å®Œæˆä¹‹å‰æ²¡æœ‰è¿›ç¨‹å¼€å§‹åŠ è½½ã€‚<font color='red'><b>æ­¤å¤–ï¼Œåœ¨åŠ è½½æ¨¡å—æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æä¾›ä¸€ä¸ªé€‚å½“çš„ map_location å‚æ•°ï¼Œä»¥é˜²æ­¢è¿›ç¨‹è¿›å…¥å…¶ä»–è¿›ç¨‹çš„è®¾å¤‡</b></font>ã€‚å¦‚æœç¼ºå°‘ `map_location`ï¼Œ`torch.load` å°†é¦–å…ˆå°†æ¨¡å—åŠ è½½åˆ° CPUï¼Œç„¶åå°†æ¯ä¸ªå‚æ•°å¤åˆ¶åˆ°å®ƒä¿å­˜çš„ä½ç½®ï¼Œè¿™å°†å¯¼è‡´åŒä¸€å°æœºå™¨ä¸Šçš„æ‰€æœ‰è¿›ç¨‹ä½¿ç”¨åŒä¸€ç»„è®¾å¤‡ã€‚

```python
def demo_checkpoint(rank, world_size):
    print(f"Running DDP checkpoint example on rank {rank}.")
    setup(rank, world_size)  # åˆå§‹åŒ–è¿›ç¨‹ç»„

    model = ToyModel().to(rank)  # å®šä¹‰æ¨¡å‹
    ddp_model = DDP(model, device_ids=[rank])  # device_idså¿…é¡»ç”¨list

    # ckptä¿å­˜è·¯å¾„
    CHECKPOINT_PATH = tempfile.gettempdir() + "/model.checkpoint"
    
    if rank == 0:
        # All processes should see same parameters as they all start from same random parameters and gradients are synchronized in backward passes. Therefore, saving it in one process is sufficient.
        # æ‰€æœ‰è¿›ç¨‹åº”è¯¥çœ‹åˆ°ç›¸åŒçš„å‚æ•°ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä»ç›¸åŒçš„éšæœºå‚æ•°å¼€å§‹ï¼Œå¹¶ä¸”åœ¨åå‘ä¼ æ’­ä¸­åŒæ­¥æ¢¯åº¦ã€‚å› æ­¤ï¼Œåœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­ä¿å­˜å°±è¶³å¤Ÿäº†
        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)

    # Use a barrier() to make sure that process 1 loads the model after process 0 saves it.
    # âš ï¸ ä½¿ç”¨barrier()æ¥ç¡®ä¿è¿›ç¨‹1åœ¨è¿›ç¨‹0ä¿å­˜æ¨¡å‹ä¹‹ååŠ è½½æ¨¡å‹
    dist.barrier()
    
    # configure map_location properly | æ­£ç¡®é…ç½®map_location
    # âš ï¸ %0ç¡®ä¿äº†æ‰€æœ‰è¿›ç¨‹åœ¨åŠ è½½æ¨¡å‹æ—¶éƒ½é¦–å…ˆå°†å…¶åŠ è½½åˆ°cuda:0è®¾å¤‡ä¸Šï¼Œç„¶åæ ¹æ®æ¯ä¸ªè¿›ç¨‹çš„rankå°†å…¶å‚æ•°ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡ä¸Šã€‚
    # è¿™æ ·å¯ä»¥é¿å…åœ¨åŠ è½½æ¨¡å‹æ—¶å‡ºç°è®¾å¤‡å†²çª
    map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}
    print(f"[rank={rank}]map_location: {map_location}")
    weights = torch.load(CHECKPOINT_PATH, map_location=map_location)
    ddp_model.load_state_dict(weights)

    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    optimizer.zero_grad()
    outputs = ddp_model(torch.randn(20, 10))
    labels = torch.randn(20, 5).to(rank)

    loss_fn(outputs, labels).backward()
    optimizer.step()

    # Not necessary to use a dist.barrier() to guard the file deletion below as the AllReduce ops in the backward pass of DDP already served as a synchronization.
    # åœ¨DDPçš„åå‘ä¼ æ’­ä¸­çš„AllReduceæ“ä½œå·²ç»èµ·åˆ°äº†åŒæ­¥ä½œç”¨ï¼Œå› æ­¤ä¸éœ€è¦ä½¿ç”¨dist.barrier()æ¥ä¿æŠ¤ä¸‹é¢çš„æ–‡ä»¶åˆ é™¤æ“ä½œ
    if rank == 0:
        os.remove(CHECKPOINT_PATH)  # åˆ é™¤æ‰ç¤ºä¾‹ä¸­çš„æƒå€¼æ–‡ä»¶

    cleanup()
```

```
Running DDP checkpoint example on rank 3.
Running DDP checkpoint example on rank 2.
Running DDP checkpoint example on rank 0.
Running DDP checkpoint example on rank 1.
[rank=2]map_location: {'cuda:0': 'cuda:2'}
[rank=0]map_location: {'cuda:0': 'cuda:0'}
[rank=1]map_location: {'cuda:0': 'cuda:1'}
[rank=3]map_location: {'cuda:0': 'cuda:3'}
```

<kbd><b>Question</b></kbd>ï¼š`dist.barrier()` çš„ä½œç”¨ï¼Ÿ

<kbd><b>Answer</b></kbd>ï¼š`dist.barrier()` æ˜¯ PyTorch ä¸­åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„ä¸€ä¸ªåŒæ­¥æ“ä½œã€‚å®ƒçš„ä½œç”¨æ˜¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„å¤šä¸ªè¿›ç¨‹ä¹‹é—´åˆ›å»ºä¸€ä¸ªåŒæ­¥ç‚¹ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½åœ¨æ­¤åŒæ­¥ç‚¹åˆ°è¾¾ä¹‹å‰ç­‰å¾…ã€‚

å…·ä½“æ¥è¯´ï¼Œ`dist.barrier()` çš„ä½œç”¨åŒ…æ‹¬ï¼š

1. **åŒæ­¥ç‚¹ï¼š** å½“æŸä¸ªè¿›ç¨‹è°ƒç”¨ `dist.barrier()` æ—¶ï¼Œå®ƒä¼šè¢«é˜»å¡ï¼Œç›´åˆ°æ‰€æœ‰å‚ä¸åˆ†å¸ƒå¼è®­ç»ƒçš„è¿›ç¨‹éƒ½åˆ°è¾¾è¿™ä¸ªåŒæ­¥ç‚¹ã€‚

2. **ç¡®ä¿ä¸€è‡´æ€§ï¼š** åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½å¸Œæœ›åœ¨æ‰€æœ‰è¿›ç¨‹éƒ½å®Œæˆäº†æŸä¸ªä»»åŠ¡ä¹‹åå†ç»§ç»­è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œã€‚`dist.barrier()` æä¾›äº†ä¸€ç§ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½è¾¾åˆ°æŸä¸ªçŠ¶æ€åå†ç»§ç»­æ‰§è¡Œçš„æœºåˆ¶ã€‚

æ³¨æ„äº‹é¡¹ï¼š
- ä½¿ç”¨ `dist.barrier()` æ—¶ï¼Œç¡®ä¿æ‰€æœ‰å‚ä¸åˆ†å¸ƒå¼è®­ç»ƒçš„è¿›ç¨‹éƒ½è°ƒç”¨äº†è¯¥å‡½æ•°ï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´æ­»é”ã€‚
- å°½é‡åœ¨åˆé€‚çš„åœ°æ–¹ä½¿ç”¨ `dist.barrier()`ï¼Œä»¥é¿å…ä¸å¿…è¦çš„ç­‰å¾…æ—¶é—´ã€‚

ç¤ºä¾‹ï¼š

```python
import os
import torch.distributed as dist
import torch.multiprocessing as mp


def setup(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    
    # åˆå§‹åŒ–è¿›ç¨‹ç»„
    dist.init_process_group(
        backend='nccl',
        rank=rank,
        world_size=world_size
    )
    
    
def example(rank, world_size):
    setup(rank=rank, world_size=world_size)  # åˆå§‹åŒ–è¿›ç¨‹ç»„

    print(f"Before barrier [rank {rank}]")
    dist.barrier()
    print(f"After barrier [rank {rank}]")
    
    # å…³é—­è¿›ç¨‹ç»„
    dist.destroy_process_group()
    

def main():
    world_size = 4
    
    mp.spawn(
        fn=example,
        args=(world_size, ),  # ä¸éœ€è¦ä¼ é€’ rank å‚æ•°ï¼Œmp.spawnå‡½æ•°ä¼šè‡ªåŠ¨ä¼ å…¥rankå‚æ•°çš„
        nprocs=world_size,
        join=True
    )
    
    
if __name__ == "__main__":
    main()
```

```
Before barrier [rank 0]
Before barrier [rank 2]
Before barrier [rank 1]
Before barrier [rank 3]

âš ï¸ è¿™é‡Œä¼šç­‰å¾…ä¸€ä¼šå„¿å†æ‰“å°å‡ºä¸‹é¢çš„å†…å®¹

After barrier [rank 1]
After barrier [rank 2]
After barrier [rank 3]
After barrier [rank 0]
```

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹åœ¨è°ƒç”¨ `dist.barrier()` ä¹‹å‰æ‰“å°ä¸€æ¡æ¶ˆæ¯ï¼Œç„¶ååœ¨è°ƒç”¨ä¹‹åå†æ‰“å°ä¸€æ¡æ¶ˆæ¯ã€‚ä½ ä¼šæ³¨æ„åˆ°åœ¨æ‰€æœ‰è¿›ç¨‹éƒ½è°ƒç”¨ `dist.barrier()` ä¹‹å‰ï¼Œæ²¡æœ‰ä»»ä½•ä¸€ä¸ªè¿›ç¨‹èƒ½å¤Ÿæ‰“å° "After barrier" çš„æ¶ˆæ¯ã€‚è¿™å±•ç¤ºäº† `dist.barrier()` çš„åŒæ­¥æ•ˆæœã€‚

#### 5.7.2.11 å°† DDP ä¸æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰ç»“åˆï¼ˆCombining DDP with Model Parallelismï¼‰

DDP ä¹Ÿé€‚ç”¨äºå¤š GPU æ¨¡å‹ã€‚å½“è®­ç»ƒå…·æœ‰å¤§é‡æ•°æ®çš„å¤§å‹æ¨¡å‹æ—¶ï¼Œä½¿ç”¨ DDP åŒ…è£…å¤š GPU æ¨¡å‹ç‰¹åˆ«æœ‰å¸®åŠ©ã€‚

```python
class ToyMpModel(nn.Module):
    def __init__(self, dev0, dev1):
        super(ToyMpModel, self).__init__()
        self.dev0 = dev0  # è®¾å¤‡0
        self.dev1 = dev1  # è®¾å¤‡1
        self.net1 = torch.nn.Linear(10, 10).to(dev0)
        self.relu = torch.nn.ReLU()
        self.net2 = torch.nn.Linear(10, 5).to(dev1)

    def forward(self, x):
        x = x.to(self.dev0)  # å°†ç‰¹å¾å›¾æ”¾åˆ°è®¾å¤‡0ä¸Š
        x = self.relu(self.net1(x))
        x = x.to(self.dev1)  # å°†ç‰¹å¾å›¾æ”¾åˆ°è®¾å¤‡1ä¸Š
        return self.net2(x)
```

å½“å°†å¤š GPU æ¨¡å‹ä¼ é€’ç»™ DDP æ—¶ï¼Œä¸åº”è®¾ç½® `device_ids` å’Œ `output_device`ã€‚è¾“å…¥å’Œè¾“å‡ºæ•°æ®å°†ç”±åº”ç”¨ç¨‹åºæˆ–æ¨¡å‹çš„ `forward()` æ–¹æ³•æ”¾ç½®åœ¨é€‚å½“çš„è®¾å¤‡ä¸Šã€‚

```python
import os
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp

from torch.nn.parallel import DistributedDataParallel as DDP


def setup(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„IPä¸ºæœ¬åœ°ä¸»æœº
    os.environ['MASTER_PORT'] = '12355'  # è®¾ç½®ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰çš„ç›‘å¬ç«¯å£
    
    dist.init_process_group(backend='gloo',
                            world_size=world_size,
                            rank=rank)


def cleanup():
    dist.destroy_process_group()  # å…³é—­è¿›ç¨‹ç»„


class ToyMpModel(nn.Module):
    def __init__(self, dev0, dev1):
        super(ToyMpModel, self).__init__()
        self.dev0 = dev0  # è®¾å¤‡0
        self.dev1 = dev1  # è®¾å¤‡1
        self.net1 = torch.nn.Linear(10, 10).to(dev0)
        self.relu = torch.nn.ReLU()
        self.net2 = torch.nn.Linear(10, 5).to(dev1)

    def forward(self, x):
        x = x.to(self.dev0)  # å°†ç‰¹å¾å›¾æ”¾åˆ°è®¾å¤‡0ä¸Š
        print(f"å·²åŠ è½½åˆ°è®¾å¤‡-{self.dev0}")
        x = self.relu(self.net1(x))

        x = x.to(self.dev1)  # å°†ç‰¹å¾å›¾æ”¾åˆ°è®¾å¤‡1ä¸Š
        print(f"å·²åŠ è½½åˆ°è®¾å¤‡-{self.dev1}")
        return self.net2(x)
    
    
def demo_model_parallel(rank, world_size):
    print(f"Running DDP with model parallel example on rank {rank}.")
    setup(rank, world_size)

    # setup mp_model and devices for this process
    # ç¡®ä¿æ¯ä¸ªè¿›ç¨‹å¤„ç†ä¸¤ä¸ªç›¸é‚»çš„ GPU è®¾å¤‡
    dev0 = rank * 2  # å¥‡æ•°
    dev1 = rank * 2 + 1  # å¶æ•°
    print(f"[rank{rank}] {dev0=}    {dev1=}")
    mp_model = ToyMpModel(dev0, dev1)
    ddp_mp_model = DDP(mp_model)

    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)

    optimizer.zero_grad()
    # outputs will be on dev1
    outputs = ddp_mp_model(torch.randn(20, 10))
    labels = torch.randn(20, 5).to(dev1)
    loss_fn(outputs, labels).backward()
    optimizer.step()

    cleanup()
    
    
def run_demo(demo_fn, world_size):
    mp.spawn(demo_fn, 
             args=(world_size,),
             nprocs=world_size,
             join=True)


if __name__ == "__main__":
    n_gpus = torch.cuda.device_count()  # è®¡ç®—GPUä¸ªæ•°
    print(f"{n_gpus = }")
    
    assert n_gpus >= 2, f"Requires at least 2 GPUs to run, but got {n_gpus}"
    
    # world_size = n_gpus
    world_size = n_gpus // 2  # å› ä¸ºæ¶‰åŠåˆ°äº†æ¨¡å‹å¹¶è¡ŒMPï¼Œè¿™é‡Œæˆ‘ä»¬æ˜¯ä¸€ä¸ªæ¨¡å‹è¢«åˆ†ä¸ºäº†ä¸¤éƒ¨åˆ†ï¼Œæ‰€ä»¥å°±æ˜¯ä¸€ä¸ªçº¿ç¨‹è´Ÿè´£æ¨¡å‹çš„ä¸¤éƒ¨åˆ†ï¼Œéœ€è¦ä¸¤ä¸ªGPU
    run_demo(demo_model_parallel, world_size)
```

```
n_gpus = 8

Running DDP with model parallel example on rank 1.
Running DDP with model parallel example on rank 2.
Running DDP with model parallel example on rank 0.
Running DDP with model parallel example on rank 3.

[rank0] dev0=0    dev1=1
[rank3] dev0=6    dev1=7
[rank2] dev0=4    dev1=5
[rank1] dev0=2    dev1=3

å·²åŠ è½½åˆ°è®¾å¤‡-0
å·²åŠ è½½åˆ°è®¾å¤‡-4

å·²åŠ è½½åˆ°è®¾å¤‡-6
å·²åŠ è½½åˆ°è®¾å¤‡-2

å·²åŠ è½½åˆ°è®¾å¤‡-7
å·²åŠ è½½åˆ°è®¾å¤‡-3

å·²åŠ è½½åˆ°è®¾å¤‡-5
å·²åŠ è½½åˆ°è®¾å¤‡-1
```

#### 5.7.2.12 ä½¿ç”¨ torch.distributed.run/torchrun åˆå§‹åŒ– DDP

æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ PyTorch Elastic æ¥ç®€åŒ– DDP ä»£ç ï¼Œæ›´å®¹æ˜“åœ°åˆå§‹åŒ–ä½œä¸šã€‚è®©æˆ‘ä»¬ä»ç„¶ä½¿ç”¨ Toymodel ç¤ºä¾‹ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªåä¸º `exp5-elastic_ddp.py` çš„æ–‡ä»¶ã€‚

```python
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim

from torch.nn.parallel import DistributedDataParallel as DDP


class ToyModel(nn.Module):
    def __init__(self):
        super(ToyModel, self).__init__()
        self.net1 = nn.Linear(10, 10)
        self.relu = nn.ReLU()
        self.net2 = nn.Linear(10, 5)

    def forward(self, x):
        return self.net2(self.relu(self.net1(x)))


def demo_basic():
    dist.init_process_group("nccl")
    rank = dist.get_rank()  # è·å–çº¿ç¨‹rank
    # print(f"Start running basic DDP example on rank {rank}.")

    # create model and move it to GPU with id rank
    device_id = rank % torch.cuda.device_count()
    print(f"{device_id = }\t{rank = }")
    model = ToyModel().to(device_id)
    ddp_model = DDP(model, device_ids=[device_id])  # device_idså¿…é¡»ç”¨list

    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

    optimizer.zero_grad()
    outputs = ddp_model(torch.randn(20, 10))
    labels = torch.randn(20, 5).to(device_id)
    loss_fn(outputs, labels).backward()
    optimizer.step()
    dist.destroy_process_group()


if __name__ == "__main__":
    demo_basic()
```

ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šè¿è¡Œ `torch elastic` æˆ–è€… `torchrun` å‘½ä»¤æ¥åˆå§‹åŒ–ä¸Šè¿°åˆ›å»ºçš„ DDP ä½œä¸šï¼š

```bash
#!/bin/bash
export CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7

# æ–¹æ³•1
torchrun --nproc_per_node 7 --master_port 34231 learn-20240218/exp5-elastic_ddp.py

# æ–¹æ³•2
python -m torch.distributed.launch --nproc_per_node 7 --master_port 34231 learn-20240218/exp5-elastic_ddp.py
```

```
device_id = 0   rank = 0
device_id = 2   rank = 2
device_id = 4   rank = 4
device_id = 5   rank = 5
device_id = 3   rank = 3
device_id = 1   rank = 1
device_id = 6   rank = 6
```

ã€”**å‘½ä»¤è§£æ**ã€•ï¼š
- `--nproc_per_node=7`: æ­¤å‚æ•°æŒ‡å®šæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„è¿›ç¨‹æ•°ã€‚åœ¨è¿™é‡Œï¼Œè®¾ç½®ä¸º 7ï¼Œæ„å‘³ç€æ¯ä¸ªèŠ‚ç‚¹ä¸Šå°†æœ‰ 7 ä¸ªè¿›ç¨‹ï¼Œå¦‚æœæ˜¯ä¸€ä¸ª GPU ä¸€ä¸ªè¿›ç¨‹ï¼Œé‚£ä¹ˆå°±æ„å‘³ç€æœ‰ 7 ä¸ª GPUã€‚
- `--master_port=34231`: ä¸»èŠ‚ç‚¹ï¼ˆMasterNodeï¼‰ç›‘å¬ç«¯å£

#### 5.7.2.13 å•æœºæ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelï¼ŒMPï¼‰ç»ƒä¹ 

æ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelï¼ŒMPï¼‰åœ¨åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ä¹‹å‰çš„å†…å®¹è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨ DataParallel åœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œï¼Œè¿™ä¸ªç‰¹æ€§å°†åŒä¸€ä¸ªæ¨¡å‹å¤åˆ¶åˆ°æ‰€æœ‰ GPU ä¸Šï¼Œæ¯ä¸ª GPU å¤„ç†è¾“å…¥æ•°æ®çš„ä¸åŒçš„åˆ†åŒºã€‚å°½ç®¡å®ƒå¯ä»¥æ˜¾è‘—åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œä½†å®ƒä¸é€‚ç”¨äºä¸€äº›åœºæ™¯ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œæ¨¡å‹å¤ªå¤§ï¼Œæ— æ³•æ”¾å…¥å•ä¸ª GPU ä¸­ã€‚

æ¥ä¸‹æ¥å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰æ¥è§£å†³è¯¥é—®é¢˜ï¼Œä¸ DataParallel ä¸åŒï¼ŒMP å°†å•ä¸ªæ¨¡å‹åˆ†å‰²åˆ°ä¸åŒçš„ GPU ä¸Šï¼Œè€Œä¸æ˜¯åœ¨æ¯ä¸ª GPU ä¸Šå¤åˆ¶æ•´ä¸ªæ¨¡å‹ï¼ˆå…·ä½“æ¥è¯´ï¼Œå‡è®¾ä¸€ä¸ªæ¨¡å‹ m åŒ…å« 10 å±‚ï¼šå½“ä½¿ç”¨ DataParallel æ—¶ï¼Œæ¯ä¸ª GPU éƒ½å°†æ‹¥æœ‰è¿™äº› 10 å±‚çš„å‰¯æœ¬ï¼Œè€Œå½“åœ¨ä¸¤ä¸ª GPU ä¸Šä½¿ç”¨ MP æ—¶ï¼Œæ¯ä¸ª GPU å¯èƒ½æ‰˜ç®¡ 5 å±‚ï¼‰ã€‚

MP çš„é«˜çº§æ€æƒ³æ˜¯å°†æ¨¡å‹çš„ä¸åŒå­ç½‘ç»œæ”¾ç½®åœ¨ä¸åŒçš„è®¾å¤‡ä¸Šï¼Œå¹¶ç›¸åº”åœ°å®ç° `forward` æ–¹æ³•ï¼Œä»¥åœ¨ä¸åŒè®¾å¤‡ä¹‹é—´ç§»åŠ¨ä¸­é—´è¾“å‡ºã€‚ç”±äºåªæœ‰æ¨¡å‹çš„éƒ¨åˆ†åœ¨å•ä¸ªè®¾å¤‡ä¸Šè¿è¡Œï¼Œä¸€ç»„è®¾å¤‡å¯ä»¥å…±åŒå¤„ç†æ›´å¤§çš„æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šå°è¯•æ„å»ºå·¨å¤§çš„æ¨¡å‹å¹¶å°†å®ƒä»¬æŒ¤å‹åˆ°æœ‰é™æ•°é‡çš„ GPU ä¸Šã€‚ç›¸åï¼Œæœ¬æ–‡çš„é‡ç‚¹æ˜¯å±•ç¤ºæ¨¡å‹å¹¶è¡Œçš„æƒ³æ³•ã€‚å°†æƒ³æ³•åº”ç”¨åˆ°å®é™…åº”ç”¨ä¸­å–å†³äºè¯»è€…ã€‚

ã€”**ç®€å•ç¤ºä¾‹**ã€•

è®©æˆ‘ä»¬ä»ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªçº¿æ€§å±‚çš„ç©å…·æ¨¡å‹å¼€å§‹ã€‚ä¸ºäº†åœ¨ä¸¤ä¸ª GPU ä¸Šè¿è¡Œè¿™ä¸ªæ¨¡å‹ï¼Œåªéœ€å°†æ¯ä¸ªçº¿æ€§å±‚æ”¾åœ¨ä¸åŒçš„ GPU ä¸Šï¼Œå¹¶ç›¸åº”åœ°ç§»åŠ¨è¾“å…¥å’Œä¸­é—´è¾“å‡ºä»¥åŒ¹é…å±‚è®¾å¤‡ã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim


class ToyModel(nn.Module):
    def __init__(self):
        super(ToyModel, self).__init__()
        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')
        self.relu = torch.nn.ReLU()
        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')

    def forward(self, x):
        x = self.relu(self.net1(x.to('cuda:0')))
        return self.net2(x.to('cuda:1'))
```

æ³¨æ„ï¼Œä¸Šè¿° ToyModel çœ‹èµ·æ¥ä¸å¦‚ä½•åœ¨å•ä¸ª GPU ä¸Šå®ç°å®ƒéå¸¸ç›¸ä¼¼ï¼Œé™¤äº†å››ä¸ª `.to(device)` è°ƒç”¨ï¼Œè¿™äº›è°ƒç”¨å°†çº¿æ€§å±‚å’Œå¼ é‡æ”¾ç½®åœ¨é€‚å½“çš„è®¾å¤‡ä¸Šã€‚è¿™æ˜¯æ¨¡å‹ä¸­å”¯ä¸€éœ€è¦æ›´æ”¹çš„åœ°æ–¹ã€‚`.backward()` å’Œ `torch.optim` å°†è‡ªåŠ¨å¤„ç†æ¢¯åº¦ï¼Œå°±åƒæ¨¡å‹åœ¨å•ä¸ª GPU ä¸Šä¸€æ ·ã€‚æˆ‘ä»¬åªéœ€è¦ç¡®ä¿åœ¨è°ƒç”¨æŸå¤±å‡½æ•°æ—¶ï¼Œæ ‡ç­¾ä½äºä¸è¾“å‡ºç›¸åŒçš„è®¾å¤‡ä¸Šã€‚

```python
model = ToyModel()
loss_fn = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)

optimizer.zero_grad()
outputs = model(torch.randn(20, 10))
labels = torch.randn(20, 5).to('cuda:1')  # è¦ä¸ output çš„è®¾å¤‡ç±»å‹ç»Ÿä¸€
loss_fn(outputs, labels).backward()
optimizer.step()
```

ã€”**å°†æ¨¡å‹å¹¶è¡Œåº”ç”¨äºç°æœ‰æ¨¡å—**ã€•

æˆ‘ä»¬è¿˜å¯ä»¥ä»…é€šè¿‡å‡ è¡Œä»£ç æ›´æ”¹ï¼Œå°†ç°æœ‰çš„å• GPU æ¨¡å—è¿è¡Œåœ¨å¤šä¸ª GPU ä¸Šã€‚ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†å¦‚ä½•å°† `torchvision.models.resnet50()` åˆ†è§£åˆ°ä¸¤ä¸ª GPU ä¸Šã€‚æƒ³æ³•æ˜¯ç»§æ‰¿ç°æœ‰çš„ ResNet æ¨¡å—ï¼Œå¹¶åœ¨æ„é€ è¿‡ç¨‹ä¸­å°†å±‚åˆ†å‰²åˆ°ä¸¤ä¸ª GPU ä¸Šã€‚ç„¶åï¼Œè¦†ç›– forward æ–¹æ³•ï¼Œé€šè¿‡ç›¸åº”åœ°ç§»åŠ¨ä¸­é—´è¾“å‡ºå°†ä¸¤ä¸ªå­ç½‘ç»œæ‹¼æ¥åœ¨ä¸€èµ·ã€‚

```python
import time
import torch.nn as nn
from torchvision.models.resnet import ResNet, Bottleneck, resnet50


class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
            Bottleneck, [3, 4, 6, 3], num_classes=1000, *args, **kwargs)

        self.seq1 = nn.Sequential(
            self.conv1,
            self.bn1,
            self.relu,
            self.maxpool,

            self.layer1,
            self.layer2
        ).to('cuda:0')

        self.seq2 = nn.Sequential(
            self.layer3,
            self.layer4,
            self.avgpool,
        ).to('cuda:1')

        self.fc.to('cuda:1')

    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))
    
    
if __name__ == "__main__":
    
    # warm-up
    model = resnet50().to(0)
    del model
    
    # MP
    t1 = time.time()
    model = ModelParallelResNet50()
    t2 = time.time()
    print(f"MP: {t2 - t1 = }")
    
    # release gpu
    del model

    # without MP
    t1 = time.time()
    model = resnet50().to(0)
    t2 = time.time()
    print(f"No MP: {t2 - t1 = }")
```

```
MP:    t2 - t1 = 3.3101274967193604
No MP: t2 - t1 = 0.39362549781799316
```

ä¸Šè¿°å®ç°è§£å†³äº†æ¨¡å‹å¤ªå¤§æ— æ³•æ”¾å…¥å•ä¸ª GPU çš„æƒ…å†µã€‚ç„¶è€Œå¦‚æœæ¨¡å‹é€‚åˆå•ä¸ª GPUï¼Œå®ƒçš„é€Ÿåº¦ä¼šæ¯”åœ¨å•ä¸ª GPU ä¸Šè¿è¡Œæ…¢ã€‚è¿™æ˜¯å› ä¸ºï¼Œ**åœ¨ä»»ä½•æ—¶åˆ»ï¼Œåªæœ‰ä¸¤ä¸ª GPU ä¸­çš„ä¸€ä¸ªåœ¨å·¥ä½œï¼Œè€Œå¦ä¸€ä¸ªåˆ™æ— æ‰€äº‹äº‹**ã€‚éšç€ä¸­é—´è¾“å‡ºéœ€è¦åœ¨å±‚ 2 å’Œå±‚ 3 ä¹‹é—´ä» cuda:0 å¤åˆ¶åˆ° cuda:1ï¼Œæ€§èƒ½è¿›ä¸€æ­¥æ¶åŒ–ã€‚

è®©æˆ‘ä»¬è¿›è¡Œä¸€ä¸ªå®éªŒï¼Œä»¥è·å¾—æ›´å®šé‡çš„æ‰§è¡Œæ—¶é—´è§†å›¾ã€‚åœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è¿è¡Œéšæœºè¾“å…¥å’Œæ ‡ç­¾æ¥è®­ç»ƒ ModelParallelResNet50 å’Œç°æœ‰çš„ torchvision.models.resnet50()ã€‚è®­ç»ƒç»“æŸåï¼Œæ¨¡å‹ä¸ä¼šäº§ç”Ÿä»»ä½•æœ‰ç”¨çš„é¢„æµ‹ï¼Œä½†æˆ‘ä»¬å¯ä»¥å¯¹æ‰§è¡Œæ—¶é—´æœ‰ä¸€ä¸ªåˆç†çš„äº†è§£ã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.models.resnet import ResNet, Bottleneck
import matplotlib.pyplot as plt
plt.switch_backend('Agg')
import numpy as np
import timeit


class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
            Bottleneck, [3, 4, 6, 3], num_classes=1000, *args, **kwargs)

        self.seq1 = nn.Sequential(
            self.conv1,
            self.bn1,
            self.relu,
            self.maxpool,

            self.layer1,
            self.layer2
        ).to('cuda:0')

        self.seq2 = nn.Sequential(
            self.layer3,
            self.layer4,
            self.avgpool,
        ).to('cuda:1')

        self.fc.to('cuda:1')

    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))


def train(model):
    model.train(True)
    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001)

    one_hot_indices = torch.LongTensor(batch_size).random_(0, num_classes).view(batch_size, 1)

    for _ in range(num_batches):
        # generate random inputs and labels
        inputs = torch.randn(batch_size, 3, image_w, image_h)
        labels = torch.zeros(batch_size, num_classes).scatter_(1, one_hot_indices, 1)

        # run forward pass
        optimizer.zero_grad()
        outputs = model(inputs.to('cuda:0'))

        # run backward pass
        labels = labels.to(outputs.device)
        loss_fn(outputs, labels).backward()
        optimizer.step()
        
        
def plot(means, stds, labels, fig_name):
    fig, ax = plt.subplots()
    ax.bar(np.arange(len(means)), means, yerr=stds,
        align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)
    ax.set_ylabel('ResNet50 Execution Time (Second)')
    ax.set_xticks(np.arange(len(means)))
    ax.set_xticklabels(labels)
    ax.yaxis.grid(True)
    plt.tight_layout()
    plt.savefig(fig_name)
    plt.close(fig)
        

if __name__ == "__main__":
    num_batches = 3
    batch_size = 120
    image_w = 128
    image_h = 128
    num_classes = 1000

    num_repeat = 10

    stmt = "train(model)"

    setup = "model = ModelParallelResNet50()"
    mp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())
    mp_run_times = mp_run_times[1:]  # èˆå¼ƒç¬¬ä¸€æ¬¡çš„ç»“æœ
    mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)
    print(f"{mp_mean = :.4f}")
    print(f"{mp_std = :.4f}\n")

    setup = "import torchvision.models as models;" + "model = models.resnet50(num_classes=num_classes).to('cuda:0')"
    rn_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())
    rn_run_times = rn_run_times[1:]
    rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)
    print(f"{rn_mean = :.4f}")
    print(f"{rn_std = :.4f}")

    plot([mp_mean, rn_mean],
        [mp_std, rn_std],
        ['Model Parallel', 'Single GPU'],
        'mp_vs_rn.png')
```

```
mp_mean = 0.5374
mp_std = 0.0056

rn_mean = 0.5002
rn_std = 0.0039
```

<div align=center>
    <img src=./imgs_markdown/2024-02-18-17-35-19.png
    width=65%>
    <center></center>
</div>

ä¸Šé¢çš„ `train(model)` æ–¹æ³•ä½¿ç”¨ `nn.MSELoss` ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œ`optim.SGD` ä½œä¸ºä¼˜åŒ–å™¨ã€‚å®ƒæ¨¡æ‹Ÿäº†å¯¹ 128x128 å›¾åƒçš„è®­ç»ƒï¼Œè¿™äº›å›¾åƒè¢«ç»„ç»‡æˆ 3 ä¸ª Batchï¼Œæ¯ä¸ª Batch åŒ…å« 120 å¼ å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ `timeit` è¿è¡Œ `train(model)` æ–¹æ³• 10 æ¬¡ï¼Œå¹¶ç»˜åˆ¶æ‰§è¡Œæ—¶é—´åŠå…¶æ ‡å‡†å·®ã€‚

ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹å¹¶è¡Œå®ç°çš„æ‰§è¡Œæ—¶é—´æ¯”ç°æœ‰çš„å• GPU å®ç°é•¿äº† (0.5374/0.5002-1)*100=7.44%ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œåœ¨ GPU ä¹‹é—´å¤åˆ¶å¼ é‡çš„å¤§è‡´å¼€é”€ä¸º 7%ã€‚æœ‰æ”¹è¿›çš„ç©ºé—´ï¼Œå› ä¸ºæˆ‘ä»¬éƒ½çŸ¥é“åœ¨æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œä¸¤ä¸ª GPU ä¸­çš„ä¸€ä¸ªå¤„äºé—²ç½®çŠ¶æ€ã€‚ä¸€ä¸ªé€‰é¡¹æ˜¯å°†æ¯ä¸ª Batch è¿›ä¸€æ­¥åˆ’åˆ†ä¸ºä¸€ç³»åˆ—çš„åˆ†å‰²ï¼Œè¿™æ ·å½“ä¸€ä¸ªåˆ†å‰²åˆ°è¾¾ç¬¬äºŒä¸ªå­ç½‘ç»œæ—¶ï¼Œæ¥ä¸‹æ¥çš„åˆ†å‰²å¯ä»¥è¢«è¾“å…¥åˆ°ç¬¬ä¸€ä¸ªå­ç½‘ç»œã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä¸¤ä¸ªè¿ç»­çš„åˆ†å‰²å¯ä»¥åœ¨ä¸¤ä¸ª GPU ä¸ŠåŒæ—¶è¿è¡Œã€‚

> åœ¨ä¸Šè¿°æè¿°ä¸­ï¼Œæåˆ°çš„â€œåˆ†å‰²â€ï¼ˆsplitsï¼‰æ˜¯ä¸€ç§å‡è®¾çš„æ¨¡å‹å¹¶è¡Œç­–ç•¥ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹å¹¶è¡Œè®­ç»ƒä¸­çš„ GPU åˆ©ç”¨ç‡ã€‚è¿™ç§ç­–ç•¥çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ï¼ˆBatchï¼‰è¿›ä¸€æ­¥ç»†åˆ†æˆå¤šä¸ªæ›´å°çš„éƒ¨åˆ†ï¼Œå¹¶ç¡®ä¿è¿™äº›éƒ¨åˆ†åœ¨ä¸¤ä¸ª GPU ä¹‹é—´å‡åŒ€åˆ†å¸ƒã€‚
> 
> è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–çš„ä¾‹å­æ¥è¯´æ˜è¿™ä¸ªç­–ç•¥ï¼š
> 
> å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ‰¹æ¬¡ï¼ˆBatchï¼‰åŒ…å« 128 ä¸ªå›¾åƒï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰ä¸¤ä¸ª GPUã€‚å¦‚æœæˆ‘ä»¬æŒ‰ç…§ä¼ ç»Ÿçš„æ¨¡å‹å¹¶è¡Œæ–¹æ³•ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå°†å‰ 64 ä¸ªå›¾åƒåˆ†é…ç»™ GPU 0ï¼Œå°†å 64 ä¸ªå›¾åƒåˆ†é…ç»™ GPU 1ã€‚è¿™æ ·ï¼Œåœ¨å¤„ç†å®Œå‰ 64 ä¸ªå›¾åƒå¹¶å°†å…¶ç»“æœå‘é€åˆ° GPU 1 ä¹‹åï¼ŒGPU 0 ä¼šç­‰å¾… GPU 1 å¤„ç†å®Œå 64 ä¸ªå›¾åƒã€‚è¿™ç§æƒ…å†µä¸‹ï¼ŒGPU 0 ä¼šæœ‰ä¸€æ®µæ—¶é—´å¤„äºé—²ç½®çŠ¶æ€ã€‚
> 
> ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ª Batch è¿›ä¸€æ­¥åˆ’åˆ†ä¸ºå¤šä¸ªâ€œåˆ†å‰²â€ï¼ˆsplitsï¼‰ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ª Batch åˆ’åˆ†ä¸º 4 ä¸ªåˆ†å‰²ï¼Œæ¯ä¸ªåˆ†å‰²åŒ…å« 32 ä¸ªå›¾åƒã€‚è¿™æ ·ï¼Œæ¯ä¸ª GPU éƒ½ä¼šåŒæ—¶å¤„ç†ä¸¤ä¸ªåˆ†å‰²ã€‚å½“ä¸€ä¸ªåˆ†å‰²åœ¨ GPU 0 ä¸Šå¤„ç†å®Œå¹¶åˆ°è¾¾ç¬¬äºŒä¸ªå­ç½‘ç»œæ—¶ï¼ŒGPU 1 å·²ç»å¤„ç†å®Œå…¶ç¬¬ä¸€ä¸ªåˆ†å‰²ï¼Œå¹¶å‡†å¤‡æ¥æ”¶ GPU 0 çš„ç¬¬äºŒä¸ªåˆ†å‰²ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä¸¤ä¸ª GPU å¯ä»¥æ›´æœ‰æ•ˆåœ°å¹¶è¡Œå·¥ä½œï¼Œå‡å°‘é—²ç½®æ—¶é—´ã€‚
> 
> è¯·æ³¨æ„ï¼Œè¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå®é™…çš„åˆ†å‰²ç­–ç•¥å¯èƒ½ä¼šæ ¹æ®æ¨¡å‹çš„ç»“æ„å’Œæ•°æ®çš„ç‰¹ç‚¹è€Œæœ‰æ‰€ä¸åŒã€‚è¿™ç§ç­–ç•¥çš„å…³é”®æ˜¯ç¡®ä¿æ¯ä¸ª GPU éƒ½æœ‰è¿ç»­çš„è¾“å…¥æ•°æ®å¤„ç†ï¼Œä»è€Œå‡å°‘ GPU ä¹‹é—´çš„ç­‰å¾…æ—¶é—´ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚
>
> ä¸Šè¿°çš„æ–¹å¼å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
>
> <div align=center>
>     <img src=./imgs_markdown/plots-MP.jpg
>     width=100%>
>     <center></center>
> </div>

ã€”**é€šè¿‡æµæ°´çº¿è¾“å…¥ (Pipelining Inputs) åŠ é€Ÿ**ã€•

åœ¨æ¥ä¸‹æ¥çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªåŒ…å« 120 å¼ å›¾åƒçš„ Batch è¿›ä¸€æ­¥åˆ’åˆ†ä¸º 60 å¼ å›¾åƒçš„åˆ†å‰²ã€‚ç”±äº PyTorch ä»¥å¼‚æ­¥æ–¹å¼å¯åŠ¨ CUDA æ“ä½œï¼Œå®ç°ä¸éœ€è¦ `spawn` å¤šä¸ªçº¿ç¨‹æ¥è¾¾åˆ°å¹¶å‘æ€§ã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.models.resnet import ResNet, Bottleneck
import matplotlib.pyplot as plt
plt.switch_backend('Agg')
import numpy as np
import timeit
import prettytable


class ModelParallelResNet50(ResNet):
    def __init__(self, *args, **kwargs):
        super(ModelParallelResNet50, self).__init__(
            Bottleneck, [3, 4, 6, 3], num_classes=1000, *args, **kwargs)

        self.seq1 = nn.Sequential(
            self.conv1,
            self.bn1,
            self.relu,
            self.maxpool,

            self.layer1,
            self.layer2
        ).to('cuda:0')

        self.seq2 = nn.Sequential(
            self.layer3,
            self.layer4,
            self.avgpool,
        ).to('cuda:1')

        self.fc.to('cuda:1')

    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1'))
        return self.fc(x.view(x.size(0), -1))
    
    
class PipelineParallelResNet50(ModelParallelResNet50):
    """è¿™ä¸ªç±»ä½¿ç”¨äº†æµæ°´çº¿å¹¶è¡ŒæŠ€æœ¯ï¼Œå°†è¾“å…¥æ•°æ®åˆ†å‰²æˆæ›´å°çš„éƒ¨åˆ†ï¼Œå¹¶åœ¨ä¸¤ä¸ªä¸åŒçš„GPUä¸Šå¹¶è¡Œå¤„ç†ã€‚
        seq1å’Œseq2æ˜¯ResNet50æ¨¡å‹çš„ä¸åŒéƒ¨åˆ†ï¼Œå®ƒä»¬åœ¨ä¸åŒçš„GPUä¸Šè¿è¡Œã€‚
        é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æœ€å¤§åŒ–GPUçš„åˆ©ç”¨ç‡å’Œè®¡ç®—æ•ˆç‡ã€‚
    """
    def __init__(self, split_size=60, *args, **kwargs):
        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)
        self.split_size = split_size  # è®¾ç½®split_sizeå‚æ•°ï¼Œç”¨äºå°†è¾“å…¥æ•°æ®åˆ†å‰²æˆæ›´å°çš„éƒ¨åˆ†

    def forward(self, x):
        splits = iter(x.split(self.split_size, dim=0))  # æ²¿ç€batchç»´åº¦è¿›è¡Œsplitï¼Œå¹¶ä½¿å…¶å˜ä¸ºå¯è¿­ä»£å¯¹è±¡
        s_next = next(splits)  # è·å–ä¸‹ä¸€ä¸ªåˆ†å‰²çš„æ•°æ®
        s_prev = self.seq1(s_next).to('cuda:1')  # å°†åˆ†å‰²çš„æ•°æ®é€šè¿‡seq1å¤„ç†ï¼Œå¹¶å°†ç»“æœå‘é€åˆ°cuda:1
        ret = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¤„ç†ç»“æœ

        for s_next in splits:
            # A. ``s_prev`` runs on ``cuda:1``
            s_prev = self.seq2(s_prev)  # åœ¨cuda:1ä¸Šå¤„ç†s_prev
            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))  # å°†å¤„ç†ç»“æœé€šè¿‡å…¨è¿æ¥å±‚ï¼Œå¹¶å°†ç»“æœæ·»åŠ åˆ°retåˆ—è¡¨ä¸­

            # B. ``s_next`` runs on ``cuda:0``, which can run concurrently with A
            s_prev = self.seq1(s_next).to('cuda:1')  # åœ¨cuda:0ä¸Šå¤„ç†s_nextï¼Œå¹¶å°†ç»“æœå‘é€åˆ°cuda:1

        s_prev = self.seq2(s_prev)  # å¤„ç†æœ€åä¸€ä¸ªåˆ†å‰²çš„æ•°æ®
        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))  # å°†å¤„ç†ç»“æœæ·»åŠ åˆ°retåˆ—è¡¨ä¸­

        return torch.cat(ret)  # å°†æ‰€æœ‰å¤„ç†ç»“æœæ‹¼æ¥èµ·æ¥ï¼Œå¹¶è¿”å›


def train(model):
    model.train(True)
    loss_fn = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001)

    one_hot_indices = torch.LongTensor(batch_size).random_(0, num_classes).view(batch_size, 1)

    for _ in range(num_batches):
        # generate random inputs and labels
        inputs = torch.randn(batch_size, 3, image_w, image_h)
        labels = torch.zeros(batch_size, num_classes).scatter_(1, one_hot_indices, 1)

        # run forward pass
        optimizer.zero_grad()
        outputs = model(inputs.to('cuda:0'))

        # run backward pass
        labels = labels.to(outputs.device)
        loss_fn(outputs, labels).backward()
        optimizer.step()
        
        
def plot(means, stds, labels, fig_name):
    fig, ax = plt.subplots()
    ax.bar(np.arange(len(means)), means, yerr=stds,
        align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)
    ax.set_ylabel('ResNet50 Execution Time (Second)')
    ax.set_xticks(np.arange(len(means)))
    ax.set_xticklabels(labels)
    ax.yaxis.grid(True)
    plt.tight_layout()
    plt.savefig(fig_name)
    plt.close(fig)
        

if __name__ == "__main__":
    num_batches = 3
    batch_size = 120
    image_w = 128
    image_h = 128
    num_classes = 1000
    num_repeat = 10
    
    ptable = prettytable.PrettyTable(["model", 'mean', 'std'])
    ptable.border = True

    stmt = "train(model)"

    setup = "model = ModelParallelResNet50()"
    mp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())[1:]  # èˆå¼ƒç¬¬ä¸€æ¬¡çš„ç»“æœ
    mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)
    ptable.add_row(['Model Parallel', round(mp_mean, 4), round(mp_std, 4)])

    setup = "import torchvision.models as models;" + "model = models.resnet50(num_classes=num_classes).to('cuda:0')"
    rn_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())[1:]
    rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)
    ptable.add_row(['Single GPU', round(rn_mean, 4), round(rn_std, 4)])
    
    setup = "model = PipelineParallelResNet50()"
    pp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())[1:]
    pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)
    ptable.add_row(['Pipelining Model Parallel', round(pp_mean, 4), round(pp_std, 4)])
    
    print(ptable)

    plot([mp_mean, rn_mean, pp_mean],
        [mp_std, rn_std, pp_std],
        ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'],
        'mp_vs_rn_vs_pp.png')
```

```
+---------------------------+--------+--------+
|           model           |  mean  |  std   |
+---------------------------+--------+--------+
|       Model Parallel      | 0.5319 | 0.0077 |
|         Single GPU        | 0.4971 | 0.0048 |
| Pipelining Model Parallel | 0.5103 | 0.0099 |
+---------------------------+--------+--------+
```

<div align=center>
    <img src=./imgs_markdown/2024-02-19-10-28-26.png
    width=80%>
    <center></center>
</div>

å®éªŒç»“æœè¡¨æ˜ï¼Œå°†è¾“å…¥æ•°æ®æµæ°´çº¿åŒ–åˆ°æ¨¡å‹å¹¶è¡Œçš„ ResNet50 å¯ä»¥åŠ å¿«è®­ç»ƒè¿‡ç¨‹ï¼Œå¤§çº¦æé«˜äº† 4.2328%ï¼ˆ0.5319/0.5103-1ï¼‰ã€‚è¿™ä¸ PyTorch å®˜æ–¹æä¾›çš„ç»“æœç›¸å·®æœ‰ç‚¹å¤§ã€‚

> <div align=center>
>     <img src=./imgs_markdown/2024-02-19-10-30-00.png
>     width=80%>
>     <center>PyTorch å®˜æ–¹æä¾›çš„ç»“æœ</center>
> </div>
>
> åœ¨ PyTorch å®˜æ–¹æä¾›çš„ç»“æœä¸­ï¼Œä½¿ç”¨ Pipline çš„ MP æå‡äº† 49% çš„é€Ÿåº¦ï¼Œä½†åœ¨æˆ‘ä»¬çš„æœºå™¨ä¸Šå¹¶æ²¡æœ‰å¾—å‡ºå¯¹åº”çš„ç»“è®ºï¼ˆRTX 2080Tiï¼‰ã€‚


ç”±äºåœ¨æˆ‘ä»¬çš„æµæ°´çº¿å¹¶è¡Œå®ç°ä¸­å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å‚æ•° `split_size`ï¼Œç›®å‰å°šä¸æ¸…æ¥šè¿™ä¸ªæ–°å‚æ•°å¦‚ä½•å½±å“æ•´ä½“è®­ç»ƒæ—¶é—´ã€‚ç›´è§‚åœ°è¯´ï¼Œä½¿ç”¨è¾ƒå°çš„ `split_size` ä¼šå¯¼è‡´è®¸å¤šå¾®å°çš„ CUDA å†…æ ¸å¯åŠ¨ï¼Œè€Œä½¿ç”¨è¾ƒå¤§çš„ `split_size` ä¼šåœ¨ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª split æœŸé—´å¯¼è‡´ç›¸å¯¹è¾ƒé•¿çš„ç©ºé—²æ—¶é—´ã€‚è¿™ä¸¤ç§æƒ…å†µéƒ½ä¸ç†æƒ³ã€‚å¯èƒ½å­˜åœ¨ä¸€ä¸ªé’ˆå¯¹è¿™ä¸ªç‰¹å®šå®éªŒçš„æœ€ä¼˜ `split_size` é…ç½®ã€‚è®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨å‡ ä¸ªä¸åŒçš„ `split_size` å€¼è¿›è¡Œå®éªŒæ¥å°è¯•æ‰¾åˆ°å®ƒã€‚

```python
...

means = []
stds = []
split_sizes = [1, 3, 5, 8, 10, 12, 20, 40, 60, 80, 100]

# åˆ›å»ºè¡¨æ ¼å¯¹è±¡
table = prettytable.PrettyTable()
table.field_names = ["split_size", "mean", "std"]  # æ·»åŠ åˆ—å
table.border = True  # è®¾ç½®è¡¨æ ¼æ ¼å¼

for split_size in split_sizes:
    setup = "model = PipelineParallelResNet50(split_size=%d)" % split_size
    pp_run_times = timeit.repeat(stmt, setup, number=1, repeat=num_repeat, globals=globals())[1:]  # å»æ‰ç¬¬ä¸€ä¸ªç»“æœä»¥å‡å°‘è¯¯å·®
    means.append(np.mean(pp_run_times))
    stds.append(np.std(pp_run_times))
    # print(f"[split_size={split_size}]\n\tmean: {means[-1]:.4f}\n\tstd: {stds[-1]:.4f}")
    table.add_row([split_size, round(means[-1], 4), round(stds[-1], 4)])  # æ·»åŠ è¡Œæ•°æ®
    print(table)

fig, ax = plt.subplots()
ax.plot(split_sizes, means)
ax.errorbar(split_sizes, means, yerr=stds, ecolor='red', fmt='ro')
ax.set_ylabel('ResNet50 Execution Time (Second)')
ax.set_xlabel('Pipeline Split Size')
ax.set_xticks(split_sizes)
ax.yaxis.grid(True)
plt.tight_layout()
plt.savefig("split_size_tradeoff.png")
plt.close(fig)
```

```
+------------+--------+--------+
| split_size |  mean  |  std   |
+------------+--------+--------+
|     1      | 7.2939 | 0.1057 |
|     3      | 2.7698 | 0.0721 |
|     5      | 1.7975 |  0.02  |
|     8      | 1.273  |  0.02  |
|     10     | 1.0167 | 0.0288 |
|     12     | 0.8842 | 0.0442 |
|     20     | 0.7015 | 0.0263 |
|     40     | 0.5397 | 0.0103 |
|     60     | 0.5086 | 0.0157 |
|     80     | 0.5375 | 0.0113 |
|    100     | 0.5584 | 0.0048 |
+------------+--------+--------+
```

<div align=center>
    <img src=./imgs_markdown/2024-02-19-10-22-14.png
    width=80%>
    <center></center>
</div>

ç»“æœæ˜¾ç¤ºï¼Œå°† `split_size` è®¾ç½®ä¸º 60 å¯ä»¥å®ç°æœ€å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼Œè¿™å¯¼è‡´äº† 54%ï¼ˆ3.75/2.43-1ï¼‰çš„é€Ÿåº¦æå‡ã€‚ä»ç„¶æœ‰æœºä¼šè¿›ä¸€æ­¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼Œæ‰€æœ‰åœ¨ cuda:0 ä¸Šçš„æ“ä½œéƒ½è¢«æ”¾ç½®åœ¨å…¶é»˜è®¤æµä¸Šã€‚è¿™æ„å‘³ç€ä¸‹ä¸€ä¸ª split çš„è®¡ç®—æ— æ³•ä¸ä¸Šä¸€ä¸ª split çš„å¤åˆ¶æ“ä½œé‡å ã€‚ç„¶è€Œï¼Œç”±äº prev å’Œ next splits æ˜¯ä¸åŒçš„å¼ é‡ï¼Œé‡å ä¸€ä¸ªçš„è®¡ç®—ä¸å¦ä¸€ä¸ªçš„å¤åˆ¶æ˜¯æ²¡æœ‰é—®é¢˜çš„ã€‚å®ç°éœ€è¦åœ¨ä¸¤ä¸ª GPU ä¸Šä½¿ç”¨å¤šä¸ªæµï¼Œå¹¶ä¸”ä¸åŒçš„å­ç½‘ç»œç»“æ„éœ€è¦ä¸åŒçš„æµç®¡ç†ç­–ç•¥ã€‚

> âš ï¸ è¯¥ç»“æœä¹Ÿä¸ PyTorch å®˜æ–¹æä¾›çš„ç»“æœæœ‰å·®å¼‚ï¼ŒPyTorch å®˜æ–¹æä¾›çš„ç»“æœå¦‚ä¸‹ï¼š
> 
> <div align=center>
>     <img src=./imgs_markdown/2024-02-19-10-32-05.png
>     width=80%>
>     <center>PyTorch å®˜æ–¹æä¾›çš„ç»“æœ</center>
> </div>
> 
> åœ¨è¯¥ç»“æœä¸­ï¼Œ`split_size` çš„æœ€ä½³ç»“æœä¸º 12ï¼Œè€Œæˆ‘ä»¬çš„æœ€ä½³ç»“æœæ˜¯ 60ã€‚

ğŸ’¡ è¿™ç¯‡æ–‡ç« å±•ç¤ºäº†å‡ ç§æ€§èƒ½æµ‹é‡ã€‚å½“æˆ‘ä»¬åœ¨è‡ªå·±çš„æœºå™¨ä¸Šè¿è¡Œç›¸åŒä»£ç æ—¶ï¼Œå¯èƒ½ä¼šçœ‹åˆ°ä¸åŒçš„æ•°å­—ï¼Œå› ä¸ºç»“æœå–å†³äºåº•å±‚ç¡¬ä»¶å’Œè½¯ä»¶ã€‚ä¸ºäº†è·å¾—æˆ‘ä»¬ç¯å¢ƒä¸‹çš„æœ€ä½³æ€§èƒ½ï¼Œä¸€ä¸ªåˆé€‚çš„æ–¹æ³•æ˜¯é¦–å…ˆç”Ÿæˆæ›²çº¿ä»¥ç¡®å®šæœ€ä½³çš„åˆ†å‰²å¤§å°ï¼Œç„¶åä½¿ç”¨è¯¥åˆ†å‰²å¤§å°æ¥æµæ°´çº¿åŒ–è¾“å…¥ã€‚

## 5.8 Parallelizing Data Loading å¹¶è¡ŒåŒ–æ•°æ®åŠ è½½

<div align=center>
    <img src=./imgs_markdown/plots-æ•°æ®åŠ è½½.jpg
    width=100%>
    <center></center>
</div>

---

ã€”**DPæµç¨‹**ã€•

1. Transfer minibatch data from page-locked memory to GPU 0 (master). Master GPU also holds the model. Other GPUs have a stale copy of the model.
    å°†å°æ‰¹é‡ (minibatch) æ•°æ®ä»é¡µé”å®šå†…å­˜ä¼ è¾“åˆ° GPU 0ï¼ˆä¸» GPUï¼‰ã€‚ä¸» GPU è¿˜ä¿å­˜ç€æ¨¡å‹ã€‚å…¶ä»– GPU åˆ™ä¿å­˜ç€æ¨¡å‹çš„æ—§å‰¯æœ¬
2. Scatter minibatch data across GPUs
    åœ¨å¤šä¸ª GPU ä¸Šåˆ†æ•£å°æ‰¹é‡æ•°æ®
3. Replicate model across GPUs
    åœ¨å¤šä¸ª GPU ä¸Šå¤åˆ¶æ¨¡å‹
4. Run forward pass on each GPU, compute output. PyTorch implementataion spins up separate threads to parallelize forward pass
    åœ¨æ¯ä¸ª GPU ä¸Šè¿è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—è¾“å‡ºã€‚PyTorch å®ç°ä¼šå¯åŠ¨ (spin up) å•ç‹¬çš„çº¿ç¨‹æ¥å¹¶è¡ŒåŒ–å‰å‘ä¼ æ’­
5. Gather ouput on master GPU, compute loss
    åœ¨ä¸» GPU ä¸Šæ”¶é›†è¾“å‡ºï¼Œè®¡ç®—æŸå¤±
6. Scatter loss to GPUs and run backward pass to calculate parameter gradients
    åœ¨ GPU ä¸Šåˆ†æ•£æŸå¤±å¹¶è¿è¡Œåå‘ä¼ æ’­ä»¥è®¡ç®—å‚æ•°æ¢¯åº¦
7. Reduce gradients on GPU 0
    åœ¨ GPU 0 ä¸Šå‡å°‘æ¢¯åº¦
8. Update model's parameters
    æ›´æ–°æ¨¡å‹çš„å‚æ•°

---

ã€”**DDPæµç¨‹**ã€•

1. Load data from disk into page-locked memory on the host. Use multiple worker processes to parallelize data load. Distributed mini-batch sampler ensures that each process loads non-overlapping data
    å°†æ•°æ®ä»ç£ç›˜åŠ è½½åˆ°ä¸»æœºä¸Šçš„é¡µé”å®šå†…å­˜ä¸­ã€‚ä½¿ç”¨å¤šä¸ªå·¥ä½œè¿›ç¨‹æ¥å¹¶è¡ŒåŠ è½½æ•°æ®ã€‚**åˆ†å¸ƒå¼å°æ‰¹é‡é‡‡æ ·å™¨ç¡®ä¿æ¯ä¸ªè¿›ç¨‹åŠ è½½ä¸é‡å çš„æ•°æ®**
2. Trasfer mini-batch data from page-locked memory to each GPU concurrently. No data broadcast is needed. Each GPU has an identical copy of the model and no model broadcast is needed either
    åŒæ—¶å°†å°æ‰¹é‡æ•°æ®ä»é¡µé”å®šå†…å­˜ä¼ è¾“åˆ°æ¯ä¸ª GPUã€‚æ— éœ€æ•°æ®å¹¿æ’­ã€‚æ¯ä¸ª GPU éƒ½æœ‰æ¨¡å‹çš„ç›¸åŒå‰¯æœ¬ï¼Œä¹Ÿæ— éœ€æ¨¡å‹å¹¿æ’­
3. Run forward pass on each GPU, compute output
    åœ¨æ¯ä¸ª GPU ä¸Šè¿è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—è¾“å‡º
4. Compute loss, run backward pass to compute gradients. Perform gradient all-reduce in parallel with gradient computation
    è®¡ç®—æŸå¤±ï¼Œè¿è¡Œåå‘ä¼ æ’­ä»¥è®¡ç®—æ¢¯åº¦ã€‚åœ¨ä¸æ¢¯åº¦è®¡ç®—å¹¶è¡Œçš„æƒ…å†µä¸‹æ‰§è¡Œæ¢¯åº¦å…¨å½’çº¦
5. Update model's parameters. Because each GPU started with identical copy of the model and gradients were all-reduced, weights updates on all GPUs are identical. Thus no model sync is required.
    æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚<font color='red'><b>ç”±äºæ¯ä¸ª GPU éƒ½æ˜¯ä»ç›¸åŒçš„æ¨¡å‹å‰¯æœ¬å¼€å§‹çš„ï¼Œå¹¶ä¸”æ¢¯åº¦å·²ç»å…¨å½’çº¦ï¼Œæ‰€ä»¥æ‰€æœ‰ GPU ä¸Šçš„æƒé‡æ›´æ–°éƒ½æ˜¯ç›¸åŒçš„ã€‚å› æ­¤ï¼Œä¸éœ€è¦æ¨¡å‹åŒæ­¥</b></font>

## 5.9 YOLOv5 å¼€å¯ GPU è®­ç»ƒ

> ç›¸å…³ Issueï¼š[Multi-GPU Training ğŸŒŸ #475](https://github.com/ultralytics/yolov5/issues/475)

### 5.9.1 âœ”ï¸ã€”æ¨èã€•å• GPU è®­ç»ƒ

```bash
python train.py \
    --weights weights/yolov5s.pt \
    --data data/coco128.yaml \
    --hyp data/hyps/hyp.scratch-low.yaml \
    --epochs 150 \
    --batch-size 64 \
    --imgsz 640 \
    --project runs/train \
    --name exp
    --device 0
```

### 5.9.2 âš ï¸ã€”ä¸æ¨èã€•DP è®­ç»ƒ

```bash
python train.py \
    --weights weights/yolov5s.pt \
    --data data/coco128.yaml \
    --hyp data/hyps/hyp.scratch-low.yaml \
    --epochs 150 \
    --batch-size 64 \
    --imgsz 640 \
    --project runs/train \
    --name exp \
    --device 0,1
```

### 5.9.3 âœ”ï¸ã€”æ¨èã€•DDP è®­ç»ƒ

```bash
python -m torch.distributed.run \
    --nproc_per_node 4 \  # æ¯ä¸ªèŠ‚ç‚¹çš„ GPU æ•°é‡
    train.py \
    --weights weights/yolov5s.pt \
    --data data/coco128.yaml \
    --hyp data/hyps/hyp.scratch-low.yaml \
    --epochs 150 \
    --batch-size 64 \
    --imgsz 640 \
    --project runs/train \
    --name exp \
    --device 0,1,2,3
```

å…¶ä¸­ï¼Œ`--nproc_per_node` è¡¨æ˜ä¸€ä¸ªèŠ‚ç‚¹ä¸­ GPU çš„æ•°é‡

> å…³äºèŠ‚ç‚¹æ˜¯ä»€ä¹ˆï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œ[nodeçš„è¯´æ˜](#explanation-node)è¿›è¡Œäº†è¯´æ˜ã€‚



# å‚è€ƒ

1. ã€”è§†é¢‘æ•™ç¨‹ã€•[YOLOv5å…¥é—¨åˆ°ç²¾é€šï¼ä¸æ„§æ˜¯å…¬è®¤çš„è®²çš„æœ€å¥½çš„ã€ç›®æ ‡æ£€æµ‹å…¨å¥—æ•™ç¨‹ã€‘åŒæµå¤§ä½¬12å°æ—¶å¸¦æˆ‘ä»¬ä»å…¥é—¨åˆ°è¿›é˜¶ï¼ˆYOLO/ç›®æ ‡æ£€æµ‹/ç¯å¢ƒéƒ¨ç½²+é¡¹ç›®å®æˆ˜/Python/ï¼‰](https://www.bilibili.com/video/BV1YG411876u?p=13)
2. ã€”PyTorch å®˜æ–¹æ–‡æ¡£ã€•[torch.cuda.amp.autocast](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.autocast)
3. ã€”PyTorch å®˜æ–¹æ–‡æ¡£ã€•[torch.cuda.amp.GradScaler](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler)
3. ã€”PyTorch å®˜æ–¹æ–‡æ¡£ã€•[PyTorch Distributed Overview](https://pytorch.org/tutorials/beginner/dist_overview.html)